{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0105_DCN_like_predict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBTOhQ463t7z",
        "outputId": "6b1edd39-a35e-4681-f310-0e78d4f9c747"
      },
      "source": [
        "cd /content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2usum1jB5bHe",
        "outputId": "427d198f-bd75-4f22-cc8f-c7d61f2dd5ac"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 0105_DCN_like_predict.ipynb           train_v2_201130.json\n",
            "'0105_DCN_like_predict.ipynbá„‹á…´ á„‰á…¡á„‡á…©á†«'   user_test_v2.json\n",
            " 1220_dcn.ipynb                        user_train_v2.json\n",
            " DCN.py                                Wine_segment_201229.csv\n",
            " \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                          Wine_segment_scaled_201231.csv\n",
            " test_v2_201130.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65nKvxZD5e9j",
        "outputId": "5ad1b072-366e-4cbc-8088-a00feb75d423"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 5.1MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.6MB 14.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fwep3Dx5njv"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import glob\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, Callback\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_K49pf5vvR"
      },
      "source": [
        "# 0. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASm4pmAi5qr4"
      },
      "source": [
        "# 0. Data Load"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIYEMAos5uhg"
      },
      "source": [
        "train = pd.read_json('train_v2_201130.json')\n",
        "test = pd.read_json('test_v2_201130.json')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "saoP8nR752wc",
        "outputId": "51fc18ef-e86c-44e4-83b4-1e4332f1a1cb"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_note</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>vintage_id</th>\n",
              "      <th>user_like_count</th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>wine_name</th>\n",
              "      <th>url</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Soooo good ðŸ’•</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>BelÃ­ssimo champanhe rose, bem seco mais com mu...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>2</td>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Perfekt med gratinerede Ã¸sters.</td>\n",
              "      <td>4.5</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Delicious!</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... like\n",
              "0      0  ...    1\n",
              "1      1  ...    1\n",
              "2      4  ...    1\n",
              "3      5  ...    1\n",
              "4      6  ...    0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF4Yup4jD08j",
        "outputId": "82121e1a-6924-4183-e3fc-e0d8e0001854"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((763387, 10), (188718, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9fTbUA0Db6R"
      },
      "source": [
        "item = pd.read_csv('Wine_segment_201229.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "C4_NozHvD7Qe",
        "outputId": "0c5b135c-3dc2-47a6-ba63-1882a01bd90d"
      },
      "source": [
        "item.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>name</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>label_count</th>\n",
              "      <th>review_count</th>\n",
              "      <th>body</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>winery_ratings_count</th>\n",
              "      <th>winery_ratings_average</th>\n",
              "      <th>winery_labels_count</th>\n",
              "      <th>winery_wines_count</th>\n",
              "      <th>Aperitif</th>\n",
              "      <th>Appetizers and snacks</th>\n",
              "      <th>Blue cheese</th>\n",
              "      <th>Cured Meat</th>\n",
              "      <th>Fruity desserts</th>\n",
              "      <th>Game</th>\n",
              "      <th>Goat cheese</th>\n",
              "      <th>Lamb</th>\n",
              "      <th>Lean fish</th>\n",
              "      <th>Mature and hard cheese</th>\n",
              "      <th>Mild and soft cheese</th>\n",
              "      <th>Mushrooms</th>\n",
              "      <th>Pasta</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Poultry</th>\n",
              "      <th>Rich fish</th>\n",
              "      <th>Shellfish</th>\n",
              "      <th>Spicy food</th>\n",
              "      <th>Sweet desserts</th>\n",
              "      <th>Veal</th>\n",
              "      <th>Vegetarian</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Blue cheese.1</th>\n",
              "      <th>Fruity desserts.1</th>\n",
              "      <th>Game .1</th>\n",
              "      <th>Lamb.1</th>\n",
              "      <th>Mature and hard cheese.1</th>\n",
              "      <th>Pasta.1</th>\n",
              "      <th>...</th>\n",
              "      <th>pca_18</th>\n",
              "      <th>pca_19</th>\n",
              "      <th>pca_20</th>\n",
              "      <th>pca_21</th>\n",
              "      <th>pca_22</th>\n",
              "      <th>pca_23</th>\n",
              "      <th>pca_24</th>\n",
              "      <th>pca_25</th>\n",
              "      <th>pca_26</th>\n",
              "      <th>pca_27</th>\n",
              "      <th>pca_28</th>\n",
              "      <th>pca_29</th>\n",
              "      <th>pca_30</th>\n",
              "      <th>pca_31</th>\n",
              "      <th>pca_32</th>\n",
              "      <th>pca_33</th>\n",
              "      <th>pca_34</th>\n",
              "      <th>pca_35</th>\n",
              "      <th>pca_36</th>\n",
              "      <th>pca_37</th>\n",
              "      <th>pca_38</th>\n",
              "      <th>pca_39</th>\n",
              "      <th>pca_40</th>\n",
              "      <th>pca_41</th>\n",
              "      <th>pca_42</th>\n",
              "      <th>pca_43</th>\n",
              "      <th>pca_44</th>\n",
              "      <th>pca_45</th>\n",
              "      <th>pca_46</th>\n",
              "      <th>pca_47</th>\n",
              "      <th>pca_48</th>\n",
              "      <th>pca_49</th>\n",
              "      <th>pca_50</th>\n",
              "      <th>pca_51</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>region_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>type_id</th>\n",
              "      <th>winery_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1938520</td>\n",
              "      <td>1882 Cabernet Sauvignon</td>\n",
              "      <td>1697</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14879</td>\n",
              "      <td>16</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18888.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>121618.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.551669</td>\n",
              "      <td>4.234245</td>\n",
              "      <td>-4.399549</td>\n",
              "      <td>-1.394831</td>\n",
              "      <td>4.230004</td>\n",
              "      <td>2.214657</td>\n",
              "      <td>3.698479</td>\n",
              "      <td>-11.544035</td>\n",
              "      <td>3.926973</td>\n",
              "      <td>2.027013</td>\n",
              "      <td>-3.108813</td>\n",
              "      <td>0.066079</td>\n",
              "      <td>3.901737</td>\n",
              "      <td>5.336387</td>\n",
              "      <td>-2.893791</td>\n",
              "      <td>-7.887779</td>\n",
              "      <td>-12.434086</td>\n",
              "      <td>5.029867</td>\n",
              "      <td>-2.870348</td>\n",
              "      <td>1.098466</td>\n",
              "      <td>0.041303</td>\n",
              "      <td>-0.516198</td>\n",
              "      <td>0.322788</td>\n",
              "      <td>-0.443685</td>\n",
              "      <td>-3.136951</td>\n",
              "      <td>0.742006</td>\n",
              "      <td>0.173241</td>\n",
              "      <td>-1.924884</td>\n",
              "      <td>-1.610956</td>\n",
              "      <td>2.868221</td>\n",
              "      <td>-2.167123</td>\n",
              "      <td>1.151749</td>\n",
              "      <td>1.444787</td>\n",
              "      <td>2.489641</td>\n",
              "      <td>[2]</td>\n",
              "      <td>105.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14604</td>\n",
              "      <td>Les Bessards Hermitage</td>\n",
              "      <td>1078</td>\n",
              "      <td>4.3</td>\n",
              "      <td>5370</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>72079.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>462021.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.201073</td>\n",
              "      <td>3.788378</td>\n",
              "      <td>1.210495</td>\n",
              "      <td>1.083187</td>\n",
              "      <td>0.590964</td>\n",
              "      <td>3.617076</td>\n",
              "      <td>0.106284</td>\n",
              "      <td>7.155894</td>\n",
              "      <td>1.924063</td>\n",
              "      <td>-1.217552</td>\n",
              "      <td>3.798950</td>\n",
              "      <td>-0.573204</td>\n",
              "      <td>0.910653</td>\n",
              "      <td>2.294474</td>\n",
              "      <td>-1.256222</td>\n",
              "      <td>-1.491831</td>\n",
              "      <td>-2.579453</td>\n",
              "      <td>-0.628009</td>\n",
              "      <td>-0.097134</td>\n",
              "      <td>-4.154698</td>\n",
              "      <td>-2.861205</td>\n",
              "      <td>-4.497887</td>\n",
              "      <td>1.583489</td>\n",
              "      <td>-0.026252</td>\n",
              "      <td>-1.082327</td>\n",
              "      <td>0.338037</td>\n",
              "      <td>-2.199833</td>\n",
              "      <td>-0.638129</td>\n",
              "      <td>1.981586</td>\n",
              "      <td>1.148229</td>\n",
              "      <td>-0.780446</td>\n",
              "      <td>-1.026985</td>\n",
              "      <td>-3.631833</td>\n",
              "      <td>-0.124608</td>\n",
              "      <td>[1]</td>\n",
              "      <td>535.0</td>\n",
              "      <td>fr</td>\n",
              "      <td>1</td>\n",
              "      <td>7636.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1930757</td>\n",
              "      <td>Patriarch Estate Grown</td>\n",
              "      <td>1072</td>\n",
              "      <td>4.6</td>\n",
              "      <td>6042</td>\n",
              "      <td>25</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>7747.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>49362.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.994470</td>\n",
              "      <td>3.356056</td>\n",
              "      <td>-0.923651</td>\n",
              "      <td>0.741282</td>\n",
              "      <td>2.596084</td>\n",
              "      <td>7.155602</td>\n",
              "      <td>-1.910814</td>\n",
              "      <td>-3.998637</td>\n",
              "      <td>-0.054258</td>\n",
              "      <td>0.587277</td>\n",
              "      <td>-0.887633</td>\n",
              "      <td>-0.478954</td>\n",
              "      <td>-0.442926</td>\n",
              "      <td>-1.749812</td>\n",
              "      <td>-1.185678</td>\n",
              "      <td>-0.141588</td>\n",
              "      <td>0.728802</td>\n",
              "      <td>-1.242658</td>\n",
              "      <td>0.493817</td>\n",
              "      <td>-1.872077</td>\n",
              "      <td>-2.067729</td>\n",
              "      <td>-3.043356</td>\n",
              "      <td>0.165190</td>\n",
              "      <td>0.615640</td>\n",
              "      <td>-0.657080</td>\n",
              "      <td>0.566004</td>\n",
              "      <td>0.658332</td>\n",
              "      <td>-0.343338</td>\n",
              "      <td>-1.285816</td>\n",
              "      <td>0.543290</td>\n",
              "      <td>-0.569400</td>\n",
              "      <td>1.647680</td>\n",
              "      <td>-1.445715</td>\n",
              "      <td>-0.359417</td>\n",
              "      <td>[2, 10]</td>\n",
              "      <td>88.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>1905.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1564280</td>\n",
              "      <td>Merlot</td>\n",
              "      <td>3577</td>\n",
              "      <td>4.3</td>\n",
              "      <td>18748</td>\n",
              "      <td>52</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>14091.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>83324.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.055126</td>\n",
              "      <td>-6.163670</td>\n",
              "      <td>-17.412258</td>\n",
              "      <td>3.399827</td>\n",
              "      <td>0.748214</td>\n",
              "      <td>17.899010</td>\n",
              "      <td>-2.046424</td>\n",
              "      <td>-11.186761</td>\n",
              "      <td>12.007775</td>\n",
              "      <td>0.894301</td>\n",
              "      <td>5.050331</td>\n",
              "      <td>-2.478301</td>\n",
              "      <td>8.826864</td>\n",
              "      <td>7.167604</td>\n",
              "      <td>-6.359656</td>\n",
              "      <td>-1.473321</td>\n",
              "      <td>-3.462038</td>\n",
              "      <td>4.614712</td>\n",
              "      <td>-0.875028</td>\n",
              "      <td>-7.256990</td>\n",
              "      <td>-2.221329</td>\n",
              "      <td>-6.283630</td>\n",
              "      <td>-0.477432</td>\n",
              "      <td>0.779232</td>\n",
              "      <td>2.592272</td>\n",
              "      <td>-0.271975</td>\n",
              "      <td>1.884531</td>\n",
              "      <td>0.176404</td>\n",
              "      <td>4.579372</td>\n",
              "      <td>1.793655</td>\n",
              "      <td>-4.051642</td>\n",
              "      <td>3.926317</td>\n",
              "      <td>-2.261881</td>\n",
              "      <td>-0.431446</td>\n",
              "      <td>[10]</td>\n",
              "      <td>24.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576427</td>\n",
              "      <td>Cabernet Sauvignon F Block</td>\n",
              "      <td>115</td>\n",
              "      <td>4.4</td>\n",
              "      <td>806</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>7749.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>-0.478264</td>\n",
              "      <td>-1.010209</td>\n",
              "      <td>-0.003157</td>\n",
              "      <td>0.367176</td>\n",
              "      <td>-0.270334</td>\n",
              "      <td>-0.550214</td>\n",
              "      <td>0.490301</td>\n",
              "      <td>-0.315579</td>\n",
              "      <td>0.299809</td>\n",
              "      <td>-0.471115</td>\n",
              "      <td>-0.199453</td>\n",
              "      <td>-0.326484</td>\n",
              "      <td>-0.776345</td>\n",
              "      <td>-0.717146</td>\n",
              "      <td>0.147173</td>\n",
              "      <td>0.347295</td>\n",
              "      <td>-0.071307</td>\n",
              "      <td>0.385532</td>\n",
              "      <td>-0.230784</td>\n",
              "      <td>0.216109</td>\n",
              "      <td>0.222512</td>\n",
              "      <td>-0.104980</td>\n",
              "      <td>-0.133218</td>\n",
              "      <td>-0.016644</td>\n",
              "      <td>-0.063100</td>\n",
              "      <td>-0.098678</td>\n",
              "      <td>0.082621</td>\n",
              "      <td>0.164888</td>\n",
              "      <td>-0.078193</td>\n",
              "      <td>0.113466</td>\n",
              "      <td>0.270745</td>\n",
              "      <td>0.158934</td>\n",
              "      <td>-0.330067</td>\n",
              "      <td>[2]</td>\n",
              "      <td>42.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>2232.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wine_id                        name  ...  winery_id  segment\n",
              "0  1938520     1882 Cabernet Sauvignon  ...     2412.0        2\n",
              "1    14604      Les Bessards Hermitage  ...     7636.0        2\n",
              "2  1930757      Patriarch Estate Grown  ...     1905.0        2\n",
              "3  1564280                      Merlot  ...     1297.0        2\n",
              "4  2576427  Cabernet Sauvignon F Block  ...     2232.0        2\n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JjrbiN5uZ2S"
      },
      "source": [
        "# 1. Data Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXe-6WSvuPso"
      },
      "source": [
        "train = train[['userID', 'wine_id', 'rating_per_user', 'like']]\n",
        "test = test[['userID', 'wine_id', 'rating_per_user', 'like']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "SO8ZFdsGvUMr",
        "outputId": "f81a36b7-97e6-46a4-9b66-0c31fd45ccdb"
      },
      "source": [
        "selected_item = item[[\n",
        "      'wine_id',\n",
        "      'rating_count',\n",
        "      'rating_average',\n",
        "      'review_count',\n",
        "      'label_count',\n",
        "      'body',\n",
        "      'acidity_y',\n",
        "      'alcohol',\n",
        "      'type_id',\n",
        "      'grapes_id',\n",
        "      'country_code',\n",
        "      'region_id',\n",
        "      'segment'\n",
        "]]\n",
        "\n",
        "selected_item"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1938520</td>\n",
              "      <td>1697</td>\n",
              "      <td>4.1</td>\n",
              "      <td>16</td>\n",
              "      <td>14879</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.485010</td>\n",
              "      <td>14.5</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>105.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14604</td>\n",
              "      <td>1078</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3</td>\n",
              "      <td>5370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.429150</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>fr</td>\n",
              "      <td>535.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1930757</td>\n",
              "      <td>1072</td>\n",
              "      <td>4.6</td>\n",
              "      <td>25</td>\n",
              "      <td>6042</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.851015</td>\n",
              "      <td>14.2</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 10]</td>\n",
              "      <td>us</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1564280</td>\n",
              "      <td>3577</td>\n",
              "      <td>4.3</td>\n",
              "      <td>52</td>\n",
              "      <td>18748</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.775668</td>\n",
              "      <td>14.4</td>\n",
              "      <td>1</td>\n",
              "      <td>[10]</td>\n",
              "      <td>us</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576427</td>\n",
              "      <td>115</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1</td>\n",
              "      <td>806</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.511364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50855</th>\n",
              "      <td>1669561</td>\n",
              "      <td>788</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9</td>\n",
              "      <td>6635</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.212859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[104, 34]</td>\n",
              "      <td>it</td>\n",
              "      <td>983.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50856</th>\n",
              "      <td>1861275</td>\n",
              "      <td>231</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6</td>\n",
              "      <td>961</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.072673</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[5]</td>\n",
              "      <td>it</td>\n",
              "      <td>613.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50857</th>\n",
              "      <td>2201892</td>\n",
              "      <td>390</td>\n",
              "      <td>3.9</td>\n",
              "      <td>14</td>\n",
              "      <td>1983</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.982507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[112]</td>\n",
              "      <td>it</td>\n",
              "      <td>3232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50858</th>\n",
              "      <td>2396179</td>\n",
              "      <td>302</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4</td>\n",
              "      <td>730</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.061171</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[17]</td>\n",
              "      <td>fr</td>\n",
              "      <td>635.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50859</th>\n",
              "      <td>7715684</td>\n",
              "      <td>82</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4</td>\n",
              "      <td>483</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.560714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[88]</td>\n",
              "      <td>es</td>\n",
              "      <td>1687.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50860 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       wine_id  rating_count  rating_average  ...  country_code  region_id  segment\n",
              "0      1938520          1697             4.1  ...            us      105.0        2\n",
              "1        14604          1078             4.3  ...            fr      535.0        2\n",
              "2      1930757          1072             4.6  ...            us       88.0        2\n",
              "3      1564280          3577             4.3  ...            us       24.0        2\n",
              "4      2576427           115             4.4  ...            us       42.0        2\n",
              "...        ...           ...             ...  ...           ...        ...      ...\n",
              "50855  1669561           788             3.5  ...            it      983.0        1\n",
              "50856  1861275           231             3.8  ...            it      613.0        1\n",
              "50857  2201892           390             3.9  ...            it     3232.0        1\n",
              "50858  2396179           302             4.2  ...            fr      635.0        3\n",
              "50859  7715684            82             4.1  ...            es     1687.0        2\n",
              "\n",
              "[50860 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnnQu07OGSV_"
      },
      "source": [
        "train.loc[train['wine_id'] == 1886805, 'wine_id'] = 1183966\n",
        "test.loc[test['wine_id'] == 1886805, 'wine_id'] = 1183966"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "ROxPukdYutjk",
        "outputId": "f6bead17-3588-4123-b6f1-4e6a3fb51b5e"
      },
      "source": [
        "add_train = train.merge(selected_item, on = 'wine_id', how = 'left')\n",
        "add_test = test.merge(selected_item, on = 'wine_id', how = 'left')\n",
        "\n",
        "add_train"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>like</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763382</th>\n",
              "      <td>11274168</td>\n",
              "      <td>87064</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1379</td>\n",
              "      <td>3.8</td>\n",
              "      <td>37</td>\n",
              "      <td>5851</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.045876</td>\n",
              "      <td>12.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[49]</td>\n",
              "      <td>es</td>\n",
              "      <td>766.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763383</th>\n",
              "      <td>11274168</td>\n",
              "      <td>63654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9222</td>\n",
              "      <td>3.9</td>\n",
              "      <td>178</td>\n",
              "      <td>37914</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.339126</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[7]</td>\n",
              "      <td>fr</td>\n",
              "      <td>387.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763384</th>\n",
              "      <td>11274168</td>\n",
              "      <td>5602</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>23457</td>\n",
              "      <td>4.4</td>\n",
              "      <td>865</td>\n",
              "      <td>133651</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.695950</td>\n",
              "      <td>14.4</td>\n",
              "      <td>2</td>\n",
              "      <td>[5]</td>\n",
              "      <td>us</td>\n",
              "      <td>96.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763385</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1396664</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>374</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1</td>\n",
              "      <td>2032</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.493441</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763386</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1142712</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>21638</td>\n",
              "      <td>3.9</td>\n",
              "      <td>262</td>\n",
              "      <td>226514</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.891555</td>\n",
              "      <td>13.5</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>327.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>763387 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          userID  wine_id  rating_per_user  ...  country_code  region_id  segment\n",
              "0       19484511  1141133              4.0  ...            fr      409.0        3\n",
              "1         352674  1141133              4.0  ...            fr      409.0        3\n",
              "2       17786617  1141133              4.0  ...            fr      409.0        3\n",
              "3        8078038  1141133              4.5  ...            fr      409.0        3\n",
              "4        3014532  1141133              4.0  ...            fr      409.0        3\n",
              "...          ...      ...              ...  ...           ...        ...      ...\n",
              "763382  11274168    87064              3.0  ...            es      766.0        1\n",
              "763383  11274168    63654              4.0  ...            fr      387.0        3\n",
              "763384  11274168     5602              4.5  ...            us       96.0        3\n",
              "763385  11274168  1396664              3.0  ...            us       25.0        2\n",
              "763386  11274168  1142712              3.5  ...            us      327.0        2\n",
              "\n",
              "[763387 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPruvbalv3d-",
        "outputId": "50cfeae9-746f-4b36-91ac-02abbdb43f7f"
      },
      "source": [
        "add_train.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 763387 entries, 0 to 763386\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   userID           763387 non-null  int64  \n",
            " 1   wine_id          763387 non-null  int64  \n",
            " 2   rating_per_user  763387 non-null  float64\n",
            " 3   like             763387 non-null  int64  \n",
            " 4   rating_count     763387 non-null  int64  \n",
            " 5   rating_average   763387 non-null  float64\n",
            " 6   review_count     763387 non-null  int64  \n",
            " 7   label_count      763387 non-null  int64  \n",
            " 8   body             763387 non-null  float64\n",
            " 9   acidity_y        763387 non-null  float64\n",
            " 10  alcohol          763387 non-null  float64\n",
            " 11  type_id          763387 non-null  int64  \n",
            " 12  grapes_id        763387 non-null  object \n",
            " 13  country_code     763387 non-null  object \n",
            " 14  region_id        763387 non-null  float64\n",
            " 15  segment          763387 non-null  int64  \n",
            "dtypes: float64(6), int64(8), object(2)\n",
            "memory usage: 99.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77nxCbawHLW",
        "outputId": "16f73e28-2deb-4a8b-fd99-4149ac9330a4"
      },
      "source": [
        "add_train.isnull().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userID             0\n",
              "wine_id            0\n",
              "rating_per_user    0\n",
              "like               0\n",
              "rating_count       0\n",
              "rating_average     0\n",
              "review_count       0\n",
              "label_count        0\n",
              "body               0\n",
              "acidity_y          0\n",
              "alcohol            0\n",
              "type_id            0\n",
              "grapes_id          0\n",
              "country_code       0\n",
              "region_id          0\n",
              "segment            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DekllzMl0aPQ",
        "outputId": "308453ef-b9a3-49ff-9cd3-7c9629e06a29"
      },
      "source": [
        "add_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>like</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     userID  wine_id  rating_per_user  ...  country_code  region_id  segment\n",
              "0  19484511  1141133              4.0  ...            fr      409.0        3\n",
              "1    352674  1141133              4.0  ...            fr      409.0        3\n",
              "2  17786617  1141133              4.0  ...            fr      409.0        3\n",
              "3   8078038  1141133              4.5  ...            fr      409.0        3\n",
              "4   3014532  1141133              4.0  ...            fr      409.0        3\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfNyvKFlIqXQ"
      },
      "source": [
        "# 2. Data Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHFuIMPLlZnR",
        "outputId": "3b9c1a66-c32e-4eac-864d-b2b5d3bfb12d"
      },
      "source": [
        "add_train.columns, len(add_train.columns)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Index(['userID', 'wine_id', 'rating_per_user', 'like', 'rating_count',\n",
              "        'rating_average', 'review_count', 'label_count', 'body', 'acidity_y',\n",
              "        'alcohol', 'type_id', 'grapes_id', 'country_code', 'region_id',\n",
              "        'segment'],\n",
              "       dtype='object'), 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-s4mY6oGpme",
        "outputId": "79258c34-9503-4e0f-c998-b29d14cf1425"
      },
      "source": [
        "str_features = ['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment']\n",
        "int_features = ['rating_count', 'rating_average', 'review_count', 'label_count', 'body', 'acidity_y', 'alcohol']\n",
        "label_feature = ['like']\n",
        "feature_names = str_features + int_features + label_feature\n",
        "feature_names"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['userID',\n",
              " 'wine_id',\n",
              " 'type_id',\n",
              " 'grapes_id',\n",
              " 'country_code',\n",
              " 'region_id',\n",
              " 'segment',\n",
              " 'rating_count',\n",
              " 'rating_average',\n",
              " 'review_count',\n",
              " 'label_count',\n",
              " 'body',\n",
              " 'acidity_y',\n",
              " 'alcohol',\n",
              " 'like']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGHHfKEQA5tP",
        "outputId": "e8cfcf09-5129-407b-ddf3-9e9f017566cb"
      },
      "source": [
        "import DCN\n",
        "import imp\n",
        "imp.reload(DCN)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'DCN' from '/content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN/DCN.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OhEbINhabEX",
        "outputId": "46e3ae7e-db64-490f-9d6a-0676790be664"
      },
      "source": [
        "cached_train, vocabularies = DCN.preprocessing(add_train, str_features, int_features, df_type = 'train')\n",
        "cached_test = DCN.preprocessing(add_test, str_features, int_features, df_type = 'test')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [01:39<00:00,  7.09s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_DjpVawg5ZE",
        "outputId": "1b1921e1-9fe7-45b6-f4ab-f239e18ceadb"
      },
      "source": [
        "vocabularies"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acidity_y': array([ 0,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "        26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
              "        43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
              "        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75]),\n",
              " 'alcohol': array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "         14,  15,  16,  17,  18,  19,  20,  21,  23,  45,  80, 112, 114,\n",
              "        135]),\n",
              " 'body': array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
              " 'country_code': array([b'al', b'am', b'ar', b'at', b'au', b'be', b'bg', b'bo', b'br',\n",
              "        b'ca', b'ch', b'cl', b'cn', b'cy', b'cz', b'de', b'dk', b'es',\n",
              "        b'fr', b'gb', b'ge', b'gr', b'hr', b'hu', b'il', b'in', b'it',\n",
              "        b'jp', b'lb', b'lu', b'ma', b'md', b'me', b'mk', b'mt', b'mx',\n",
              "        b'nl', b'nz', b'pe', b'ps', b'pt', b'ro', b'rs', b'ru', b'se',\n",
              "        b'si', b'sk', b'th', b'tn', b'tr', b'ua', b'unk', b'us', b'uy',\n",
              "        b'za'], dtype=object),\n",
              " 'grapes_id': array([b'0', b'1', b'10', b'100', b'1005', b'1006', b'101', b'1011',\n",
              "        b'1015', b'1019', b'102', b'103', b'1030', b'1031', b'1032',\n",
              "        b'1033', b'1034', b'1037', b'1039', b'104', b'1042', b'1044',\n",
              "        b'1046', b'105', b'106', b'1072', b'1074', b'1076', b'1078',\n",
              "        b'108', b'1084', b'109', b'1098', b'11', b'110', b'1101', b'1106',\n",
              "        b'111', b'1116', b'112', b'1121', b'1122', b'1127', b'1132',\n",
              "        b'1136', b'114', b'115', b'1153', b'1154', b'1155', b'1156',\n",
              "        b'1157', b'116', b'117', b'1173', b'1175', b'1176', b'1178',\n",
              "        b'118', b'1180', b'1185', b'119', b'1197', b'1198', b'1199', b'12',\n",
              "        b'120', b'1201', b'122', b'1222', b'1229', b'123', b'1232',\n",
              "        b'1237', b'124', b'1242', b'1250', b'1255', b'1258', b'1261',\n",
              "        b'1262', b'1265', b'1266', b'1269', b'127', b'128', b'1281',\n",
              "        b'1282', b'1285', b'129', b'1291', b'1298', b'13', b'130', b'1307',\n",
              "        b'131', b'132', b'1320', b'1333', b'1336', b'1338', b'1349',\n",
              "        b'135', b'1350', b'1353', b'136', b'1364', b'1365', b'1367',\n",
              "        b'1368', b'137', b'1372', b'1374', b'138', b'1384', b'1394', b'14',\n",
              "        b'140', b'141', b'1419', b'142', b'1421', b'1423', b'1427', b'143',\n",
              "        b'144', b'1446', b'145', b'1466', b'147', b'1472', b'148', b'1489',\n",
              "        b'149', b'1495', b'1497', b'15', b'150', b'151', b'1519', b'152',\n",
              "        b'1529', b'153', b'1530', b'1536', b'1543', b'1544', b'155',\n",
              "        b'1551', b'1555', b'156', b'1566', b'157', b'1578', b'158',\n",
              "        b'1587', b'1589', b'159', b'1594', b'1595', b'1596', b'1599',\n",
              "        b'16', b'1602', b'1607', b'161', b'162', b'1621', b'1623', b'1628',\n",
              "        b'1630', b'1632', b'1635', b'1639', b'1645', b'165', b'1657',\n",
              "        b'166', b'1665', b'1666', b'1668', b'167', b'1670', b'1672',\n",
              "        b'1675', b'1677', b'1678', b'168', b'1680', b'1687', b'1688',\n",
              "        b'169', b'1692', b'1697', b'1699', b'17', b'170', b'1701', b'171',\n",
              "        b'1710', b'1715', b'1716', b'1718', b'1719', b'172', b'1721',\n",
              "        b'173', b'1730', b'1732', b'1733', b'1738', b'1739', b'174',\n",
              "        b'175', b'176', b'177', b'178', b'179', b'18', b'180', b'184',\n",
              "        b'186', b'19', b'190', b'191', b'192', b'194', b'196', b'197',\n",
              "        b'198', b'199', b'2', b'20', b'200', b'202', b'204', b'206',\n",
              "        b'208', b'209', b'21', b'210', b'211', b'212', b'215', b'216',\n",
              "        b'218', b'219', b'22', b'221', b'222', b'224', b'225', b'226',\n",
              "        b'228', b'23', b'230', b'231', b'232', b'233', b'235', b'236',\n",
              "        b'237', b'239', b'24', b'240', b'241', b'242', b'243', b'245',\n",
              "        b'246', b'248', b'25', b'250', b'251', b'252', b'254', b'255',\n",
              "        b'256', b'257', b'259', b'260', b'261', b'262', b'263', b'264',\n",
              "        b'265', b'267', b'268', b'27', b'270', b'271', b'273', b'274',\n",
              "        b'275', b'279', b'28', b'280', b'282', b'283', b'284', b'286',\n",
              "        b'289', b'29', b'290', b'291', b'292', b'293', b'294', b'295',\n",
              "        b'297', b'298', b'299', b'3', b'300', b'302', b'303', b'304',\n",
              "        b'307', b'308', b'309', b'31', b'310', b'311', b'312', b'314',\n",
              "        b'315', b'316', b'317', b'318', b'32', b'320', b'321', b'322',\n",
              "        b'324', b'325', b'326', b'327', b'328', b'329', b'33', b'331',\n",
              "        b'334', b'335', b'336', b'337', b'338', b'339', b'34', b'340',\n",
              "        b'341', b'342', b'343', b'344', b'346', b'347', b'348', b'349',\n",
              "        b'35', b'350', b'351', b'352', b'353', b'354', b'355', b'356',\n",
              "        b'358', b'359', b'36', b'363', b'365', b'366', b'367', b'368',\n",
              "        b'37', b'370', b'374', b'377', b'38', b'381', b'382', b'383',\n",
              "        b'385', b'386', b'387', b'388', b'389', b'39', b'390', b'394',\n",
              "        b'40', b'404', b'41', b'414', b'42', b'43', b'434', b'44', b'444',\n",
              "        b'45', b'454', b'46', b'464', b'47', b'474', b'48', b'49', b'494',\n",
              "        b'5', b'50', b'504', b'51', b'514', b'52', b'524', b'53', b'534',\n",
              "        b'54', b'545', b'546', b'547', b'548', b'55', b'550', b'551',\n",
              "        b'552', b'553', b'556', b'557', b'56', b'562', b'563', b'564',\n",
              "        b'565', b'566', b'567', b'57', b'572', b'573', b'576', b'577',\n",
              "        b'579', b'58', b'580', b'583', b'584', b'585', b'586', b'588',\n",
              "        b'589', b'59', b'590', b'592', b'594', b'595', b'596', b'597',\n",
              "        b'598', b'599', b'6', b'601', b'602', b'603', b'604', b'605',\n",
              "        b'608', b'609', b'61', b'610', b'611', b'614', b'616', b'617',\n",
              "        b'619', b'62', b'620', b'624', b'625', b'627', b'628', b'63',\n",
              "        b'630', b'632', b'633', b'634', b'635', b'636', b'64', b'642',\n",
              "        b'643', b'646', b'648', b'65', b'653', b'656', b'658', b'66',\n",
              "        b'661', b'662', b'663', b'664', b'665', b'666', b'669', b'67',\n",
              "        b'671', b'673', b'674', b'675', b'677', b'678', b'679', b'68',\n",
              "        b'682', b'69', b'698', b'7', b'70', b'702', b'708', b'71', b'714',\n",
              "        b'715', b'72', b'725', b'732', b'733', b'734', b'74', b'741',\n",
              "        b'75', b'750', b'76', b'760', b'769', b'77', b'773', b'774', b'78',\n",
              "        b'780', b'785', b'793', b'795', b'8', b'80', b'803', b'808', b'81',\n",
              "        b'82', b'83', b'839', b'847', b'85', b'852', b'856', b'86', b'88',\n",
              "        b'883', b'885', b'887', b'888', b'89', b'895', b'898', b'899',\n",
              "        b'9', b'906', b'91', b'910', b'913', b'915', b'92', b'927', b'93',\n",
              "        b'938', b'94', b'947', b'949', b'950', b'951', b'957', b'96',\n",
              "        b'964', b'966', b'97', b'973', b'975', b'978', b'98', b'99'],\n",
              "       dtype=object),\n",
              " 'label_count': array([      9,      19,      23, ...,  999982, 1097345, 1137754]),\n",
              " 'rating_average': array([ 0, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
              "        40, 41, 42, 43, 44, 45, 46, 47, 48]),\n",
              " 'rating_count': array([     4,      6,      9, ..., 122634, 123375, 148911]),\n",
              " 'region_id': array([b'0', b'100', b'1034', ..., b'99', b'992', b'996'], dtype=object),\n",
              " 'review_count': array([    0,     1,     2, ..., 16540, 21005, 22865]),\n",
              " 'segment': array([b'0', b'1', b'2', b'3'], dtype=object),\n",
              " 'type_id': array([b'1', b'2', b'24', b'25', b'3', b'4', b'7'], dtype=object),\n",
              " 'userID': array([b'10001895', b'10003665', b'10006310', ..., b'9990646', b'9993784',\n",
              "        b'9993829'], dtype=object),\n",
              " 'wine_id': array([b'10', b'10000', b'100002', ..., b'99984', b'99986', b'99988'],\n",
              "       dtype=object)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1FLMJP7hIxw"
      },
      "source": [
        "import pickle\n",
        "with open('vocabularies.pickle','wb') as f:\n",
        "    pickle.dump(vocabularies, f)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn1j7dRrIyEe"
      },
      "source": [
        "# 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCdDXv220t1N"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "class MaskedEmbeddingsAggregatorLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, agg_mode='sum', **kwargs):\n",
        "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
        "\n",
        "        if agg_mode not in ['sum', 'mean']:\n",
        "            raise NotImplementedError('mode {} not implemented!'.format(agg_mode))\n",
        "        self.agg_mode = agg_mode\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, mask=None):\n",
        "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
        "        if self.agg_mode == 'sum':\n",
        "            aggregated =  tf.reduce_sum(masked_embeddings, axis=1)\n",
        "        elif self.agg_mode == 'mean':\n",
        "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
        "        \n",
        "        return aggregated\n",
        "    \n",
        "    def get_config(self):\n",
        "        # this is used when loading a saved model that uses a custom layer\n",
        "        return {'agg_mode': self.agg_mode}\n",
        "\n",
        "\n",
        "class L2NormLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(L2NormLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
        "        return tf.math.l2_normalize(inputs, axis=-1)\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return mask\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uikNZ3VyJSis"
      },
      "source": [
        "learning_rate = 0.001\n",
        "model = DCN.model(use_cross_layer = True,\n",
        "            deep_layer_sizes = [512, 256, 128, 64],\n",
        "            learning_rate = learning_rate,\n",
        "            str_features = str_features,\n",
        "            int_features = int_features,\n",
        "            vocabularies = vocabularies,\n",
        "            projection_dim = None,\n",
        "            metric = 'binary'\n",
        "            )\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate))"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAdCJ3j6Jdpf"
      },
      "source": [
        "# 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1fBus_2VWwA"
      },
      "source": [
        "import keras\n",
        "callbacks_list = [\n",
        "                  keras.callbacks.EarlyStopping(\n",
        "                      monitor = 'binary_accuracy',\n",
        "                      patience = 20\n",
        "                      )]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3L_YebbQ92b",
        "outputId": "125876c1-d7c1-4feb-8579-6534cf65a6df"
      },
      "source": [
        "history = model.fit(cached_train,\n",
        "                     epochs = 500,\n",
        "                     callbacks = callbacks_list,\n",
        "                     verbose = True)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "94/94 [==============================] - 11s 102ms/step - binary_accuracy: 0.6720 - loss: 0.6000 - regularization_loss: 0.0000e+00 - total_loss: 0.6000\n",
            "Epoch 2/500\n",
            "94/94 [==============================] - 10s 104ms/step - binary_accuracy: 0.7376 - loss: 0.5240 - regularization_loss: 0.0000e+00 - total_loss: 0.5240\n",
            "Epoch 3/500\n",
            "94/94 [==============================] - 10s 104ms/step - binary_accuracy: 0.7656 - loss: 0.4760 - regularization_loss: 0.0000e+00 - total_loss: 0.4760\n",
            "Epoch 4/500\n",
            "94/94 [==============================] - 10s 102ms/step - binary_accuracy: 0.7790 - loss: 0.4481 - regularization_loss: 0.0000e+00 - total_loss: 0.4481\n",
            "Epoch 5/500\n",
            "94/94 [==============================] - 10s 101ms/step - binary_accuracy: 0.7868 - loss: 0.4294 - regularization_loss: 0.0000e+00 - total_loss: 0.4294\n",
            "Epoch 6/500\n",
            "94/94 [==============================] - 10s 102ms/step - binary_accuracy: 0.7930 - loss: 0.4158 - regularization_loss: 0.0000e+00 - total_loss: 0.4158\n",
            "Epoch 7/500\n",
            "94/94 [==============================] - 10s 101ms/step - binary_accuracy: 0.7951 - loss: 0.4094 - regularization_loss: 0.0000e+00 - total_loss: 0.4094\n",
            "Epoch 8/500\n",
            "94/94 [==============================] - 9s 101ms/step - binary_accuracy: 0.7921 - loss: 0.4112 - regularization_loss: 0.0000e+00 - total_loss: 0.4112\n",
            "Epoch 9/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.7835 - loss: 0.4251 - regularization_loss: 0.0000e+00 - total_loss: 0.4251\n",
            "Epoch 10/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.7921 - loss: 0.4061 - regularization_loss: 0.0000e+00 - total_loss: 0.4061\n",
            "Epoch 11/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.7987 - loss: 0.3941 - regularization_loss: 0.0000e+00 - total_loss: 0.3941\n",
            "Epoch 12/500\n",
            "94/94 [==============================] - 9s 101ms/step - binary_accuracy: 0.8017 - loss: 0.3866 - regularization_loss: 0.0000e+00 - total_loss: 0.3866\n",
            "Epoch 13/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.8032 - loss: 0.3846 - regularization_loss: 0.0000e+00 - total_loss: 0.3846\n",
            "Epoch 14/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.7987 - loss: 0.3868 - regularization_loss: 0.0000e+00 - total_loss: 0.3868\n",
            "Epoch 15/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.8069 - loss: 0.3720 - regularization_loss: 0.0000e+00 - total_loss: 0.3720\n",
            "Epoch 16/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.8119 - loss: 0.3616 - regularization_loss: 0.0000e+00 - total_loss: 0.3616\n",
            "Epoch 17/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.8320 - loss: 0.3260 - regularization_loss: 0.0000e+00 - total_loss: 0.3260\n",
            "Epoch 18/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.8524 - loss: 0.2884 - regularization_loss: 0.0000e+00 - total_loss: 0.2884\n",
            "Epoch 19/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.8617 - loss: 0.2679 - regularization_loss: 0.0000e+00 - total_loss: 0.2679\n",
            "Epoch 20/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.8748 - loss: 0.2554 - regularization_loss: 0.0000e+00 - total_loss: 0.2554\n",
            "Epoch 21/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.8865 - loss: 0.2234 - regularization_loss: 0.0000e+00 - total_loss: 0.2234\n",
            "Epoch 22/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9012 - loss: 0.1935 - regularization_loss: 0.0000e+00 - total_loss: 0.1935\n",
            "Epoch 23/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9153 - loss: 0.1643 - regularization_loss: 0.0000e+00 - total_loss: 0.1643\n",
            "Epoch 24/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9259 - loss: 0.1442 - regularization_loss: 0.0000e+00 - total_loss: 0.1442\n",
            "Epoch 25/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9348 - loss: 0.1241 - regularization_loss: 0.0000e+00 - total_loss: 0.1241\n",
            "Epoch 26/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9426 - loss: 0.1090 - regularization_loss: 0.0000e+00 - total_loss: 0.1090\n",
            "Epoch 27/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9477 - loss: 0.0980 - regularization_loss: 0.0000e+00 - total_loss: 0.0980\n",
            "Epoch 28/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9524 - loss: 0.0870 - regularization_loss: 0.0000e+00 - total_loss: 0.0870\n",
            "Epoch 29/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9552 - loss: 0.0793 - regularization_loss: 0.0000e+00 - total_loss: 0.0793\n",
            "Epoch 30/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9577 - loss: 0.0733 - regularization_loss: 0.0000e+00 - total_loss: 0.0733\n",
            "Epoch 31/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9597 - loss: 0.0682 - regularization_loss: 0.0000e+00 - total_loss: 0.0682\n",
            "Epoch 32/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9613 - loss: 0.0639 - regularization_loss: 0.0000e+00 - total_loss: 0.0639\n",
            "Epoch 33/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9625 - loss: 0.0611 - regularization_loss: 0.0000e+00 - total_loss: 0.0611\n",
            "Epoch 34/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9647 - loss: 0.0590 - regularization_loss: 0.0000e+00 - total_loss: 0.0590\n",
            "Epoch 35/500\n",
            "94/94 [==============================] - 9s 101ms/step - binary_accuracy: 0.9656 - loss: 0.0575 - regularization_loss: 0.0000e+00 - total_loss: 0.0575\n",
            "Epoch 36/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9666 - loss: 0.0562 - regularization_loss: 0.0000e+00 - total_loss: 0.0562\n",
            "Epoch 37/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9677 - loss: 0.0541 - regularization_loss: 0.0000e+00 - total_loss: 0.0541\n",
            "Epoch 38/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9686 - loss: 0.0524 - regularization_loss: 0.0000e+00 - total_loss: 0.0524\n",
            "Epoch 39/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9696 - loss: 0.0511 - regularization_loss: 0.0000e+00 - total_loss: 0.0511\n",
            "Epoch 40/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9706 - loss: 0.0499 - regularization_loss: 0.0000e+00 - total_loss: 0.0499\n",
            "Epoch 41/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9713 - loss: 0.0488 - regularization_loss: 0.0000e+00 - total_loss: 0.0488\n",
            "Epoch 42/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9720 - loss: 0.0487 - regularization_loss: 0.0000e+00 - total_loss: 0.0487\n",
            "Epoch 43/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9725 - loss: 0.0480 - regularization_loss: 0.0000e+00 - total_loss: 0.0480\n",
            "Epoch 44/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9731 - loss: 0.0469 - regularization_loss: 0.0000e+00 - total_loss: 0.0469\n",
            "Epoch 45/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9734 - loss: 0.0461 - regularization_loss: 0.0000e+00 - total_loss: 0.0461\n",
            "Epoch 46/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9740 - loss: 0.0457 - regularization_loss: 0.0000e+00 - total_loss: 0.0457\n",
            "Epoch 47/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9743 - loss: 0.0450 - regularization_loss: 0.0000e+00 - total_loss: 0.0450\n",
            "Epoch 48/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9743 - loss: 0.0450 - regularization_loss: 0.0000e+00 - total_loss: 0.0450\n",
            "Epoch 49/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9745 - loss: 0.0444 - regularization_loss: 0.0000e+00 - total_loss: 0.0444\n",
            "Epoch 50/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9745 - loss: 0.0441 - regularization_loss: 0.0000e+00 - total_loss: 0.0441\n",
            "Epoch 51/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9748 - loss: 0.0430 - regularization_loss: 0.0000e+00 - total_loss: 0.0430\n",
            "Epoch 52/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9751 - loss: 0.0427 - regularization_loss: 0.0000e+00 - total_loss: 0.0427\n",
            "Epoch 53/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9754 - loss: 0.0428 - regularization_loss: 0.0000e+00 - total_loss: 0.0428\n",
            "Epoch 54/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9757 - loss: 0.0429 - regularization_loss: 0.0000e+00 - total_loss: 0.0429\n",
            "Epoch 55/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9757 - loss: 0.0431 - regularization_loss: 0.0000e+00 - total_loss: 0.0431\n",
            "Epoch 56/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9756 - loss: 0.0422 - regularization_loss: 0.0000e+00 - total_loss: 0.0422\n",
            "Epoch 57/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9759 - loss: 0.0412 - regularization_loss: 0.0000e+00 - total_loss: 0.0412\n",
            "Epoch 58/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9762 - loss: 0.0408 - regularization_loss: 0.0000e+00 - total_loss: 0.0408\n",
            "Epoch 59/500\n",
            "94/94 [==============================] - 9s 96ms/step - binary_accuracy: 0.9765 - loss: 0.0404 - regularization_loss: 0.0000e+00 - total_loss: 0.0404\n",
            "Epoch 60/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9769 - loss: 0.0399 - regularization_loss: 0.0000e+00 - total_loss: 0.0399\n",
            "Epoch 61/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9766 - loss: 0.0398 - regularization_loss: 0.0000e+00 - total_loss: 0.0398\n",
            "Epoch 62/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9769 - loss: 0.0390 - regularization_loss: 0.0000e+00 - total_loss: 0.0390\n",
            "Epoch 63/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9770 - loss: 0.0391 - regularization_loss: 0.0000e+00 - total_loss: 0.0391\n",
            "Epoch 64/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9771 - loss: 0.0373 - regularization_loss: 0.0000e+00 - total_loss: 0.0373\n",
            "Epoch 65/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9774 - loss: 0.0370 - regularization_loss: 0.0000e+00 - total_loss: 0.0370\n",
            "Epoch 66/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9776 - loss: 0.0369 - regularization_loss: 0.0000e+00 - total_loss: 0.0369\n",
            "Epoch 67/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9777 - loss: 0.0364 - regularization_loss: 0.0000e+00 - total_loss: 0.0364\n",
            "Epoch 68/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9777 - loss: 0.0361 - regularization_loss: 0.0000e+00 - total_loss: 0.0361\n",
            "Epoch 69/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9780 - loss: 0.0359 - regularization_loss: 0.0000e+00 - total_loss: 0.0359\n",
            "Epoch 70/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9780 - loss: 0.0354 - regularization_loss: 0.0000e+00 - total_loss: 0.0354\n",
            "Epoch 71/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9781 - loss: 0.0353 - regularization_loss: 0.0000e+00 - total_loss: 0.0353\n",
            "Epoch 72/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9781 - loss: 0.0356 - regularization_loss: 0.0000e+00 - total_loss: 0.0356\n",
            "Epoch 73/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9781 - loss: 0.0356 - regularization_loss: 0.0000e+00 - total_loss: 0.0356\n",
            "Epoch 74/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9780 - loss: 0.0354 - regularization_loss: 0.0000e+00 - total_loss: 0.0354\n",
            "Epoch 75/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9780 - loss: 0.0356 - regularization_loss: 0.0000e+00 - total_loss: 0.0356\n",
            "Epoch 76/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9778 - loss: 0.0362 - regularization_loss: 0.0000e+00 - total_loss: 0.0362\n",
            "Epoch 77/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9781 - loss: 0.0358 - regularization_loss: 0.0000e+00 - total_loss: 0.0358\n",
            "Epoch 78/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9781 - loss: 0.0352 - regularization_loss: 0.0000e+00 - total_loss: 0.0352\n",
            "Epoch 79/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9781 - loss: 0.0349 - regularization_loss: 0.0000e+00 - total_loss: 0.0349\n",
            "Epoch 80/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9783 - loss: 0.0346 - regularization_loss: 0.0000e+00 - total_loss: 0.0346\n",
            "Epoch 81/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9786 - loss: 0.0342 - regularization_loss: 0.0000e+00 - total_loss: 0.0342\n",
            "Epoch 82/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9786 - loss: 0.0338 - regularization_loss: 0.0000e+00 - total_loss: 0.0338\n",
            "Epoch 83/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9786 - loss: 0.0339 - regularization_loss: 0.0000e+00 - total_loss: 0.0339\n",
            "Epoch 84/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9785 - loss: 0.0337 - regularization_loss: 0.0000e+00 - total_loss: 0.0337\n",
            "Epoch 85/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9787 - loss: 0.0331 - regularization_loss: 0.0000e+00 - total_loss: 0.0331\n",
            "Epoch 86/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9789 - loss: 0.0331 - regularization_loss: 0.0000e+00 - total_loss: 0.0331\n",
            "Epoch 87/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9789 - loss: 0.0329 - regularization_loss: 0.0000e+00 - total_loss: 0.0329\n",
            "Epoch 88/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9790 - loss: 0.0329 - regularization_loss: 0.0000e+00 - total_loss: 0.0329\n",
            "Epoch 89/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9790 - loss: 0.0327 - regularization_loss: 0.0000e+00 - total_loss: 0.0327\n",
            "Epoch 90/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9791 - loss: 0.0329 - regularization_loss: 0.0000e+00 - total_loss: 0.0329\n",
            "Epoch 91/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9789 - loss: 0.0329 - regularization_loss: 0.0000e+00 - total_loss: 0.0329\n",
            "Epoch 92/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9789 - loss: 0.0331 - regularization_loss: 0.0000e+00 - total_loss: 0.0331\n",
            "Epoch 93/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9790 - loss: 0.0327 - regularization_loss: 0.0000e+00 - total_loss: 0.0327\n",
            "Epoch 94/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9790 - loss: 0.0328 - regularization_loss: 0.0000e+00 - total_loss: 0.0328\n",
            "Epoch 95/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9790 - loss: 0.0328 - regularization_loss: 0.0000e+00 - total_loss: 0.0328\n",
            "Epoch 96/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9791 - loss: 0.0328 - regularization_loss: 0.0000e+00 - total_loss: 0.0328\n",
            "Epoch 97/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9792 - loss: 0.0326 - regularization_loss: 0.0000e+00 - total_loss: 0.0326\n",
            "Epoch 98/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9793 - loss: 0.0324 - regularization_loss: 0.0000e+00 - total_loss: 0.0324\n",
            "Epoch 99/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9793 - loss: 0.0326 - regularization_loss: 0.0000e+00 - total_loss: 0.0326\n",
            "Epoch 100/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9792 - loss: 0.0327 - regularization_loss: 0.0000e+00 - total_loss: 0.0327\n",
            "Epoch 101/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9793 - loss: 0.0330 - regularization_loss: 0.0000e+00 - total_loss: 0.0330\n",
            "Epoch 102/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9793 - loss: 0.0331 - regularization_loss: 0.0000e+00 - total_loss: 0.0331\n",
            "Epoch 103/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9793 - loss: 0.0333 - regularization_loss: 0.0000e+00 - total_loss: 0.0333\n",
            "Epoch 104/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9793 - loss: 0.0334 - regularization_loss: 0.0000e+00 - total_loss: 0.0334\n",
            "Epoch 105/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9792 - loss: 0.0336 - regularization_loss: 0.0000e+00 - total_loss: 0.0336\n",
            "Epoch 106/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9791 - loss: 0.0335 - regularization_loss: 0.0000e+00 - total_loss: 0.0335\n",
            "Epoch 107/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9792 - loss: 0.0334 - regularization_loss: 0.0000e+00 - total_loss: 0.0334\n",
            "Epoch 108/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9792 - loss: 0.0331 - regularization_loss: 0.0000e+00 - total_loss: 0.0331\n",
            "Epoch 109/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9792 - loss: 0.0330 - regularization_loss: 0.0000e+00 - total_loss: 0.0330\n",
            "Epoch 110/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9794 - loss: 0.0327 - regularization_loss: 0.0000e+00 - total_loss: 0.0327\n",
            "Epoch 111/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9795 - loss: 0.0323 - regularization_loss: 0.0000e+00 - total_loss: 0.0323\n",
            "Epoch 112/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9796 - loss: 0.0322 - regularization_loss: 0.0000e+00 - total_loss: 0.0322\n",
            "Epoch 113/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0320 - regularization_loss: 0.0000e+00 - total_loss: 0.0320\n",
            "Epoch 114/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0317 - regularization_loss: 0.0000e+00 - total_loss: 0.0317\n",
            "Epoch 115/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0319 - regularization_loss: 0.0000e+00 - total_loss: 0.0319\n",
            "Epoch 116/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0319 - regularization_loss: 0.0000e+00 - total_loss: 0.0319\n",
            "Epoch 117/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9798 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 118/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0314 - regularization_loss: 0.0000e+00 - total_loss: 0.0314\n",
            "Epoch 119/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0314 - regularization_loss: 0.0000e+00 - total_loss: 0.0314\n",
            "Epoch 120/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 121/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 122/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0308 - regularization_loss: 0.0000e+00 - total_loss: 0.0308\n",
            "Epoch 123/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0308 - regularization_loss: 0.0000e+00 - total_loss: 0.0308\n",
            "Epoch 124/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0309 - regularization_loss: 0.0000e+00 - total_loss: 0.0309\n",
            "Epoch 125/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 126/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 127/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9798 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 128/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0312 - regularization_loss: 0.0000e+00 - total_loss: 0.0312\n",
            "Epoch 129/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9796 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 130/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 131/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 132/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 133/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0315 - regularization_loss: 0.0000e+00 - total_loss: 0.0315\n",
            "Epoch 134/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9799 - loss: 0.0316 - regularization_loss: 0.0000e+00 - total_loss: 0.0316\n",
            "Epoch 135/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9798 - loss: 0.0313 - regularization_loss: 0.0000e+00 - total_loss: 0.0313\n",
            "Epoch 136/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0313 - regularization_loss: 0.0000e+00 - total_loss: 0.0313\n",
            "Epoch 137/500\n",
            "94/94 [==============================] - 9s 97ms/step - binary_accuracy: 0.9798 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 138/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9798 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 139/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9796 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 140/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9795 - loss: 0.0313 - regularization_loss: 0.0000e+00 - total_loss: 0.0313\n",
            "Epoch 141/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9796 - loss: 0.0309 - regularization_loss: 0.0000e+00 - total_loss: 0.0309\n",
            "Epoch 142/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9795 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 143/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 144/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0308 - regularization_loss: 0.0000e+00 - total_loss: 0.0308\n",
            "Epoch 145/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 146/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 147/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9797 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 148/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9799 - loss: 0.0309 - regularization_loss: 0.0000e+00 - total_loss: 0.0309\n",
            "Epoch 149/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9800 - loss: 0.0308 - regularization_loss: 0.0000e+00 - total_loss: 0.0308\n",
            "Epoch 150/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9801 - loss: 0.0306 - regularization_loss: 0.0000e+00 - total_loss: 0.0306\n",
            "Epoch 151/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9801 - loss: 0.0304 - regularization_loss: 0.0000e+00 - total_loss: 0.0304\n",
            "Epoch 152/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9800 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 153/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9800 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 154/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9799 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 155/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9799 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 156/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9799 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 157/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9800 - loss: 0.0305 - regularization_loss: 0.0000e+00 - total_loss: 0.0305\n",
            "Epoch 158/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9799 - loss: 0.0303 - regularization_loss: 0.0000e+00 - total_loss: 0.0303\n",
            "Epoch 159/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9798 - loss: 0.0306 - regularization_loss: 0.0000e+00 - total_loss: 0.0306\n",
            "Epoch 160/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0306 - regularization_loss: 0.0000e+00 - total_loss: 0.0306\n",
            "Epoch 161/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9796 - loss: 0.0309 - regularization_loss: 0.0000e+00 - total_loss: 0.0309\n",
            "Epoch 162/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9796 - loss: 0.0310 - regularization_loss: 0.0000e+00 - total_loss: 0.0310\n",
            "Epoch 163/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9795 - loss: 0.0312 - regularization_loss: 0.0000e+00 - total_loss: 0.0312\n",
            "Epoch 164/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9795 - loss: 0.0313 - regularization_loss: 0.0000e+00 - total_loss: 0.0313\n",
            "Epoch 165/500\n",
            "94/94 [==============================] - 9s 98ms/step - binary_accuracy: 0.9798 - loss: 0.0311 - regularization_loss: 0.0000e+00 - total_loss: 0.0311\n",
            "Epoch 166/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9797 - loss: 0.0309 - regularization_loss: 0.0000e+00 - total_loss: 0.0309\n",
            "Epoch 167/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9799 - loss: 0.0308 - regularization_loss: 0.0000e+00 - total_loss: 0.0308\n",
            "Epoch 168/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9799 - loss: 0.0307 - regularization_loss: 0.0000e+00 - total_loss: 0.0307\n",
            "Epoch 169/500\n",
            "94/94 [==============================] - 9s 100ms/step - binary_accuracy: 0.9800 - loss: 0.0304 - regularization_loss: 0.0000e+00 - total_loss: 0.0304\n",
            "Epoch 170/500\n",
            "94/94 [==============================] - 9s 99ms/step - binary_accuracy: 0.9800 - loss: 0.0302 - regularization_loss: 0.0000e+00 - total_loss: 0.0302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f10TwemRD14",
        "outputId": "7e46a185-90fe-4a7d-c56c-8ff02dc944ca"
      },
      "source": [
        "DCN.getResult(model, cached_test, metric = 'binary')"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC: 0.9571572609509558\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.90      0.92     88227\n",
            "           1       0.92      0.94      0.93    100491\n",
            "\n",
            "    accuracy                           0.92    188718\n",
            "   macro avg       0.92      0.92      0.92    188718\n",
            "weighted avg       0.92      0.92      0.92    188718\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjKUFedR27j",
        "outputId": "4b654907-ac13-4fb1-b897-f55f347ad7fd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_54 (Sequential)   (None, 64)                4224      \n",
            "_________________________________________________________________\n",
            "sequential_55 (Sequential)   (None, 64)                1792      \n",
            "_________________________________________________________________\n",
            "sequential_53 (Sequential)   (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "sequential_46 (Sequential)   (None, 64)                3584      \n",
            "_________________________________________________________________\n",
            "sequential_45 (Sequential)   (None, 64)                37760     \n",
            "_________________________________________________________________\n",
            "sequential_52 (Sequential)   (None, 64)                1370944   \n",
            "_________________________________________________________________\n",
            "sequential_50 (Sequential)   (None, 64)                1728      \n",
            "_________________________________________________________________\n",
            "sequential_49 (Sequential)   (None, 64)                509376    \n",
            "_________________________________________________________________\n",
            "sequential_47 (Sequential)   (None, 64)                122304    \n",
            "_________________________________________________________________\n",
            "sequential_51 (Sequential)   (None, 64)                66304     \n",
            "_________________________________________________________________\n",
            "sequential_48 (Sequential)   (None, 64)                320       \n",
            "_________________________________________________________________\n",
            "sequential_44 (Sequential)   (None, 64)                512       \n",
            "_________________________________________________________________\n",
            "sequential_42 (Sequential)   (None, 64)                406016    \n",
            "_________________________________________________________________\n",
            "sequential_43 (Sequential)   (None, 64)                3254528   \n",
            "_________________________________________________________________\n",
            "cross_3 (Cross)              multiple                  803712    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             multiple                  459264    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             multiple                  131328    \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             multiple                  32896     \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             multiple                  65        \n",
            "_________________________________________________________________\n",
            "ranking_3 (Ranking)          multiple                  2         \n",
            "=================================================================\n",
            "Total params: 7,215,491\n",
            "Trainable params: 7,215,489\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkDiBOZTgmMk"
      },
      "source": [
        "pred = DCN.recommendation(1201, model, selected_item, str_features, int_features)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "hVBirQyRgoEC",
        "outputId": "10b2db68-4f6a-4501-b369-9b40264cd185"
      },
      "source": [
        "pred.merge(item[['wine_id', 'name']], on = 'wine_id', )"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>prob</th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4380</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>RosÃ©</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>620</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>Merlot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11654</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>Santa Lucia Highlands Pinot Noir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1688</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>Castello della Sala Cervaro della Sala</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3740</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>La Putere FeteascÄƒ NeagrÄƒ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4321</th>\n",
              "      <td>17943</td>\n",
              "      <td>9.288893e-14</td>\n",
              "      <td>Chloe Ritchie Vineyard Chardonnay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4322</th>\n",
              "      <td>23158</td>\n",
              "      <td>8.615945e-14</td>\n",
              "      <td>GewÃ¼rztraminer Grand Cru Hengst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4323</th>\n",
              "      <td>18510</td>\n",
              "      <td>4.586117e-14</td>\n",
              "      <td>Catarina Branco</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4324</th>\n",
              "      <td>3088</td>\n",
              "      <td>4.368048e-14</td>\n",
              "      <td>Merlot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4325</th>\n",
              "      <td>23369</td>\n",
              "      <td>3.241119e-15</td>\n",
              "      <td>Molmenti</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4326 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      wine_id          prob                                    name\n",
              "0        4380  1.000000e+00                                    RosÃ©\n",
              "1         620  1.000000e+00                                  Merlot\n",
              "2       11654  1.000000e+00        Santa Lucia Highlands Pinot Noir\n",
              "3        1688  1.000000e+00  Castello della Sala Cervaro della Sala\n",
              "4        3740  1.000000e+00               La Putere FeteascÄƒ NeagrÄƒ\n",
              "...       ...           ...                                     ...\n",
              "4321    17943  9.288893e-14       Chloe Ritchie Vineyard Chardonnay\n",
              "4322    23158  8.615945e-14         GewÃ¼rztraminer Grand Cru Hengst\n",
              "4323    18510  4.586117e-14                         Catarina Branco\n",
              "4324     3088  4.368048e-14                                  Merlot\n",
              "4325    23369  3.241119e-15                                Molmenti\n",
              "\n",
              "[4326 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTDZA6DNoQK-"
      },
      "source": [
        "import seaborn as sns\n",
        "plt.style.use('seaborn') # seaborn ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜\n",
        "sns.set(rc={'figure.figsize' : (15,15)})"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "DTX_1G6vkGiR",
        "outputId": "f1a7f045-5611-4538-b482-a3d8b14cd8ab"
      },
      "source": [
        "try:\n",
        "    mat = model._cross_layer._dense.kernel\n",
        "    features = model._all_features\n",
        "    block_norm = np.ones([len(features), len(features)])\n",
        "\n",
        "    dim = model.embedding_dimension\n",
        "\n",
        "    # Compute the norms of the blocks.\n",
        "    for i in range(len(features)):\n",
        "        for j in range(len(features)):\n",
        "            block = mat[i * dim:(i + 1) * dim,\n",
        "                        j * dim:(j + 1) * dim]\n",
        "            block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
        "\n",
        "    plt.figure(figsize=(25,25))\n",
        "    im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
        "    ax = plt.gca()\n",
        "    divider = make_axes_locatable(plt.gca())\n",
        "    cax = divider.append_axes(\"right\", size=\"1%\", pad=0.001)\n",
        "    plt.colorbar(im, cax=cax)\n",
        "    cax.tick_params(labelsize=10)\n",
        "    # ax.set_xticklabels(np.arange(1, 15), features, ha=\"left\")\n",
        "    ax.set_xticks(np.arange(0,14))\n",
        "    ax.set_yticks(np.arange(0,14))\n",
        "    _ = ax.set_xticklabels(features, rotation=45, ha=\"left\", fontsize=10)\n",
        "    _ = ax.set_yticklabels(features, fontsize=10)\n",
        "except:\n",
        "    print('Project dims is formed!')"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnJqLOKiVqWN"
      },
      "source": [
        "model.save_weights('./model_weights(project_dims is None).tf', save_format = 'tf')"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmt_T0is2Fe",
        "outputId": "40891b81-f2d8-42bd-f50f-714b981dba52"
      },
      "source": [
        "learning_rate = 0.001\n",
        "model = DCN.model(use_cross_layer = True,\n",
        "            deep_layer_sizes = [512, 256, 128, 64],\n",
        "            learning_rate = learning_rate,\n",
        "            str_features = str_features,\n",
        "            int_features = int_features,\n",
        "            vocabularies = vocabularies,\n",
        "            projection_dim = None,\n",
        "            metric = 'binary'\n",
        "            )\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate))\n",
        "\n",
        "model.load_weights('./model_weights(project_dims is None).tf')"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f70629faf60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "jvaYpE_Wtejv",
        "outputId": "b2579764-6fec-4eb7-993e-e97aae5d6876"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_68 (Sequential)   (None, 1, 64)             4224      \n",
            "_________________________________________________________________\n",
            "sequential_69 (Sequential)   (None, 1, 64)             1792      \n",
            "_________________________________________________________________\n",
            "sequential_67 (Sequential)   (None, 1, 64)             576       \n",
            "_________________________________________________________________\n",
            "sequential_60 (Sequential)   (None, 1, 64)             3584      \n",
            "_________________________________________________________________\n",
            "sequential_59 (Sequential)   (None, 1, 64)             37760     \n",
            "_________________________________________________________________\n",
            "sequential_66 (Sequential)   (None, 1, 64)             1370944   \n",
            "_________________________________________________________________\n",
            "sequential_64 (Sequential)   (None, 1, 64)             1728      \n",
            "_________________________________________________________________\n",
            "sequential_63 (Sequential)   (None, 1, 64)             509376    \n",
            "_________________________________________________________________\n",
            "sequential_61 (Sequential)   (None, 1, 64)             122304    \n",
            "_________________________________________________________________\n",
            "sequential_65 (Sequential)   (None, 1, 64)             66304     \n",
            "_________________________________________________________________\n",
            "sequential_62 (Sequential)   (None, 1, 64)             320       \n",
            "_________________________________________________________________\n",
            "sequential_58 (Sequential)   (None, 1, 64)             512       \n",
            "_________________________________________________________________\n",
            "sequential_56 (Sequential)   (None, 1, 64)             406016    \n",
            "_________________________________________________________________\n",
            "sequential_57 (Sequential)   (None, 1, 64)             3254528   \n",
            "_________________________________________________________________\n",
            "cross_4 (Cross)              multiple                  0         \n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2382\u001b[0m                               \u001b[0mline_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2383\u001b[0m                               \u001b[0mpositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2384\u001b[0;31m                               print_fn=print_fn)\n\u001b[0m\u001b[1;32m   2385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2386\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_summary\u001b[0;34m(model, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequential_like\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       \u001b[0mprint_layer_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0mprint_layer_summary_with_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/layer_utils.py\u001b[0m in \u001b[0;36mprint_layer_summary\u001b[0;34m(layer)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mcls_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' ('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0mprint_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcount_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2206\u001b[0m                          \u001b[0;34m', but the layer isn\\'t built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m                          \u001b[0;34m'You can build it manually via: `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2208\u001b[0;31m                          '.build(batch_input_shape)`.')\n\u001b[0m\u001b[1;32m   2209\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: You tried to call `count_params` on dense_20, but the layer isn't built. You can build it manually via: `dense_20.build(batch_input_shape)`."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyJSjMWmnc6y"
      },
      "source": [
        "# Hitrate"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbHKTrNgTlY0"
      },
      "source": [
        "H4test = pd.read_json('user_test_v2.json')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vauMT33FT-id"
      },
      "source": [
        "H4test = H4test[['userID', 'wine_id']]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wNvsuDsDZSyc",
        "outputId": "e81a2932-0539-41b3-e189-5a7daffaa075"
      },
      "source": [
        "HRate = 0\n",
        "for user, wine in tqdm(H4test.values):\n",
        "    pred = DCN.recommendation(user, model, selected_item, str_features, int_features)\n",
        "    pred['rank'] = pred['prob'].rank(method = 'min', ascending = False)\n",
        "                  \n",
        "    rank = pred.loc[pred['rank'] < 500]\n",
        "    break\n",
        "    if wine in rank['wine_id'].values:\n",
        "        HRate += 1"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6343 [00:01<?, ?it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-28414304cd99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mHRate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH4test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecommendation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN/DCN.py\u001b[0m in \u001b[0;36mrecommendation\u001b[0;34m(userID, model, item, str_features, int_features)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m   \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'wine_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prob'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /content/drive/My Drive/á„‚á…©á†«á„†á…®á†«/DCN/DCN.py:197 call  *\n        x = self._cross_layer(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow_recommenders/layers/dcn.py:173 call  *\n        prod_output = self._dense(x)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1008 __call__  **\n        self._maybe_build(inputs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:2710 _maybe_build\n        self.build(input_shapes)  # pylint:disable=not-callable\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:1192 build\n        trainable=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:639 add_weight\n        caching_device=caching_device)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:810 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:142 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3332 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3332 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3332 creator\n        return next_creator(**kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:714 variable_capturing_scope\n        lifted_initializer_graph=lifted_initializer_graph, **kwds)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py:264 __call__\n        return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:227 __init__\n        initial_value = initial_value()\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:82 __call__\n        self._checkpoint_position, shape, shard_info=shard_info)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py:117 __init__\n        self.wrapped_value.set_shape(shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1217 set_shape\n        (self.shape, shape))\n\n    ValueError: Tensor's shape (896, 896) is not compatible with supplied shape [64, 64]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFLk1OB-eaak"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
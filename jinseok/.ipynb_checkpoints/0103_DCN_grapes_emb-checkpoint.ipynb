{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1227_DCN_practive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBTOhQ463t7z",
        "outputId": "faa35cb0-576a-4b26-86fd-8d2987256d65"
      },
      "source": [
        "cd /content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/á„‚á…©á†«á„†á…®á†«/DCN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2usum1jB5bHe",
        "outputId": "f0f2a7c1-2cd9-4737-8a88-f31da017c1da"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1220_dcn.ipynb           train_v2_201130.json  Wine_segment_201229.csv\n",
            "1227_DCN_practive.ipynb  user_test_v2.json     Wine_segment_scaled_201231.csv\n",
            "test_v2_201130.json      user_train_v2.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65nKvxZD5e9j",
        "outputId": "b2e87a20-3e32-43a9-81e4-93e61ab81f72"
      },
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.7MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.6MB 10.8MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Fwep3Dx5njv"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import glob\n",
        "import joblib\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Lambda, Input, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import LambdaCallback, EarlyStopping, Callback\n",
        "from tensorflow.keras.utils import plot_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q_K49pf5vvR"
      },
      "source": [
        "# 0. Data Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASm4pmAi5qr4"
      },
      "source": [
        "# 0. Data Load"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIYEMAos5uhg"
      },
      "source": [
        "train = pd.read_json('train_v2_201130.json')\n",
        "test = pd.read_json('test_v2_201130.json')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "saoP8nR752wc",
        "outputId": "4110f51b-b05a-4d69-b59b-2944c12f6d54"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_note</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>vintage_id</th>\n",
              "      <th>user_like_count</th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>wine_name</th>\n",
              "      <th>url</th>\n",
              "      <th>like</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Soooo good ðŸ’•</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>BelÃ­ssimo champanhe rose, bem seco mais com mu...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>2</td>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td></td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Perfekt med gratinerede Ã¸sters.</td>\n",
              "      <td>4.5</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>Delicious!</td>\n",
              "      <td>4.0</td>\n",
              "      <td>164942680</td>\n",
              "      <td>0</td>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>Prestige RosÃ© Brut ChampagnenN.V.</td>\n",
              "      <td>/taittinger-prestige-rose-brut-champagne/w/114...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  ... like\n",
              "0      0  ...    1\n",
              "1      1  ...    1\n",
              "2      4  ...    1\n",
              "3      5  ...    1\n",
              "4      6  ...    0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MF4Yup4jD08j",
        "outputId": "7f4e1e3d-9343-46c8-ca7b-761120f6e1b8"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((763387, 10), (188718, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9fTbUA0Db6R"
      },
      "source": [
        "item = pd.read_csv('Wine_segment_201229.csv')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "C4_NozHvD7Qe",
        "outputId": "f9b493ea-dfa4-4e6d-8632-942add6fe273"
      },
      "source": [
        "item.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>name</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>label_count</th>\n",
              "      <th>review_count</th>\n",
              "      <th>body</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>winery_ratings_count</th>\n",
              "      <th>winery_ratings_average</th>\n",
              "      <th>winery_labels_count</th>\n",
              "      <th>winery_wines_count</th>\n",
              "      <th>Aperitif</th>\n",
              "      <th>Appetizers and snacks</th>\n",
              "      <th>Blue cheese</th>\n",
              "      <th>Cured Meat</th>\n",
              "      <th>Fruity desserts</th>\n",
              "      <th>Game</th>\n",
              "      <th>Goat cheese</th>\n",
              "      <th>Lamb</th>\n",
              "      <th>Lean fish</th>\n",
              "      <th>Mature and hard cheese</th>\n",
              "      <th>Mild and soft cheese</th>\n",
              "      <th>Mushrooms</th>\n",
              "      <th>Pasta</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Poultry</th>\n",
              "      <th>Rich fish</th>\n",
              "      <th>Shellfish</th>\n",
              "      <th>Spicy food</th>\n",
              "      <th>Sweet desserts</th>\n",
              "      <th>Veal</th>\n",
              "      <th>Vegetarian</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Blue cheese.1</th>\n",
              "      <th>Fruity desserts.1</th>\n",
              "      <th>Game .1</th>\n",
              "      <th>Lamb.1</th>\n",
              "      <th>Mature and hard cheese.1</th>\n",
              "      <th>Pasta.1</th>\n",
              "      <th>...</th>\n",
              "      <th>pca_18</th>\n",
              "      <th>pca_19</th>\n",
              "      <th>pca_20</th>\n",
              "      <th>pca_21</th>\n",
              "      <th>pca_22</th>\n",
              "      <th>pca_23</th>\n",
              "      <th>pca_24</th>\n",
              "      <th>pca_25</th>\n",
              "      <th>pca_26</th>\n",
              "      <th>pca_27</th>\n",
              "      <th>pca_28</th>\n",
              "      <th>pca_29</th>\n",
              "      <th>pca_30</th>\n",
              "      <th>pca_31</th>\n",
              "      <th>pca_32</th>\n",
              "      <th>pca_33</th>\n",
              "      <th>pca_34</th>\n",
              "      <th>pca_35</th>\n",
              "      <th>pca_36</th>\n",
              "      <th>pca_37</th>\n",
              "      <th>pca_38</th>\n",
              "      <th>pca_39</th>\n",
              "      <th>pca_40</th>\n",
              "      <th>pca_41</th>\n",
              "      <th>pca_42</th>\n",
              "      <th>pca_43</th>\n",
              "      <th>pca_44</th>\n",
              "      <th>pca_45</th>\n",
              "      <th>pca_46</th>\n",
              "      <th>pca_47</th>\n",
              "      <th>pca_48</th>\n",
              "      <th>pca_49</th>\n",
              "      <th>pca_50</th>\n",
              "      <th>pca_51</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>region_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>type_id</th>\n",
              "      <th>winery_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1938520</td>\n",
              "      <td>1882 Cabernet Sauvignon</td>\n",
              "      <td>1697</td>\n",
              "      <td>4.1</td>\n",
              "      <td>14879</td>\n",
              "      <td>16</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.5</td>\n",
              "      <td>18888.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>121618.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.551669</td>\n",
              "      <td>4.234245</td>\n",
              "      <td>-4.399549</td>\n",
              "      <td>-1.394831</td>\n",
              "      <td>4.230004</td>\n",
              "      <td>2.214657</td>\n",
              "      <td>3.698479</td>\n",
              "      <td>-11.544035</td>\n",
              "      <td>3.926973</td>\n",
              "      <td>2.027013</td>\n",
              "      <td>-3.108813</td>\n",
              "      <td>0.066079</td>\n",
              "      <td>3.901737</td>\n",
              "      <td>5.336387</td>\n",
              "      <td>-2.893791</td>\n",
              "      <td>-7.887779</td>\n",
              "      <td>-12.434086</td>\n",
              "      <td>5.029867</td>\n",
              "      <td>-2.870348</td>\n",
              "      <td>1.098466</td>\n",
              "      <td>0.041303</td>\n",
              "      <td>-0.516198</td>\n",
              "      <td>0.322788</td>\n",
              "      <td>-0.443685</td>\n",
              "      <td>-3.136951</td>\n",
              "      <td>0.742006</td>\n",
              "      <td>0.173241</td>\n",
              "      <td>-1.924884</td>\n",
              "      <td>-1.610956</td>\n",
              "      <td>2.868221</td>\n",
              "      <td>-2.167123</td>\n",
              "      <td>1.151749</td>\n",
              "      <td>1.444787</td>\n",
              "      <td>2.489641</td>\n",
              "      <td>[2]</td>\n",
              "      <td>105.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>2412.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14604</td>\n",
              "      <td>Les Bessards Hermitage</td>\n",
              "      <td>1078</td>\n",
              "      <td>4.3</td>\n",
              "      <td>5370</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>72079.0</td>\n",
              "      <td>3.8</td>\n",
              "      <td>462021.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.201073</td>\n",
              "      <td>3.788378</td>\n",
              "      <td>1.210495</td>\n",
              "      <td>1.083187</td>\n",
              "      <td>0.590964</td>\n",
              "      <td>3.617076</td>\n",
              "      <td>0.106284</td>\n",
              "      <td>7.155894</td>\n",
              "      <td>1.924063</td>\n",
              "      <td>-1.217552</td>\n",
              "      <td>3.798950</td>\n",
              "      <td>-0.573204</td>\n",
              "      <td>0.910653</td>\n",
              "      <td>2.294474</td>\n",
              "      <td>-1.256222</td>\n",
              "      <td>-1.491831</td>\n",
              "      <td>-2.579453</td>\n",
              "      <td>-0.628009</td>\n",
              "      <td>-0.097134</td>\n",
              "      <td>-4.154698</td>\n",
              "      <td>-2.861205</td>\n",
              "      <td>-4.497887</td>\n",
              "      <td>1.583489</td>\n",
              "      <td>-0.026252</td>\n",
              "      <td>-1.082327</td>\n",
              "      <td>0.338037</td>\n",
              "      <td>-2.199833</td>\n",
              "      <td>-0.638129</td>\n",
              "      <td>1.981586</td>\n",
              "      <td>1.148229</td>\n",
              "      <td>-0.780446</td>\n",
              "      <td>-1.026985</td>\n",
              "      <td>-3.631833</td>\n",
              "      <td>-0.124608</td>\n",
              "      <td>[1]</td>\n",
              "      <td>535.0</td>\n",
              "      <td>fr</td>\n",
              "      <td>1</td>\n",
              "      <td>7636.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1930757</td>\n",
              "      <td>Patriarch Estate Grown</td>\n",
              "      <td>1072</td>\n",
              "      <td>4.6</td>\n",
              "      <td>6042</td>\n",
              "      <td>25</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.2</td>\n",
              "      <td>7747.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>49362.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.994470</td>\n",
              "      <td>3.356056</td>\n",
              "      <td>-0.923651</td>\n",
              "      <td>0.741282</td>\n",
              "      <td>2.596084</td>\n",
              "      <td>7.155602</td>\n",
              "      <td>-1.910814</td>\n",
              "      <td>-3.998637</td>\n",
              "      <td>-0.054258</td>\n",
              "      <td>0.587277</td>\n",
              "      <td>-0.887633</td>\n",
              "      <td>-0.478954</td>\n",
              "      <td>-0.442926</td>\n",
              "      <td>-1.749812</td>\n",
              "      <td>-1.185678</td>\n",
              "      <td>-0.141588</td>\n",
              "      <td>0.728802</td>\n",
              "      <td>-1.242658</td>\n",
              "      <td>0.493817</td>\n",
              "      <td>-1.872077</td>\n",
              "      <td>-2.067729</td>\n",
              "      <td>-3.043356</td>\n",
              "      <td>0.165190</td>\n",
              "      <td>0.615640</td>\n",
              "      <td>-0.657080</td>\n",
              "      <td>0.566004</td>\n",
              "      <td>0.658332</td>\n",
              "      <td>-0.343338</td>\n",
              "      <td>-1.285816</td>\n",
              "      <td>0.543290</td>\n",
              "      <td>-0.569400</td>\n",
              "      <td>1.647680</td>\n",
              "      <td>-1.445715</td>\n",
              "      <td>-0.359417</td>\n",
              "      <td>[2, 10]</td>\n",
              "      <td>88.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>1905.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1564280</td>\n",
              "      <td>Merlot</td>\n",
              "      <td>3577</td>\n",
              "      <td>4.3</td>\n",
              "      <td>18748</td>\n",
              "      <td>52</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>14091.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>83324.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-6.055126</td>\n",
              "      <td>-6.163670</td>\n",
              "      <td>-17.412258</td>\n",
              "      <td>3.399827</td>\n",
              "      <td>0.748214</td>\n",
              "      <td>17.899010</td>\n",
              "      <td>-2.046424</td>\n",
              "      <td>-11.186761</td>\n",
              "      <td>12.007775</td>\n",
              "      <td>0.894301</td>\n",
              "      <td>5.050331</td>\n",
              "      <td>-2.478301</td>\n",
              "      <td>8.826864</td>\n",
              "      <td>7.167604</td>\n",
              "      <td>-6.359656</td>\n",
              "      <td>-1.473321</td>\n",
              "      <td>-3.462038</td>\n",
              "      <td>4.614712</td>\n",
              "      <td>-0.875028</td>\n",
              "      <td>-7.256990</td>\n",
              "      <td>-2.221329</td>\n",
              "      <td>-6.283630</td>\n",
              "      <td>-0.477432</td>\n",
              "      <td>0.779232</td>\n",
              "      <td>2.592272</td>\n",
              "      <td>-0.271975</td>\n",
              "      <td>1.884531</td>\n",
              "      <td>0.176404</td>\n",
              "      <td>4.579372</td>\n",
              "      <td>1.793655</td>\n",
              "      <td>-4.051642</td>\n",
              "      <td>3.926317</td>\n",
              "      <td>-2.261881</td>\n",
              "      <td>-0.431446</td>\n",
              "      <td>[10]</td>\n",
              "      <td>24.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576427</td>\n",
              "      <td>Cabernet Sauvignon F Block</td>\n",
              "      <td>115</td>\n",
              "      <td>4.4</td>\n",
              "      <td>806</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1077.0</td>\n",
              "      <td>4.4</td>\n",
              "      <td>7749.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004828</td>\n",
              "      <td>-0.478264</td>\n",
              "      <td>-1.010209</td>\n",
              "      <td>-0.003157</td>\n",
              "      <td>0.367176</td>\n",
              "      <td>-0.270334</td>\n",
              "      <td>-0.550214</td>\n",
              "      <td>0.490301</td>\n",
              "      <td>-0.315579</td>\n",
              "      <td>0.299809</td>\n",
              "      <td>-0.471115</td>\n",
              "      <td>-0.199453</td>\n",
              "      <td>-0.326484</td>\n",
              "      <td>-0.776345</td>\n",
              "      <td>-0.717146</td>\n",
              "      <td>0.147173</td>\n",
              "      <td>0.347295</td>\n",
              "      <td>-0.071307</td>\n",
              "      <td>0.385532</td>\n",
              "      <td>-0.230784</td>\n",
              "      <td>0.216109</td>\n",
              "      <td>0.222512</td>\n",
              "      <td>-0.104980</td>\n",
              "      <td>-0.133218</td>\n",
              "      <td>-0.016644</td>\n",
              "      <td>-0.063100</td>\n",
              "      <td>-0.098678</td>\n",
              "      <td>0.082621</td>\n",
              "      <td>0.164888</td>\n",
              "      <td>-0.078193</td>\n",
              "      <td>0.113466</td>\n",
              "      <td>0.270745</td>\n",
              "      <td>0.158934</td>\n",
              "      <td>-0.330067</td>\n",
              "      <td>[2]</td>\n",
              "      <td>42.0</td>\n",
              "      <td>us</td>\n",
              "      <td>1</td>\n",
              "      <td>2232.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 152 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   wine_id                        name  ...  winery_id  segment\n",
              "0  1938520     1882 Cabernet Sauvignon  ...     2412.0        2\n",
              "1    14604      Les Bessards Hermitage  ...     7636.0        2\n",
              "2  1930757      Patriarch Estate Grown  ...     1905.0        2\n",
              "3  1564280                      Merlot  ...     1297.0        2\n",
              "4  2576427  Cabernet Sauvignon F Block  ...     2232.0        2\n",
              "\n",
              "[5 rows x 152 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JjrbiN5uZ2S"
      },
      "source": [
        "# 1. Data Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXe-6WSvuPso"
      },
      "source": [
        "train = train[['userID', 'wine_id', 'rating_per_user', 'like']]\n",
        "test = test[['userID', 'wine_id', 'rating_per_user', 'like']]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "SO8ZFdsGvUMr",
        "outputId": "b9ed5997-6a6c-4e30-ab24-6463272d575b"
      },
      "source": [
        "selected_item = item[[\n",
        "      'wine_id',\n",
        "      'rating_count',\n",
        "      'rating_average',\n",
        "      'review_count',\n",
        "      'label_count',\n",
        "      'body',\n",
        "      'acidity_y',\n",
        "      'alcohol',\n",
        "      'type_id',\n",
        "      'grapes_id',\n",
        "      'country_code',\n",
        "      'region_id',\n",
        "      'segment'\n",
        "]]\n",
        "\n",
        "selected_item"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1938520</td>\n",
              "      <td>1697</td>\n",
              "      <td>4.1</td>\n",
              "      <td>16</td>\n",
              "      <td>14879</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.485010</td>\n",
              "      <td>14.5</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>105.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14604</td>\n",
              "      <td>1078</td>\n",
              "      <td>4.3</td>\n",
              "      <td>3</td>\n",
              "      <td>5370</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.429150</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[1]</td>\n",
              "      <td>fr</td>\n",
              "      <td>535.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1930757</td>\n",
              "      <td>1072</td>\n",
              "      <td>4.6</td>\n",
              "      <td>25</td>\n",
              "      <td>6042</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.851015</td>\n",
              "      <td>14.2</td>\n",
              "      <td>1</td>\n",
              "      <td>[2, 10]</td>\n",
              "      <td>us</td>\n",
              "      <td>88.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1564280</td>\n",
              "      <td>3577</td>\n",
              "      <td>4.3</td>\n",
              "      <td>52</td>\n",
              "      <td>18748</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.775668</td>\n",
              "      <td>14.4</td>\n",
              "      <td>1</td>\n",
              "      <td>[10]</td>\n",
              "      <td>us</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2576427</td>\n",
              "      <td>115</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1</td>\n",
              "      <td>806</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.511364</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50855</th>\n",
              "      <td>1669561</td>\n",
              "      <td>788</td>\n",
              "      <td>3.5</td>\n",
              "      <td>9</td>\n",
              "      <td>6635</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.212859</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[104, 34]</td>\n",
              "      <td>it</td>\n",
              "      <td>983.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50856</th>\n",
              "      <td>1861275</td>\n",
              "      <td>231</td>\n",
              "      <td>3.8</td>\n",
              "      <td>6</td>\n",
              "      <td>961</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.072673</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[5]</td>\n",
              "      <td>it</td>\n",
              "      <td>613.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50857</th>\n",
              "      <td>2201892</td>\n",
              "      <td>390</td>\n",
              "      <td>3.9</td>\n",
              "      <td>14</td>\n",
              "      <td>1983</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.982507</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[112]</td>\n",
              "      <td>it</td>\n",
              "      <td>3232.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50858</th>\n",
              "      <td>2396179</td>\n",
              "      <td>302</td>\n",
              "      <td>4.2</td>\n",
              "      <td>4</td>\n",
              "      <td>730</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.061171</td>\n",
              "      <td>13.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[17]</td>\n",
              "      <td>fr</td>\n",
              "      <td>635.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50859</th>\n",
              "      <td>7715684</td>\n",
              "      <td>82</td>\n",
              "      <td>4.1</td>\n",
              "      <td>4</td>\n",
              "      <td>483</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.560714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[88]</td>\n",
              "      <td>es</td>\n",
              "      <td>1687.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50860 rows Ã— 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       wine_id  rating_count  rating_average  ...  country_code  region_id  segment\n",
              "0      1938520          1697             4.1  ...            us      105.0        2\n",
              "1        14604          1078             4.3  ...            fr      535.0        2\n",
              "2      1930757          1072             4.6  ...            us       88.0        2\n",
              "3      1564280          3577             4.3  ...            us       24.0        2\n",
              "4      2576427           115             4.4  ...            us       42.0        2\n",
              "...        ...           ...             ...  ...           ...        ...      ...\n",
              "50855  1669561           788             3.5  ...            it      983.0        1\n",
              "50856  1861275           231             3.8  ...            it      613.0        1\n",
              "50857  2201892           390             3.9  ...            it     3232.0        1\n",
              "50858  2396179           302             4.2  ...            fr      635.0        3\n",
              "50859  7715684            82             4.1  ...            es     1687.0        2\n",
              "\n",
              "[50860 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnnQu07OGSV_"
      },
      "source": [
        "train.loc[train['wine_id'] == 1886805, 'wine_id'] = 1183966\n",
        "test.loc[test['wine_id'] == 1886805, 'wine_id'] = 1183966"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "ROxPukdYutjk",
        "outputId": "adcb6205-38cb-47d9-9e48-806877eeb5c3"
      },
      "source": [
        "add_train = train.merge(selected_item, on = 'wine_id', how = 'left')\n",
        "add_test = test.merge(selected_item, on = 'wine_id', how = 'left')\n",
        "\n",
        "add_train"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>like</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763382</th>\n",
              "      <td>11274168</td>\n",
              "      <td>87064</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1379</td>\n",
              "      <td>3.8</td>\n",
              "      <td>37</td>\n",
              "      <td>5851</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.045876</td>\n",
              "      <td>12.5</td>\n",
              "      <td>2</td>\n",
              "      <td>[49]</td>\n",
              "      <td>es</td>\n",
              "      <td>766.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763383</th>\n",
              "      <td>11274168</td>\n",
              "      <td>63654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9222</td>\n",
              "      <td>3.9</td>\n",
              "      <td>178</td>\n",
              "      <td>37914</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.339126</td>\n",
              "      <td>14.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[7]</td>\n",
              "      <td>fr</td>\n",
              "      <td>387.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763384</th>\n",
              "      <td>11274168</td>\n",
              "      <td>5602</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>23457</td>\n",
              "      <td>4.4</td>\n",
              "      <td>865</td>\n",
              "      <td>133651</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.695950</td>\n",
              "      <td>14.4</td>\n",
              "      <td>2</td>\n",
              "      <td>[5]</td>\n",
              "      <td>us</td>\n",
              "      <td>96.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763385</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1396664</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>374</td>\n",
              "      <td>4.3</td>\n",
              "      <td>1</td>\n",
              "      <td>2032</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.493441</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763386</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1142712</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>21638</td>\n",
              "      <td>3.9</td>\n",
              "      <td>262</td>\n",
              "      <td>226514</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.891555</td>\n",
              "      <td>13.5</td>\n",
              "      <td>1</td>\n",
              "      <td>[2]</td>\n",
              "      <td>us</td>\n",
              "      <td>327.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>763387 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          userID  wine_id  rating_per_user  ...  country_code  region_id  segment\n",
              "0       19484511  1141133              4.0  ...            fr      409.0        3\n",
              "1         352674  1141133              4.0  ...            fr      409.0        3\n",
              "2       17786617  1141133              4.0  ...            fr      409.0        3\n",
              "3        8078038  1141133              4.5  ...            fr      409.0        3\n",
              "4        3014532  1141133              4.0  ...            fr      409.0        3\n",
              "...          ...      ...              ...  ...           ...        ...      ...\n",
              "763382  11274168    87064              3.0  ...            es      766.0        1\n",
              "763383  11274168    63654              4.0  ...            fr      387.0        3\n",
              "763384  11274168     5602              4.5  ...            us       96.0        3\n",
              "763385  11274168  1396664              3.0  ...            us       25.0        2\n",
              "763386  11274168  1142712              3.5  ...            us      327.0        2\n",
              "\n",
              "[763387 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPruvbalv3d-",
        "outputId": "30979a43-bd7d-48fb-b2b7-81b5d5bc77ab"
      },
      "source": [
        "add_train.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 763387 entries, 0 to 763386\n",
            "Data columns (total 16 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   userID           763387 non-null  int64  \n",
            " 1   wine_id          763387 non-null  int64  \n",
            " 2   rating_per_user  763387 non-null  float64\n",
            " 3   like             763387 non-null  int64  \n",
            " 4   rating_count     763387 non-null  int64  \n",
            " 5   rating_average   763387 non-null  float64\n",
            " 6   review_count     763387 non-null  int64  \n",
            " 7   label_count      763387 non-null  int64  \n",
            " 8   body             763387 non-null  float64\n",
            " 9   acidity_y        763387 non-null  float64\n",
            " 10  alcohol          763387 non-null  float64\n",
            " 11  type_id          763387 non-null  int64  \n",
            " 12  grapes_id        763387 non-null  object \n",
            " 13  country_code     763387 non-null  object \n",
            " 14  region_id        763387 non-null  float64\n",
            " 15  segment          763387 non-null  int64  \n",
            "dtypes: float64(6), int64(8), object(2)\n",
            "memory usage: 99.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B77nxCbawHLW",
        "outputId": "cc54ab83-e238-456a-cf01-38d97019ff99"
      },
      "source": [
        "add_train.isnull().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userID             0\n",
              "wine_id            0\n",
              "rating_per_user    0\n",
              "like               0\n",
              "rating_count       0\n",
              "rating_average     0\n",
              "review_count       0\n",
              "label_count        0\n",
              "body               0\n",
              "acidity_y          0\n",
              "alcohol            0\n",
              "type_id            0\n",
              "grapes_id          0\n",
              "country_code       0\n",
              "region_id          0\n",
              "segment            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "DekllzMl0aPQ",
        "outputId": "3e3dcc76-5702-4863-f4ab-edeaf6d9a465"
      },
      "source": [
        "add_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>like</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5248</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.283229</td>\n",
              "      <td>12.0</td>\n",
              "      <td>3</td>\n",
              "      <td>[5, 14, 110]</td>\n",
              "      <td>fr</td>\n",
              "      <td>409.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     userID  wine_id  rating_per_user  ...  country_code  region_id  segment\n",
              "0  19484511  1141133              4.0  ...            fr      409.0        3\n",
              "1    352674  1141133              4.0  ...            fr      409.0        3\n",
              "2  17786617  1141133              4.0  ...            fr      409.0        3\n",
              "3   8078038  1141133              4.5  ...            fr      409.0        3\n",
              "4   3014532  1141133              4.0  ...            fr      409.0        3\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfNyvKFlIqXQ"
      },
      "source": [
        "# 2. Data Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-s4mY6oGpme"
      },
      "source": [
        "str_features = ['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment']\n",
        "int_features = ['rating_count', 'rating_average', 'review_count', 'label_count', 'body', 'acidity_y', 'alcohol', 'like']\n",
        "feature_names = str_features + int_features"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enVTATM3M0xf"
      },
      "source": [
        "def setType(df):\n",
        "\n",
        "  df['rating_average'] = df['rating_average'].apply(lambda x : x * 10)\n",
        "  df['acidity_y'] = df['acidity_y'].apply(lambda x : x * 10)\n",
        "  df['grapes_id'] = df['grapes_id'].apply(lambda x : x[0])\n",
        "\n",
        "  for f in str_features:\n",
        "    if df[f].dtype == float:\n",
        "      df[f] = df[f].astype(int)\n",
        "\n",
        "\n",
        "  for f in int_features:\n",
        "    df[f] = df[f].astype(int)\n",
        "\n",
        "  return df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ5Yl7LuK5Gk"
      },
      "source": [
        "add_train = setType(add_train)\n",
        "add_test = setType(add_test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "kXI-dV1Kjevu",
        "outputId": "67cca73a-bd12-4af4-a051-00bca75f6d83"
      },
      "source": [
        "add_train"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>wine_id</th>\n",
              "      <th>rating_per_user</th>\n",
              "      <th>like</th>\n",
              "      <th>rating_count</th>\n",
              "      <th>rating_average</th>\n",
              "      <th>review_count</th>\n",
              "      <th>label_count</th>\n",
              "      <th>body</th>\n",
              "      <th>acidity_y</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>type_id</th>\n",
              "      <th>grapes_id</th>\n",
              "      <th>country_code</th>\n",
              "      <th>region_id</th>\n",
              "      <th>segment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19484511</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>41</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>409</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>352674</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>41</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>409</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17786617</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>41</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>409</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8078038</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>5248</td>\n",
              "      <td>41</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>409</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3014532</td>\n",
              "      <td>1141133</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>5248</td>\n",
              "      <td>41</td>\n",
              "      <td>1798</td>\n",
              "      <td>18046</td>\n",
              "      <td>3</td>\n",
              "      <td>42</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>409</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763382</th>\n",
              "      <td>11274168</td>\n",
              "      <td>87064</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1379</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>5851</td>\n",
              "      <td>3</td>\n",
              "      <td>40</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>[</td>\n",
              "      <td>es</td>\n",
              "      <td>766</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763383</th>\n",
              "      <td>11274168</td>\n",
              "      <td>63654</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>9222</td>\n",
              "      <td>39</td>\n",
              "      <td>178</td>\n",
              "      <td>37914</td>\n",
              "      <td>5</td>\n",
              "      <td>23</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>[</td>\n",
              "      <td>fr</td>\n",
              "      <td>387</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763384</th>\n",
              "      <td>11274168</td>\n",
              "      <td>5602</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>23457</td>\n",
              "      <td>44</td>\n",
              "      <td>865</td>\n",
              "      <td>133651</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>[</td>\n",
              "      <td>us</td>\n",
              "      <td>96</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763385</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1396664</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>374</td>\n",
              "      <td>43</td>\n",
              "      <td>1</td>\n",
              "      <td>2032</td>\n",
              "      <td>5</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[</td>\n",
              "      <td>us</td>\n",
              "      <td>25</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763386</th>\n",
              "      <td>11274168</td>\n",
              "      <td>1142712</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>21638</td>\n",
              "      <td>39</td>\n",
              "      <td>262</td>\n",
              "      <td>226514</td>\n",
              "      <td>4</td>\n",
              "      <td>38</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>[</td>\n",
              "      <td>us</td>\n",
              "      <td>327</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>763387 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          userID  wine_id  rating_per_user  ...  country_code  region_id  segment\n",
              "0       19484511  1141133              4.0  ...            fr        409        3\n",
              "1         352674  1141133              4.0  ...            fr        409        3\n",
              "2       17786617  1141133              4.0  ...            fr        409        3\n",
              "3        8078038  1141133              4.5  ...            fr        409        3\n",
              "4        3014532  1141133              4.0  ...            fr        409        3\n",
              "...          ...      ...              ...  ...           ...        ...      ...\n",
              "763382  11274168    87064              3.0  ...            es        766        1\n",
              "763383  11274168    63654              4.0  ...            fr        387        3\n",
              "763384  11274168     5602              4.5  ...            us         96        3\n",
              "763385  11274168  1396664              3.0  ...            us         25        2\n",
              "763386  11274168  1142712              3.5  ...            us        327        2\n",
              "\n",
              "[763387 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZikrncL_HcCt",
        "outputId": "c422ab4c-eeb5-4b4b-eb97-86e82ab5ef2f"
      },
      "source": [
        "train_str_dict = {\n",
        "    str_feature: [str(val).encode() for val in add_train[str_feature].values]\n",
        "    for str_feature in str_features\n",
        "}\n",
        "\n",
        "train_int_dict = {\n",
        "    int_feature: add_train[int_feature].values\n",
        "    for int_feature in int_features\n",
        "}\n",
        "\n",
        "train_label_dict = {\n",
        "    'rating_per_user' : add_train['rating_per_user'].values\n",
        "}\n",
        "\n",
        "train_str_dict.update(train_int_dict)\n",
        "train_str_dict.update(train_label_dict)\n",
        "train_str_dict.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'label_count', 'body', 'acidity_y', 'alcohol', 'like', 'rating_per_user'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp7pSrLbHeNs",
        "outputId": "964a3d9d-320f-4fd5-b1fa-24b460900786"
      },
      "source": [
        "test_str_dict = {\n",
        "    str_feature: [str(val).encode() for val in add_test[str_feature].values]\n",
        "    for str_feature in str_features\n",
        "}\n",
        "\n",
        "test_int_dict = {\n",
        "    int_feature: add_test[int_feature].values\n",
        "    for int_feature in int_features\n",
        "}\n",
        "\n",
        "test_label_dict = {\n",
        "    'rating_per_user' : add_test['rating_per_user'].values\n",
        "}\n",
        "\n",
        "test_str_dict.update(test_int_dict)\n",
        "test_str_dict.update(test_label_dict)\n",
        "test_str_dict.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'label_count', 'body', 'acidity_y', 'alcohol', 'like', 'rating_per_user'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_oUDERH5fA"
      },
      "source": [
        "tensor_train = tf.data.Dataset.from_tensor_slices(train_str_dict)\n",
        "tensor_test = tf.data.Dataset.from_tensor_slices(test_str_dict)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqU-0VChH-dZ",
        "outputId": "5d901a59-a112-4863-ed5f-67c5636a3426"
      },
      "source": [
        "vocabularies = {}\n",
        "\n",
        "for feature_name in tqdm(feature_names):\n",
        "  vocab = tensor_train.batch(1_000_000).map(lambda x: x[feature_name])\n",
        "  vocabularies[feature_name] = np.unique(np.concatenate(list(vocab)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [01:51<00:00,  7.41s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-4BLWkMIM4P",
        "outputId": "4bb28389-2a51-4f31-f98f-c7469c403d01"
      },
      "source": [
        "vocabularies"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acidity_y': array([ 0,  9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
              "        26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
              "        43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59,\n",
              "        60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75]),\n",
              " 'alcohol': array([  0,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "         14,  15,  16,  17,  18,  19,  20,  21,  23,  45,  80, 112, 114,\n",
              "        135]),\n",
              " 'body': array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
              " 'country_code': array([b'al', b'am', b'ar', b'at', b'au', b'be', b'bg', b'bo', b'br',\n",
              "        b'ca', b'ch', b'cl', b'cn', b'cy', b'cz', b'de', b'dk', b'es',\n",
              "        b'fr', b'gb', b'ge', b'gr', b'hr', b'hu', b'il', b'in', b'it',\n",
              "        b'jp', b'lb', b'lu', b'ma', b'md', b'me', b'mk', b'mt', b'mx',\n",
              "        b'nl', b'nz', b'pe', b'ps', b'pt', b'ro', b'rs', b'ru', b'se',\n",
              "        b'si', b'sk', b'th', b'tn', b'tr', b'ua', b'unk', b'us', b'uy',\n",
              "        b'za'], dtype=object),\n",
              " 'grapes_id': array([b'0', b'['], dtype=object),\n",
              " 'label_count': array([      9,      19,      23, ...,  999982, 1097345, 1137754]),\n",
              " 'like': array([0, 1]),\n",
              " 'rating_average': array([ 0, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,\n",
              "        40, 41, 42, 43, 44, 45, 46, 47, 48]),\n",
              " 'rating_count': array([     4,      6,      9, ..., 122634, 123375, 148911]),\n",
              " 'region_id': array([b'0', b'100', b'1034', ..., b'99', b'992', b'996'], dtype=object),\n",
              " 'review_count': array([    0,     1,     2, ..., 16540, 21005, 22865]),\n",
              " 'segment': array([b'0', b'1', b'2', b'3'], dtype=object),\n",
              " 'type_id': array([b'1', b'2', b'24', b'25', b'3', b'4', b'7'], dtype=object),\n",
              " 'userID': array([b'10001895', b'10003665', b'10006310', ..., b'9990646', b'9993784',\n",
              "        b'9993829'], dtype=object),\n",
              " 'wine_id': array([b'10', b'10000', b'100002', ..., b'99984', b'99986', b'99988'],\n",
              "       dtype=object)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVN6TsKCxkwP",
        "outputId": "7471f0fe-4bec-4594-a638-c0e71e3b59c0"
      },
      "source": [
        "import ast\n",
        "add_train['grapes_id'] = add_train['grapes_id'].apply(lambda x : '[]' if x == '0' else x)\n",
        "grapes =[]\n",
        "add_train['grapes_id'].apply(lambda x : grapes.extend(ast.literal_eval(x)))\n",
        "add_train['grapes_id'] = add_train['grapes_id'].apply(lambda x : ast.literal_eval(x))\n",
        "grapes = list(set(grapes))\n",
        "len(grapes)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "718"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ek0E_Mkt2zZ3"
      },
      "source": [
        "vocabularies['grapes_id'] = tf.keras.preprocessing.sequence.pad_sequences(add_train['grapes_id'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3od8nmfIqopi"
      },
      "source": [
        "vocab_grapes_id = vocabularies['grapes_id']\n",
        "vocabularies['grapes_id'] = [str(val).encode() for val in grapes]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5CEyC5Kq67S"
      },
      "source": [
        "vocabularies['grapes_id'] = np.array(vocabularies['grapes_id'])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn1j7dRrIyEe"
      },
      "source": [
        "# 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCdDXv220t1N"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "class MaskedEmbeddingsAggregatorLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, agg_mode='sum', **kwargs):\n",
        "        super(MaskedEmbeddingsAggregatorLayer, self).__init__(**kwargs)\n",
        "\n",
        "        if agg_mode not in ['sum', 'mean']:\n",
        "            raise NotImplementedError('mode {} not implemented!'.format(agg_mode))\n",
        "        self.agg_mode = agg_mode\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, mask=None):\n",
        "        masked_embeddings = tf.ragged.boolean_mask(inputs, mask)\n",
        "        if self.agg_mode == 'sum':\n",
        "            aggregated =  tf.reduce_sum(masked_embeddings, axis=1)\n",
        "        elif self.agg_mode == 'mean':\n",
        "            aggregated = tf.reduce_mean(masked_embeddings, axis=1)\n",
        "        \n",
        "        return aggregated\n",
        "    \n",
        "    def get_config(self):\n",
        "        # this is used when loading a saved model that uses a custom layer\n",
        "        return {'agg_mode': self.agg_mode}\n",
        "\n",
        "\n",
        "class L2NormLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(L2NormLayer, self).__init__(**kwargs)\n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            inputs = tf.ragged.boolean_mask(inputs, mask).to_tensor()\n",
        "        return tf.math.l2_normalize(inputs, axis=-1)\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return mask\n",
        "    "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXu9OzwInWT"
      },
      "source": [
        "class DCN(tfrs.Model):\n",
        "\n",
        "  def __init__(self, use_cross_layer, deep_layer_sizes, projection_dim=None):\n",
        "    super().__init__()\n",
        "\n",
        "    self.embedding_dimension = 64\n",
        "\n",
        "    str_features = ['userID', 'wine_id', 'type_id', 'country_code', 'region_id', 'segment', 'grapes_id']\n",
        "    # emb_features = ['grapes_id']\n",
        "    int_features = ['rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol']\n",
        "    # feature_names = str_features + int_features\n",
        "\n",
        "    self._all_features = str_features + int_features\n",
        "    self._embeddings = {}\n",
        "\n",
        "    # Compute embeddings for string features.\n",
        "    for feature_name in str_features:\n",
        "      vocabulary = vocabularies[feature_name]\n",
        "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
        "          [tf.keras.layers.experimental.preprocessing.StringLookup(\n",
        "              vocabulary=vocabulary, mask_token=None),\n",
        "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
        "                                     self.embedding_dimension)\n",
        "    ])\n",
        "      \n",
        "    # grapes_id embedding\n",
        "    # labels_embedding_layer = tf.keras.layers.Embedding(input_dim = 1740, output_dim = 50, \n",
        "    #                                         mask_zero=True, trainable=True, name='labels_embeddings')\n",
        "    \n",
        "    # avg_embeddings = MaskedEmbeddingsAggregatorLayer(agg_mode='mean', name='aggregate_embeddings')\n",
        "    # l2_norm_1 = L2NormLayer(name='l2_norm_1')\n",
        "\n",
        "    # input_grapes = vocabularies['grapes_id']\n",
        "    # grapes_embeddings = labels_embedding_layer(input_grapes)\n",
        "    # l2_norm_grapes = l2_norm_1(grapes_embeddings)\n",
        "    # self._embeddings['grapes_id'] = tf.keras.Sequential(\n",
        "    #     [avg_embeddings(l2_norm_grapes), tf.keras.layers.Embedding(1739 + 1, \n",
        "    #                                                               50)]\n",
        "    # )\n",
        "\n",
        "    # self._embeddings['grapes_id'] = avg_embeddings(l2_norm_grapes).flatten()\n",
        "\n",
        "\n",
        "    # Compute embeddings for int features.\n",
        "    for feature_name in int_features:\n",
        "      vocabulary = vocabularies[feature_name]\n",
        "      self._embeddings[feature_name] = tf.keras.Sequential(\n",
        "          [tf.keras.layers.experimental.preprocessing.IntegerLookup(\n",
        "              vocabulary=vocabulary, mask_value=None),\n",
        "           tf.keras.layers.Embedding(len(vocabulary) + 1,\n",
        "                                     self.embedding_dimension)\n",
        "    ])\n",
        "\n",
        "    if use_cross_layer:\n",
        "      self._cross_layer = tfrs.layers.dcn.Cross(\n",
        "          projection_dim = projection_dim,\n",
        "          kernel_initializer = \"glorot_uniform\")\n",
        "    else:\n",
        "      self._cross_layer = None\n",
        "\n",
        "    self._deep_layers = [tf.keras.layers.Dense(layer_size, activation=\"relu\")\n",
        "      for layer_size in deep_layer_sizes]\n",
        "\n",
        "    self._logit_layer = tf.keras.layers.Dense(1)\n",
        "\n",
        "    self.task = tfrs.tasks.Ranking(\n",
        "      # loss=tf.keras.losses.MeanSquaredError(),\n",
        "      loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "      metrics=[\n",
        "              #  tf.keras.metrics.RootMeanSquaredError(\"RMSE\")\n",
        "               tf.keras.metrics.BinaryAccuracy(\n",
        "                  name='binary_accuracy', dtype = None, threshold = 0.5)\n",
        "               ]\n",
        "    )\n",
        "\n",
        "  def call(self, features):\n",
        "    # Concatenate embeddings\n",
        "    embeddings = []\n",
        "    for feature_name in self._all_features:\n",
        "      embedding_fn = self._embeddings[feature_name]\n",
        "      embeddings.append(embedding_fn(features[feature_name]))\n",
        "\n",
        "    x = tf.concat(embeddings, axis=1)\n",
        "\n",
        "    # Build Cross Network\n",
        "    if self._cross_layer is not None:\n",
        "      x = self._cross_layer(x)\n",
        "    \n",
        "    # Build Deep Network\n",
        "    for deep_layer in self._deep_layers:\n",
        "      x = deep_layer(x)\n",
        "\n",
        "    return self._logit_layer(x)\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    labels = features.pop(\"like\")\n",
        "    scores = self(features)\n",
        "    return self.task(\n",
        "        labels=labels,\n",
        "        predictions=scores,\n",
        "    )"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrcazKx4JNB5"
      },
      "source": [
        "learning_rate = 0.001\n",
        "\n",
        "cached_train = tensor_train.shuffle(100_000).batch(8192).cache()\n",
        "cached_test = tensor_test.batch(4096).cache()"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uikNZ3VyJSis"
      },
      "source": [
        "model = DCN(use_cross_layer = True,\n",
        "            deep_layer_sizes = [256, 128, 64],\n",
        "            projection_dim = 50)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAdCJ3j6Jdpf"
      },
      "source": [
        "# 4. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3CT807rJlVJ"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "cached_test_numpy = tfds.as_numpy(cached_test)\n",
        "y_true = [item['like'] for item in cached_test_numpy]\n",
        "y_true = np.concatenate(y_true)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iakFdv6YQU72"
      },
      "source": [
        "def get_result(model):\n",
        "  y_pred = model.predict(cached_test).flatten()\n",
        "  y_pred_class = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
        "\n",
        "  print(f\"ROC: {roc_auc_score(y_true, y_pred)}\")\n",
        "  print(classification_report(y_true, y_pred_class))"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1fBus_2VWwA"
      },
      "source": [
        "import keras\n",
        "callbacks_list = [\n",
        "                  keras.callbacks.EarlyStopping(\n",
        "                    monitor = 'binary_accuracy',\n",
        "                    patience = 15\n",
        "                  )\n",
        "]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3L_YebbQ92b",
        "outputId": "d7b5a0bd-ddf5-480c-f20a-f331c06f616d"
      },
      "source": [
        "history = model.fit(cached_train,\n",
        "                     epochs = 500,\n",
        "                     callbacks = callbacks_list,\n",
        "                     verbose = True)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "94/94 [==============================] - 21s 201ms/step - binary_accuracy: 0.6379 - loss: 0.6752 - regularization_loss: 0.0000e+00 - total_loss: 0.6752\n",
            "Epoch 2/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.7191 - loss: 0.5573 - regularization_loss: 0.0000e+00 - total_loss: 0.5573\n",
            "Epoch 3/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7396 - loss: 0.5202 - regularization_loss: 0.0000e+00 - total_loss: 0.5202\n",
            "Epoch 4/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.7460 - loss: 0.5042 - regularization_loss: 0.0000e+00 - total_loss: 0.5042\n",
            "Epoch 5/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.7496 - loss: 0.4967 - regularization_loss: 0.0000e+00 - total_loss: 0.4967\n",
            "Epoch 6/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.7453 - loss: 0.4972 - regularization_loss: 0.0000e+00 - total_loss: 0.4972\n",
            "Epoch 7/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.7295 - loss: 0.5108 - regularization_loss: 0.0000e+00 - total_loss: 0.5108\n",
            "Epoch 8/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.7556 - loss: 0.4895 - regularization_loss: 0.0000e+00 - total_loss: 0.4895\n",
            "Epoch 9/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7606 - loss: 0.4748 - regularization_loss: 0.0000e+00 - total_loss: 0.4748\n",
            "Epoch 10/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.7627 - loss: 0.4696 - regularization_loss: 0.0000e+00 - total_loss: 0.4696\n",
            "Epoch 11/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7657 - loss: 0.4596 - regularization_loss: 0.0000e+00 - total_loss: 0.4596\n",
            "Epoch 12/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.7694 - loss: 0.4509 - regularization_loss: 0.0000e+00 - total_loss: 0.4509\n",
            "Epoch 13/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7740 - loss: 0.4427 - regularization_loss: 0.0000e+00 - total_loss: 0.4427\n",
            "Epoch 14/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.7778 - loss: 0.4377 - regularization_loss: 0.0000e+00 - total_loss: 0.4377\n",
            "Epoch 15/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7764 - loss: 0.4457 - regularization_loss: 0.0000e+00 - total_loss: 0.4457\n",
            "Epoch 16/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.7490 - loss: 0.4822 - regularization_loss: 0.0000e+00 - total_loss: 0.4822\n",
            "Epoch 17/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7707 - loss: 0.4564 - regularization_loss: 0.0000e+00 - total_loss: 0.4564\n",
            "Epoch 18/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.7844 - loss: 0.4316 - regularization_loss: 0.0000e+00 - total_loss: 0.4316\n",
            "Epoch 19/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.7943 - loss: 0.4090 - regularization_loss: 0.0000e+00 - total_loss: 0.4090\n",
            "Epoch 20/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.7986 - loss: 0.4014 - regularization_loss: 0.0000e+00 - total_loss: 0.4014\n",
            "Epoch 21/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.7986 - loss: 0.3969 - regularization_loss: 0.0000e+00 - total_loss: 0.3969\n",
            "Epoch 22/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.8086 - loss: 0.3891 - regularization_loss: 0.0000e+00 - total_loss: 0.3891\n",
            "Epoch 23/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.8130 - loss: 0.3810 - regularization_loss: 0.0000e+00 - total_loss: 0.3810\n",
            "Epoch 24/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8144 - loss: 0.3808 - regularization_loss: 0.0000e+00 - total_loss: 0.3808\n",
            "Epoch 25/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8201 - loss: 0.3686 - regularization_loss: 0.0000e+00 - total_loss: 0.3686\n",
            "Epoch 26/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.8308 - loss: 0.3489 - regularization_loss: 0.0000e+00 - total_loss: 0.3489\n",
            "Epoch 27/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8384 - loss: 0.3355 - regularization_loss: 0.0000e+00 - total_loss: 0.3355\n",
            "Epoch 28/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8467 - loss: 0.3213 - regularization_loss: 0.0000e+00 - total_loss: 0.3213\n",
            "Epoch 29/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8535 - loss: 0.3113 - regularization_loss: 0.0000e+00 - total_loss: 0.3113\n",
            "Epoch 30/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8584 - loss: 0.3068 - regularization_loss: 0.0000e+00 - total_loss: 0.3068\n",
            "Epoch 31/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8625 - loss: 0.3043 - regularization_loss: 0.0000e+00 - total_loss: 0.3043\n",
            "Epoch 32/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8702 - loss: 0.2884 - regularization_loss: 0.0000e+00 - total_loss: 0.2884\n",
            "Epoch 33/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8765 - loss: 0.2787 - regularization_loss: 0.0000e+00 - total_loss: 0.2787\n",
            "Epoch 34/500\n",
            "94/94 [==============================] - 7s 71ms/step - binary_accuracy: 0.8826 - loss: 0.2725 - regularization_loss: 0.0000e+00 - total_loss: 0.2725\n",
            "Epoch 35/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8749 - loss: 0.2915 - regularization_loss: 0.0000e+00 - total_loss: 0.2915\n",
            "Epoch 36/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8816 - loss: 0.2808 - regularization_loss: 0.0000e+00 - total_loss: 0.2808\n",
            "Epoch 37/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8904 - loss: 0.2598 - regularization_loss: 0.0000e+00 - total_loss: 0.2598\n",
            "Epoch 38/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8910 - loss: 0.2644 - regularization_loss: 0.0000e+00 - total_loss: 0.2644\n",
            "Epoch 39/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8784 - loss: 0.2939 - regularization_loss: 0.0000e+00 - total_loss: 0.2939\n",
            "Epoch 40/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8963 - loss: 0.2506 - regularization_loss: 0.0000e+00 - total_loss: 0.2506\n",
            "Epoch 41/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8878 - loss: 0.2692 - regularization_loss: 0.0000e+00 - total_loss: 0.2692\n",
            "Epoch 42/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.8838 - loss: 0.2873 - regularization_loss: 0.0000e+00 - total_loss: 0.2873\n",
            "Epoch 43/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.8933 - loss: 0.2581 - regularization_loss: 0.0000e+00 - total_loss: 0.2581\n",
            "Epoch 44/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9064 - loss: 0.2229 - regularization_loss: 0.0000e+00 - total_loss: 0.2229\n",
            "Epoch 45/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9140 - loss: 0.2049 - regularization_loss: 0.0000e+00 - total_loss: 0.2049\n",
            "Epoch 46/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9186 - loss: 0.1956 - regularization_loss: 0.0000e+00 - total_loss: 0.1956\n",
            "Epoch 47/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9230 - loss: 0.1895 - regularization_loss: 0.0000e+00 - total_loss: 0.1895\n",
            "Epoch 48/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9251 - loss: 0.1912 - regularization_loss: 0.0000e+00 - total_loss: 0.1912\n",
            "Epoch 49/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9133 - loss: 0.2282 - regularization_loss: 0.0000e+00 - total_loss: 0.2282\n",
            "Epoch 50/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9160 - loss: 0.2200 - regularization_loss: 0.0000e+00 - total_loss: 0.2200\n",
            "Epoch 51/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9176 - loss: 0.2114 - regularization_loss: 0.0000e+00 - total_loss: 0.2114\n",
            "Epoch 52/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9084 - loss: 0.2390 - regularization_loss: 0.0000e+00 - total_loss: 0.2390\n",
            "Epoch 53/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9109 - loss: 0.2368 - regularization_loss: 0.0000e+00 - total_loss: 0.2368\n",
            "Epoch 54/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9181 - loss: 0.2166 - regularization_loss: 0.0000e+00 - total_loss: 0.2166\n",
            "Epoch 55/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9286 - loss: 0.1869 - regularization_loss: 0.0000e+00 - total_loss: 0.1869\n",
            "Epoch 56/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9328 - loss: 0.1751 - regularization_loss: 0.0000e+00 - total_loss: 0.1751\n",
            "Epoch 57/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9344 - loss: 0.1762 - regularization_loss: 0.0000e+00 - total_loss: 0.1762\n",
            "Epoch 58/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9131 - loss: 0.2319 - regularization_loss: 0.0000e+00 - total_loss: 0.2319\n",
            "Epoch 59/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9225 - loss: 0.2076 - regularization_loss: 0.0000e+00 - total_loss: 0.2076\n",
            "Epoch 60/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9143 - loss: 0.2230 - regularization_loss: 0.0000e+00 - total_loss: 0.2230\n",
            "Epoch 61/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9295 - loss: 0.1851 - regularization_loss: 0.0000e+00 - total_loss: 0.1851\n",
            "Epoch 62/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9320 - loss: 0.1804 - regularization_loss: 0.0000e+00 - total_loss: 0.1804\n",
            "Epoch 63/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9385 - loss: 0.1625 - regularization_loss: 0.0000e+00 - total_loss: 0.1625\n",
            "Epoch 64/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9388 - loss: 0.1639 - regularization_loss: 0.0000e+00 - total_loss: 0.1639\n",
            "Epoch 65/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9429 - loss: 0.1557 - regularization_loss: 0.0000e+00 - total_loss: 0.1557\n",
            "Epoch 66/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9390 - loss: 0.1730 - regularization_loss: 0.0000e+00 - total_loss: 0.1730\n",
            "Epoch 67/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9422 - loss: 0.1633 - regularization_loss: 0.0000e+00 - total_loss: 0.1633\n",
            "Epoch 68/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.9451 - loss: 0.1570 - regularization_loss: 0.0000e+00 - total_loss: 0.1570\n",
            "Epoch 69/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9256 - loss: 0.2427 - regularization_loss: 0.0000e+00 - total_loss: 0.2427\n",
            "Epoch 70/500\n",
            "94/94 [==============================] - 7s 72ms/step - binary_accuracy: 0.9000 - loss: 0.2703 - regularization_loss: 0.0000e+00 - total_loss: 0.2703\n",
            "Epoch 71/500\n",
            "94/94 [==============================] - 7s 73ms/step - binary_accuracy: 0.9000 - loss: 0.2653 - regularization_loss: 0.0000e+00 - total_loss: 0.2653\n",
            "Epoch 72/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9162 - loss: 0.2201 - regularization_loss: 0.0000e+00 - total_loss: 0.2201\n",
            "Epoch 73/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9351 - loss: 0.1750 - regularization_loss: 0.0000e+00 - total_loss: 0.1750\n",
            "Epoch 74/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9390 - loss: 0.1624 - regularization_loss: 0.0000e+00 - total_loss: 0.1624\n",
            "Epoch 75/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9426 - loss: 0.1539 - regularization_loss: 0.0000e+00 - total_loss: 0.1539\n",
            "Epoch 76/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9461 - loss: 0.1441 - regularization_loss: 0.0000e+00 - total_loss: 0.1441\n",
            "Epoch 77/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9484 - loss: 0.1398 - regularization_loss: 0.0000e+00 - total_loss: 0.1398\n",
            "Epoch 78/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9493 - loss: 0.1436 - regularization_loss: 0.0000e+00 - total_loss: 0.1436\n",
            "Epoch 79/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9298 - loss: 0.1982 - regularization_loss: 0.0000e+00 - total_loss: 0.1982\n",
            "Epoch 80/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9442 - loss: 0.1598 - regularization_loss: 0.0000e+00 - total_loss: 0.1598\n",
            "Epoch 81/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9249 - loss: 0.2045 - regularization_loss: 0.0000e+00 - total_loss: 0.2045\n",
            "Epoch 82/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9172 - loss: 0.2623 - regularization_loss: 0.0000e+00 - total_loss: 0.2623\n",
            "Epoch 83/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9168 - loss: 0.2353 - regularization_loss: 0.0000e+00 - total_loss: 0.2353\n",
            "Epoch 84/500\n",
            "94/94 [==============================] - 7s 74ms/step - binary_accuracy: 0.9238 - loss: 0.2114 - regularization_loss: 0.0000e+00 - total_loss: 0.2114\n",
            "Epoch 85/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9352 - loss: 0.1812 - regularization_loss: 0.0000e+00 - total_loss: 0.1812\n",
            "Epoch 86/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9417 - loss: 0.1599 - regularization_loss: 0.0000e+00 - total_loss: 0.1599\n",
            "Epoch 87/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9441 - loss: 0.1536 - regularization_loss: 0.0000e+00 - total_loss: 0.1536\n",
            "Epoch 88/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9461 - loss: 0.1487 - regularization_loss: 0.0000e+00 - total_loss: 0.1487\n",
            "Epoch 89/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9473 - loss: 0.1488 - regularization_loss: 0.0000e+00 - total_loss: 0.1488\n",
            "Epoch 90/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9505 - loss: 0.1390 - regularization_loss: 0.0000e+00 - total_loss: 0.1390\n",
            "Epoch 91/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9521 - loss: 0.1359 - regularization_loss: 0.0000e+00 - total_loss: 0.1359\n",
            "Epoch 92/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9532 - loss: 0.1341 - regularization_loss: 0.0000e+00 - total_loss: 0.1341\n",
            "Epoch 93/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9543 - loss: 0.1336 - regularization_loss: 0.0000e+00 - total_loss: 0.1336\n",
            "Epoch 94/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9530 - loss: 0.1429 - regularization_loss: 0.0000e+00 - total_loss: 0.1429\n",
            "Epoch 95/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9550 - loss: 0.1366 - regularization_loss: 0.0000e+00 - total_loss: 0.1366\n",
            "Epoch 96/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9553 - loss: 0.1365 - regularization_loss: 0.0000e+00 - total_loss: 0.1365\n",
            "Epoch 97/500\n",
            "94/94 [==============================] - 7s 78ms/step - binary_accuracy: 0.9549 - loss: 0.1400 - regularization_loss: 0.0000e+00 - total_loss: 0.1400\n",
            "Epoch 98/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9539 - loss: 0.1465 - regularization_loss: 0.0000e+00 - total_loss: 0.1465\n",
            "Epoch 99/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9561 - loss: 0.1390 - regularization_loss: 0.0000e+00 - total_loss: 0.1390\n",
            "Epoch 100/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9585 - loss: 0.1308 - regularization_loss: 0.0000e+00 - total_loss: 0.1308\n",
            "Epoch 101/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9598 - loss: 0.1267 - regularization_loss: 0.0000e+00 - total_loss: 0.1267\n",
            "Epoch 102/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9581 - loss: 0.1391 - regularization_loss: 0.0000e+00 - total_loss: 0.1391\n",
            "Epoch 103/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9552 - loss: 0.1489 - regularization_loss: 0.0000e+00 - total_loss: 0.1489\n",
            "Epoch 104/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9168 - loss: 0.2473 - regularization_loss: 0.0000e+00 - total_loss: 0.2473\n",
            "Epoch 105/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9432 - loss: 0.1706 - regularization_loss: 0.0000e+00 - total_loss: 0.1706\n",
            "Epoch 106/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9527 - loss: 0.1417 - regularization_loss: 0.0000e+00 - total_loss: 0.1417\n",
            "Epoch 107/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9565 - loss: 0.1281 - regularization_loss: 0.0000e+00 - total_loss: 0.1281\n",
            "Epoch 108/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9588 - loss: 0.1203 - regularization_loss: 0.0000e+00 - total_loss: 0.1203\n",
            "Epoch 109/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9597 - loss: 0.1183 - regularization_loss: 0.0000e+00 - total_loss: 0.1183\n",
            "Epoch 110/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9608 - loss: 0.1177 - regularization_loss: 0.0000e+00 - total_loss: 0.1177\n",
            "Epoch 111/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9611 - loss: 0.1209 - regularization_loss: 0.0000e+00 - total_loss: 0.1209\n",
            "Epoch 112/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9605 - loss: 0.1282 - regularization_loss: 0.0000e+00 - total_loss: 0.1282\n",
            "Epoch 113/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9621 - loss: 0.1227 - regularization_loss: 0.0000e+00 - total_loss: 0.1227\n",
            "Epoch 114/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9610 - loss: 0.1314 - regularization_loss: 0.0000e+00 - total_loss: 0.1314\n",
            "Epoch 115/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9263 - loss: 0.2369 - regularization_loss: 0.0000e+00 - total_loss: 0.2369\n",
            "Epoch 116/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9365 - loss: 0.1912 - regularization_loss: 0.0000e+00 - total_loss: 0.1912\n",
            "Epoch 117/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9522 - loss: 0.1463 - regularization_loss: 0.0000e+00 - total_loss: 0.1463\n",
            "Epoch 118/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9547 - loss: 0.1393 - regularization_loss: 0.0000e+00 - total_loss: 0.1393\n",
            "Epoch 119/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9563 - loss: 0.1326 - regularization_loss: 0.0000e+00 - total_loss: 0.1326\n",
            "Epoch 120/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9338 - loss: 0.2167 - regularization_loss: 0.0000e+00 - total_loss: 0.2167\n",
            "Epoch 121/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9343 - loss: 0.1984 - regularization_loss: 0.0000e+00 - total_loss: 0.1984\n",
            "Epoch 122/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9373 - loss: 0.1830 - regularization_loss: 0.0000e+00 - total_loss: 0.1830\n",
            "Epoch 123/500\n",
            "94/94 [==============================] - 7s 75ms/step - binary_accuracy: 0.9514 - loss: 0.1427 - regularization_loss: 0.0000e+00 - total_loss: 0.1427\n",
            "Epoch 124/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9453 - loss: 0.1619 - regularization_loss: 0.0000e+00 - total_loss: 0.1619\n",
            "Epoch 125/500\n",
            "94/94 [==============================] - 7s 76ms/step - binary_accuracy: 0.9303 - loss: 0.2132 - regularization_loss: 0.0000e+00 - total_loss: 0.2132\n",
            "Epoch 126/500\n",
            "94/94 [==============================] - 7s 77ms/step - binary_accuracy: 0.9494 - loss: 0.1466 - regularization_loss: 0.0000e+00 - total_loss: 0.1466\n",
            "Epoch 127/500\n",
            "94/94 [==============================] - 7s 79ms/step - binary_accuracy: 0.9542 - loss: 0.1325 - regularization_loss: 0.0000e+00 - total_loss: 0.1325\n",
            "Epoch 128/500\n",
            "94/94 [==============================] - 7s 79ms/step - binary_accuracy: 0.9549 - loss: 0.1301 - regularization_loss: 0.0000e+00 - total_loss: 0.1301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcG3Ha52O8lI"
      },
      "source": [
        "pred = model.predict(cached_test).flatten()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "g2a68Z-7KRQ7",
        "outputId": "96a994df-35bb-4209-98d3-c158cd3442ea"
      },
      "source": [
        "pd.DataFrame(zip(model.predict(cached_train), add_train['rating_per_user'].values))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[3.7662323]</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[4.6074934]</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[4.6604505]</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[4.1400437]</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[3.9927986]</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763382</th>\n",
              "      <td>[3.8313277]</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763383</th>\n",
              "      <td>[4.5237317]</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763384</th>\n",
              "      <td>[4.633769]</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763385</th>\n",
              "      <td>[4.361144]</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>763386</th>\n",
              "      <td>[3.0272295]</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>763387 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0    1\n",
              "0       [3.7662323]  4.0\n",
              "1       [4.6074934]  4.0\n",
              "2       [4.6604505]  4.0\n",
              "3       [4.1400437]  4.5\n",
              "4       [3.9927986]  4.0\n",
              "...             ...  ...\n",
              "763382  [3.8313277]  3.0\n",
              "763383  [4.5237317]  4.0\n",
              "763384   [4.633769]  4.5\n",
              "763385   [4.361144]  3.0\n",
              "763386  [3.0272295]  3.5\n",
              "\n",
              "[763387 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f10TwemRD14",
        "outputId": "388af44e-2a08-49d2-cdde-7b7440382d17"
      },
      "source": [
        "get_result(model)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROC: 0.9448528879987997\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90     88227\n",
            "           1       0.91      0.91      0.91    100491\n",
            "\n",
            "    accuracy                           0.90    188718\n",
            "   macro avg       0.90      0.90      0.90    188718\n",
            "weighted avg       0.90      0.90      0.90    188718\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPjKUFedR27j",
        "outputId": "3b21ad13-075b-43ae-f3be-381da730bc49"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"dcn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_11 (Sequential)   (None, 32)                2112      \n",
            "_________________________________________________________________\n",
            "sequential_12 (Sequential)   (None, 32)                896       \n",
            "_________________________________________________________________\n",
            "sequential_10 (Sequential)   (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "sequential_4 (Sequential)    (None, 32)                1792      \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 32)                96        \n",
            "_________________________________________________________________\n",
            "sequential_8 (Sequential)    (None, 32)                864       \n",
            "_________________________________________________________________\n",
            "sequential_7 (Sequential)    (None, 32)                254688    \n",
            "_________________________________________________________________\n",
            "sequential_5 (Sequential)    (None, 32)                61152     \n",
            "_________________________________________________________________\n",
            "sequential_9 (Sequential)    (None, 32)                33152     \n",
            "_________________________________________________________________\n",
            "sequential_6 (Sequential)    (None, 32)                160       \n",
            "_________________________________________________________________\n",
            "sequential_2 (Sequential)    (None, 32)                256       \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 32)                203008    \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 32)                1627264   \n",
            "_________________________________________________________________\n",
            "cross (Cross)                multiple                  173472    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  106752    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  32896     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              multiple                  65        \n",
            "_________________________________________________________________\n",
            "ranking (Ranking)            multiple                  2         \n",
            "=================================================================\n",
            "Total params: 2,507,171\n",
            "Trainable params: 2,507,169\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc-ek27ySuOp"
      },
      "source": [
        "pred = model.predict(cached_test)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTf6e-t7hbhY"
      },
      "source": [
        "def makeTEST(df, id):\n",
        "  df['userID'] = id\n",
        "  df['like'] = 0\n",
        "  return df"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkDiBOZTgmMk",
        "outputId": "4950ed33-5366-46d3-ab10-c39751e59a95"
      },
      "source": [
        "temp = makeTEST(selected_item, 1201)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVBirQyRgoEC",
        "outputId": "39035b10-6b31-4f84-ae54-71000771a21f"
      },
      "source": [
        "add_temp = setType(temp)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1njtA74jtUQ",
        "outputId": "0a6eae23-f128-4afe-f9e0-e76fcaf30f75"
      },
      "source": [
        "temp_str_dict = {\n",
        "    str_feature: [str(val).encode() for val in add_temp[str_feature].values]\n",
        "    for str_feature in str_features\n",
        "}\n",
        "\n",
        "temp_int_dict = {\n",
        "    int_feature: add_temp[int_feature].values\n",
        "    for int_feature in int_features\n",
        "}\n",
        "\n",
        "temp_str_dict.update(temp_int_dict)\n",
        "temp_str_dict.keys()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol', 'like'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyXQuWmmi8_V"
      },
      "source": [
        "tensor_temp = tf.data.Dataset.from_tensor_slices(temp_str_dict)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tjL0fQvjezo"
      },
      "source": [
        "cached_temp = tensor_temp.batch(1024).cache()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wNwA7NHj--u",
        "outputId": "e69bae73-3a73-46bc-b176-2554a7e95ef1"
      },
      "source": [
        "pred = model.predict(cached_temp)\n",
        "pred.shape"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50860, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "7CAlidWrkYcp",
        "outputId": "7e72cb24-70f5-4347-d6bc-3f65aa57252e"
      },
      "source": [
        "pred = pd.DataFrame(pred).sort_values(0, ascending = False)\n",
        "pred.loc[pred[0] == 1]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38876</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7629</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19281</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19278</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19277</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16664</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4318</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4084</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39069</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13705</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1201 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0\n",
              "38876  1.0\n",
              "7629   1.0\n",
              "19281  1.0\n",
              "19278  1.0\n",
              "19277  1.0\n",
              "...    ...\n",
              "16664  1.0\n",
              "4318   1.0\n",
              "4084   1.0\n",
              "39069  1.0\n",
              "13705  1.0\n",
              "\n",
              "[1201 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTDZA6DNoQK-"
      },
      "source": [
        "import seaborn as sns\n",
        "plt.style.use('seaborn') # seaborn ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜\n",
        "sns.set(rc={'figure.figsize' : (15,15)})"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkeui_u9rCjJ",
        "outputId": "dcb0c35c-8947-4fd7-bb79-58bb1a55074a"
      },
      "source": [
        "features"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ListWrapper(['userID', 'wine_id', 'type_id', 'grapes_id', 'country_code', 'region_id', 'segment', 'rating_count', 'rating_average', 'review_count', 'body', 'acidity_y', 'alcohol'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951
        },
        "id": "DTX_1G6vkGiR",
        "outputId": "14c26832-d393-4c2e-d6e3-21c6325c0acd"
      },
      "source": [
        "mat = model._cross_layer._dense.kernel\n",
        "features = model._all_features\n",
        "block_norm = np.ones([len(features), len(features)])\n",
        "\n",
        "dim = model.embedding_dimension\n",
        "\n",
        "# Compute the norms of the blocks.\n",
        "for i in range(len(features)):\n",
        "  for j in range(len(features)):\n",
        "    block = mat[i * dim:(i + 1) * dim,\n",
        "                j * dim:(j + 1) * dim]\n",
        "    block_norm[i,j] = np.linalg.norm(block, ord=\"fro\")\n",
        "\n",
        "plt.figure(figsize=(25,25))\n",
        "im = plt.matshow(block_norm, cmap=plt.cm.Blues)\n",
        "ax = plt.gca()\n",
        "divider = make_axes_locatable(plt.gca())\n",
        "cax = divider.append_axes(\"right\", size=\"1%\", pad=0.001)\n",
        "plt.colorbar(im, cax=cax)\n",
        "cax.tick_params(labelsize=10)\n",
        "_ = ax.set_xticklabels([\"\"] + features, rotation=45, ha=\"left\", fontsize=10)\n",
        "_ = ax.set_yticklabels([\"\"] + features, fontsize=10)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x1800 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA70AAAOVCAYAAAClIof3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3xUVf7/8ffNpBFSSEJISEJLAiSht9CkrICI1BVREcXlq/5UUEEFBJdVEBRRYREQ6SpN3S9FBEEUEQSBaDBUQZoQQgkSSippM78/3MxXVlA3EO/k5vV8PPJ4wDAz5zOc3Dv3c8/nnGM4HA6HAAAAAACwIDezAwAAAAAAoLSQ9AIAAAAALIukFwAAAABgWSS9AAAAAADLIukFAAAAAFgWSS8AAAAAwLJIegEAAAAAlkXSCwAAAACwLJJeAAAAmMrhcJgdAgALI+kFAACAKYqT3ZycnGs+DgA3g7vZAQAAAKD8cTgcMgxDW7Zs0fLly1W/fn2FhoaqZ8+eMgzD7PAAWAgjvQAAAPhTFSe8SUlJevXVV/XQQw9px44d2rp1q/Ly8swOD4DFkPQCAADgT3Hq1CmlpKTIMAzZ7XadPHlSw4cPl8Ph0MWLFzV06FB5eXnp9OnTZocKwEJIegEAAPCnWLt2rQYMGKDjx4/Lzc1NQUFBmjRpksaMGaM5c+YoPDxcGzdu1MqVK5Wfn292uAAsgqQXAAAApap4YapHHnlEXbt21XPPPadjx46pRYsWatKkidq3by+73a7du3frn//8p+Lj4+Xp6Wly1ACswnCwPB4AAAD+BF9//bXWrl2r77//XufPn9eSJUt0+fJlbdy4UV999ZUqVaqk/v37q3Pnzs55vwBwo0h6AQAAUOpOnjyphx9+WBMnTlTTpk01depUrVu3TrNnz1bNmjV18eJFubu7y8/Pj4QXwE1FeTMAAABKXWBgoOrXr6/IyEhJ0rBhw9SgQQPdc889+vHHHxUYGCg/Pz9JIuEFcFOR9AIAAOCmKy4mvHLlivLy8uTr66vc3Fxt3LjR+ZyePXsqIiJCly9fNitMAOUA5c0AAAAoFZs2bdLChQvl6empdu3aqVWrVho+fLhat24tX19fff7553rppZfUoEEDs0MFYGHuZgcAAACspXg+pt1ul5sbRWXl1f79+zV16lSNHj1afn5+GjlypBwOh+bPn6/PPvtMZ86c0dNPP03CC6DUkfQCAICb5sKFC1q2bJnuu+8++fr6siBROZadna34+Hi1bNlSkrRw4ULdddddqlmzpu69917n8/gdAVDauP0KAABumiNHjig1NVXvvvuusrOzZRiGmElVPhT38549e5SRkaEKFSro/PnzOnfunCQpKChIffv2VVFR0VWvI+G1DrvdbnYIwDWR9AIAgJsmISFBzZs318mTJ7VkyRLl5OQ4S51hbYZhaPPmzRo1apSOHDmiBg0aqEaNGnr++ee1ceNGbdiwQR9//LEqVqxodqi4ic6ePavBgwdLktzc3DjW4ZJYyAoAANw0mzZt0qxZs1SlShVdvnxZzZs316BBg+Tr68scX4s7e/asHn30UY0dO1ZNmjRxPj5nzhxduHBBJ06c0L333qsOHTqYGCVKw7333itfX1/NmzdPkjjW4XJIegEAQIllZWXJy8tLHh4eysrK0lNPPaURI0YoLi5Omzdv1pYtW1SlShXdf//98vHxMTtclKKTJ09q7Nixmj9/vqSftyry9vZ2/ntubq4qVKhgVngoBQUFBfLw8NCZM2d03333KS4uTjNnzpRE4mtldrtdJ06cUK1atXTs2DF5e3srPDzc7LB+E7+JAACgRLKzs/Xaa68pMzNTkmSz2ZSVlaVTp05Jklq3bq3KlStrzZo1mjdv3q/mcsJaqlWrJsMw9N5770mSvL29tXXrVo0ePVoFBQXy9PQ0OULcbB4eHtqwYYPGjBmj++67Tz/++KMGDhwoiVJnKzt9+rTef/99TZgwQWPHji0T53aSXgAAUCIVK1bUsGHDlJ2drbVr16pChQq6//77tWnTJn333Xfy9PRU48aNFRsbqzvuuEM2m83skFFKigsHBw4cqKNHj2rEiBHasGGDJk2apNtuu00eHh70v0WcP39eJ0+elCQVFhZq1apV6t27tx555BGtW7dONptNjz32mCQx0mtRERER8vPz04oVK9SoUSNVq1ZNkmsvZGYbO3bsWLODAFA2ZWZmysvLy+wwYBK2GYEkVahQQTt27NDcuXMVFBSkunXrKjc3VzNnztSJEyc0Z84cPfbYY2rcuLHZoaIU2O12GYbhPBeEhoaqbt26OnDggHJyctSnTx917NiR84VF5Ofn69NPP1VYWJh8fHzk6emppKQkRUZGqnbt2pKk2NhYTZ06VTt37lSvXr1Mjhg3U/FxXPwTGRmpw4cPKycnR/Hx8TIMQ7m5ufLw8DA71F8h6QVQIleuXNFjjz2mjIwMLmbLmaysLNntdnl4eHAhC0lSTEyMgoKCtGjRItWsWVNdunRRkyZN5Onpqbvuusu5Tyus49ChQwoKCvrVSJ67u7sCAgLUoUMHJSQkqGbNms5RYM4VZZ/NZlOtWrVks9k0efJk1a5dWxUrVtSLL76o9u3bKzg4WKmpqQoMDFSvXr0UGRlpdsi4iQzDUFJSkpKTkxUaGqrbb79dNptNn3zyibOaY+XKlYqPj3e5xJekF0CJuLu7q1atWpo7d648PDwUFxdndkj4E2RlZWnOnDlKSUlR7dq1SXzh7P/o6Gj5+Pho6dKl8vLyUvv27VW3bl1VrVrV7BBxk+Xl5Wn69OkqLCxUTEzMNc8BxSPAkq4aCUbZ5+HhoZSUFJ04cULffvut+vbtq4iICL300ks6duyYZsyYoUGDBqlVq1Z8P1jMN998o2effVYBAQGaMGGCoqOj1aVLF3l7e2vRokVatGiR7r77bkVHR5sd6q+Q9AL4rxV/iV26dEnp6elavny5fH19SXzLAZvNprS0NB0/flzp6emKiYmRu7s7FzblmGEYzv6PiYmRp6enli5dqvbt27Mfq0U5HA4dOXJE58+fV0JCwq+O/aKiIueiZkeOHFFISIhJkaK0VK5cWcHBwTp16pS+/PJL9e/fX127dlV0dLS6d++uZs2aSWJ030oOHz6sjz76SA8//LDuu+8+xcbGavjw4YqJiVHnzp3VsWNHderUSU2bNjU71Gsi6QXwXzMMQ9u2bdPw4cN11113KSwsTCtXrpQk1a9f3+ToUFqKL2QvXbqkrVu3KikpSd7e3qpRowYjvuVAcf+mpaXJzc3tqtK1Xya+tWvXVvv27Ul0LOjQoUM6f/68qlSpourVq+vNN99URESEatSo4XxO8XkiMzNTDz74oNq3b6/Q0FATo0ZpqVy5sipVqqSzZ8/q008/Vf369RUbG0t/W0zxuf2DDz7Q9u3bVblyZcXGxiomJkaxsbF6/PHHVbNmTTVq1EjBwcFmh3tdJL34r9jtdi5sy6nz58/r22+/Vc2aNSVJX331lRo2bKh+/fqpWbNmioqK0owZM+Tl5aX4+Hhzg0WpcHNzU1JSkl544QXnfO5z587p0qVLio6OZsTXwor79YsvvtBbb72lRo0aKTAw8KrnFCe+drtdvr6+V5W3ouxLTk7W6tWrNX36dHl7e8tmsykuLk7Z2dmKjY2V3W6X3W53JrxPPPGEhg8friZNmpgdOkpR5cqV5efnp3PnzikmJsalkx78d4rP++fPn5ePj48SEhJkt9t16NAh+fv7KyQkRNHR0WrQoIEqVKhw1c0vV+RudgAoO77++mtt2bJFhw8fVuPGjdWwYUN16NDB7LDwJ9m5c6fq1q2rjIwM+fj4yGazafXq1XrwwQdls9nUoEED1ahRQ7Nnz1bbtm0VGhrKBa8FnDhxQpcvX1bDhg0lSfv27VPnzp3VoUMHtW3bVsuXL9fatWtlGIbuuOMOVahQweSIURqKFy+ZPn26Jk2apKioKF25ckV5eXkKCAhwXhwVJz0ZGRlavXq17rrrLlZ4L8OK+/XQoUMaP3685s+fr+7du2vPnj167733tG/fPnl7e6tNmzbOkf3MzEw99NBDGjlypJo3b27yJ8CNuN5c7f9cvCwuLk7VqlWTr6/vdV+HsscwDG3evFkzZsxQo0aNdOnSJb3xxhuaMWOGPv/8cxUWFqpFixbOXMDV+52RXvwhW7Zs0YQJE9S3b1+FhobK3d1d8+fPl6+vr+rWrWt2ePgTxMTESJLefPNNZWVlqW/fvtqxY4dWrFih2267TT/88IMOHjyosWPHqnr16i594sMft2vXLnl4eMjf31+enp7KysrS+vXrFRsbqypVqqh+/fr68MMPlZeXp0aNGjkvemAdxRcyO3bskLu7u+Li4vTZZ59pzpw52rx5s+rVq6dKlSpdVdb66KOPqkePHqpevbrZ4aOEivt99+7dGjFihB555BE1atRIoaGhatiwoTp37qyKFSuqsLBQFy5cUJMmTWQYhk6ePKkWLVo453Si7CpOelatWqWUlBTVrFlTXl5ev6risNvt8vLyUmFhodzc3Pj+t4j9+/dr4sSJeuONN5SZmakvvvhC9913n1q0aKHdu3drz549atGihfNmt6v3O0kvftfWrVs1ZswYzZ49Wy1atFCDBg3UoEEDBQcHa/bs2apRo4ZzU2pYm5ubm1JTU3Xo0CHl5ORo0KBB2r59u1asWKFVq1ZpwIAB3Nm3mJo1a6pixYrq3bu3oqKi1Lx5c6WmpurEiROSpIKCAn355ZcaMmSIatWqZXK0uJmKk56srCx5eXnJMAzt27dP8+fPV5MmTdSmTRtduXJF1apVU5UqVeTm5qaMjAw9+eSTGjZsmFq0aGH2R0AJ5OTkKD8/X56enjp+/LiioqI0b948Xb58WT169JAk57/Xr19fHh4eOnjwoNq3by9JCgoKYsXuMq742D98+LBefPFFRUdH6/jx41q/fr3atm0rLy8vFRUVyc3N7aqbXZMmTVKTJk3k7e1t9kfATXDhwgXVqlVL2dnZWrx4sWbMmKFKlSrp8OHD6t69u2JiYhQWFmZ2mH8YSS9+14YNG3TixAl169ZNgYGBzpNhrVq1lJmZqQsXLrjsSm24eRwOh3OUJy0tTXv37pXD4dCjjz6q2267TXfccYcaNGjg8uUt+O95eXnJx8dH06ZNU+PGjdWoUSOdPn1aixYt0saNGzVo0CD2YbUgwzD05Zdfas6cOdq/f7+8vLx01113qW/fvmrevLmys7P19ttvq2vXrgoJCdGVK1c0ePBgPfnkk9z8KsN27dqlGTNmKDc3V2PHjlXfvn11zz33aPr06Tp16pTat28vm83mHNXbvXu3Vq5cqV69esnT05PzvwUUT2d455139MADD6h///6Ki4vTwYMHtW7dOrVt21be3t4qLCyUu7u7MjMzNXjwYA0cOFBRUVFmh48S+s/rt3Pnzmn48OHauXOnli9frsDAQCUlJWn27Nlq1apVmUp4JZJe/Ibdu3fL4XCoffv2cjgcWrx4scLCwhQRESGHwyGbzaZdu3bp+++/V9euXc0OF6WseJEad3d31alTR+fPn9eOHTuUlZWl+Ph4+fj4sBejBRV/CdarV08VK1bUxIkT1bZtW91xxx3q0qWLbr/9dm52WNSuXbv0yiuvaPz48Vq6dKnOnDmjrl27yt3dXbt27dLIkSP13HPPKSEhQdLPlSCNGzdWvXr1TI4cNyIiIkKffPKJ5s2bp3HjxikuLk7e3t668847NXnyZP3www+69dZbnfM6c3Nz1adPH1WtWpVzgIWcO3dOc+fOVYUKFZzbj9WtW1e7du3SJ598os6dO8vDw8NZ3fHUU09xs6uMKy5nnz17trKzs9WoUSNFRUVpw4YNatCggXbt2qXJkydr0KBBZfI8T9KL6/rwww/15ptv6tZbb1Xr1q11+fJlffTRRwoLC1NkZKQk6fvvv5eXlxejPBZXnND8MvGtXbu2zp8/ryZNmig4OJiLHYv65VY0cXFx8vPz05gxYxQbG6s6derIx8fH+TxYQ3F/f/3112rWrJnc3d21adMmjRs3ToGBgUpPT5ckdenSxZnwFhYWymaz/WpFZ5Qdv7xx5eHhIQ8PD23atElt2rSRn5+fvL291bt3b02dOlUtW7ZUYGCgDMNQ1apVFRQUZHL0uFHF/Z+SkqLc3FzFxMSoY8eOmjFjhry9vVW/fn35+voqPj5eTZo0UUhIiPLz8zV+/Hg98MADznMByq4TJ07ojTfeUHx8vFJTU7V9+3bdcccdio2N1ccff6zTp0/rwQcf1F/+8pcyeaPbcDgcDrODgGv55S/yggULtG7dOk2fPl1hYWFavHixtmzZopEjRyo1NVWvvfaapk2bpujoaJOjxs1S3P8ZGRny9vaWp6enpKtXbCx+TvFcnl8+Bmv4z/785d9Xrlyp8PBwbnZZzH/2+bfffqspU6YoKytL8+bNU2hoqNavX6/du3dr2LBhznMDrCM5OVlnz55VQkKCgoOD9cYbb2jHjh1auHCh9u7dqzNnzqh3796c6y2m+NjfuHGjZs+ercDAQPn7++vuu+9WUFCQhgwZovvvv18DBgy46nU5OTnKyspSlSpVTIocN6q470+ePKnk5GTl5ubqnnvu0cGDB7Vx40alp6froYceUnh4eJm/ziPpxVV++Qv9v//7v2rQoIG++OILffXVV3rzzTcVFhampUuX6p133pFhGJo5c6ZzVV9Yx6ZNmzR//nzFxMTIMAy98MILv3pO8VyevLw85eXlyd/f34RIcbMUH/tpaWmqUqWK8vLyfrUYyW8lwijbivsyKSlJx44dcy5OtWDBAlWrVk0dOnRQQUGBxowZo2HDhunWW281O2TcZN98841efPFFhYWFyc/PT/369VO7du302muvad++fTp//ryGDRum2267zexQcZNcuXJFnp6ecnNz008//aRHHnlEr776qvz9/XXgwAH961//0qhRo3T58mU9/fTTev/998vcPE78vi1btmjs2LEKCwtzbjcnST/88IPWrl2rixcvauTIkfLx8fnVdlVlCfv04irFF7Dr16/Xxx9/rPbt22vIkCFyOBx66qmnNG3aNN13331yOBxq1aoVI7wWlJycrGnTpun111/XF198odWrVysnJ8dZxupwOGS32+Xu7q6MjAyNGTNGI0aMIOkt44oXLXrvvfcUGxsrX19f9e/fX8HBwVc9p/hmR35+voqKitiX1yIMw1BiYqKef/559ejRQ4sWLVL//v3VuHFjXbx4Ua+++qp8fHz01FNP6dZbb+WGh8UcPHhQs2fP1ltvvaWoqCgtWLBAn3/+uSRp5MiROnr0qNzc3FSrVi363iIuXLig5cuX695775Wfn59sNpv8/PwUGxsrSfLz89Pu3bu1bds2DRgwQB999JECAgJMjho32+HDh7Vo0SLNnj1bMTExGjRokJ599llNnjxZdevWlcPhkI+PjyW2Iyy76TpKzcGDB7V48WIlJCQoNDRUdrtdgwcPVseOHfW3v/1NZ8+e1YABA0h4Lcput2vo0KE6efKkNmzYoLfffls+Pj46cOCAJDkXMcvMzNSTTz6p+++/ny2rLOCHH37Q1KlTNWnSJGVnZ2vPnj3y9vbWL4uBioqKnDc7/ud//keXLl0yMWLcTMeOHdMHH3yg0aNH6+mnn9akSZN08OBBGYah//f//p9mzZqlSZMmqXPnziQ9FvHLY/uHH37Qrl279O2330qSBg0apKioKK1Zs0YbNmxQdHS0c0sy+t4a/P391bVrV+Xk5CgpKUlBQUGqXLmyXnzxRUk/J71BQUHO7ekqVqxoZri4iYqP/aKiIn355Zc6dOiQs58XLFigS5cuafDgwZKk2NhYy+y3zkJW+NUFTEFBgc6fP6/ExETVrFlTERERMgxDzZo1U25urqKjoxnVs5D/7P9jx45p9OjR2r9/vxYvXqygoCAlJibqgw8+UNOmTeXj46PMzEw9+uij7MVpAcX9f+TIEQUFBcnDw0Nr1qzRyy+/rMqVK+vIkSPOu/s2m00ZGRkaNmyYBg8e7BwRQNllt9tlGIY2bNigbdu2KScnRwkJCYqIiJCfn59mzJih2267Tf7+/vLy8pJE0mMVhmFo+/btSk9PV8eOHRUYGKjPP/9cPj4+io6OVuPGjXXixAk1bNjwqooPlH3FNzADAgK0YMECbdu2TaGhobrlllu0e/duvfPOO/Ly8tK8efM0aNAgVatWrUyXteJqhmEoOTlZeXl5at++vXJzc7Vv3z75+voqMjJSvXv31gcffKC4uDiFhISYHe5NQ9Jbzv0y4dmwYYMOHDggHx8ftWnTRgUFBUpMTJS/v7/Cw8OdiS8Jr7UUX/isWrVKNptNrVq1cs7tu/XWW5WYmKjXX39dDzzwgOLj41VUVKR58+bp7rvvZnuCMqz42C9eoMwwDL311ltau3at3nnnHVWtWlWbN2/W4sWLnXsyXr58WcOGDdOQIUNYqbOMK+7/y5cvy9vbW/Xq1VOlSpWUkpKijIwM1atXT7m5udq6dau6d+9OGbtF7dixQ0OGDFG7du3UqVMnFRUVafXq1bLZbKpdu7aaNm1KwmtBbm5uOn78uI4ePapevXrpyJEj2rVrl8LDw/XXv/5V6enpunLliv7617+qbdu2ZoeLm6T4vH/o0CHNmjVLixcvVocOHdSuXTulpKRo586d8vb2VrVq1XTnnXdaKuGVSHrLveKE9/3339f777+v6OhoDRkyRF26dFF8fLwuX76sL774QqGhoSxeYDHFJ7+9e/dq/Pjx8vLy0t69e5WSkqJ7771Xbm5uWrlypQ4fPqyHH35YHTt2lMPhkJubm+rVq6caNWqY/RFwA4pvdnz44Yc6efKkKlWqJE9PT1WpUkW5ubm6dOmSXnvtNT3wwAOKi4uTJM2YMUN//etfWbXZAor3Y5wwYYJSUlJ07Ngx9enTR9nZ2Vq9erWWL1+uTZs26eGHH3b2P6wjMzNT7u7uql+/vsLCwjRixAglJCToL3/5i3Jzc/Xxxx87b3Yxsm8dv1ywbvbs2dq2bZtq166tbt26ad++fdq7d6+Cg4PVs2dPNW3alO95iyleu2PcuHHq1q2bHA6Hli5dqtatW6tNmzY6fPiwdu7cqWbNmsnT09Nyxz5Jbzlnt9uVmpqqDz/8UFOnTtWxY8ecpauBgYGqWrWqsrKy1KRJE+ZzWERWVpbzZLZv3z5NnDhR//jHPzRgwADZbDYdPnxYP/74o+6//3717NlTnTp1cs7fLv7CZKuSsi8pKUkTJkxQy5YttWXLFmVlZcnPz09169bVxx9/rFOnTql///7q1KmTs9/btGnD/G2L+Oabb/TKK6/opZde0p49e/TJJ58oPT1dDzzwgHx8fJSenq6EhAT16dNHEit1W8mxY8c0b948VaxYUWFhYapfv76Cg4M1fPhwtW7dWrfeeqtatWqlKlWq0OcWYxiGtm3bpvHjx+uOO+7Q8ePHdebMGfn6+qpXr17auXOndu/erWbNmv1q9X5Yw4cffqju3burb9++zlX5Z8yYoQ4dOqhly5aKj49XWFiYJY99kt5y6JcXL4ZhyM/PTykpKVq3bp2Sk5M1d+5cubu765133lHdunXVunVrS6zahp/31Hv22WfVsmVLVaxYUefOndOCBQtkGIbat2+vWrVqqaioSLt27dLhw4fVqFEjubu7X/X7grIvNTVVb7zxhvr06aMBAwaoefPmSklJ0YULFzRgwADdcccdateunWJiYpznC5Kesq+4D8+ePeu8sfXTTz9p5cqVGjlypD7++GOdPn1a/fv3V2Zmpvbu3avc3FzFxMQwn6+M++Xx6+HhoW+//VZHjhyRn5+fgoOD1aBBAyUmJmrOnDkaMGCAgoKCTI4YN5vD4VBhYaE++OAD/eUvf9E999yjhIQEHTt2TBs3blTNmjXVo0cPxcTEKDQ01OxwUUq+/PJLnTlzRh06dJDNZlNAQIC2bt2qTZs2qU2bNpZZtOpaSHrLmV9+8S1fvlwHDx5U7dq1tXr1an333XdasGCBKlSooHXr1mnRokW6/fbbWaLeQjw8PNS9e3edPXtWO3fuVOvWrdWqVSstXbpUWVlZatq0qWrWrCmHw6FmzZopJCSERMdi0tLSdPjwYR04cED79+9X27ZtFRYWpoiICM2cOVMJCQkKCgqSzWaTJG54WIhhGNq6dauWLVumrl27KiQkRNOmTdMzzzyjFi1a6Ouvv9aBAwfUunVrNWnSRNnZ2WrTpg1VPmVc8fd+cnKy9u/fr0uXLql///7atWuX9u/fLw8PD6WlpSkjI0MjRoygmsOiDMOQzWbT0aNHlZiYqJYtWyokJESRkZFaunSprly5ojp16igiIoKbnBbxy3L2o0eP6sKFC+rWrZtmzZqlixcvqnnz5vrxxx+VlpamgIAAubu7q06dOmaHXWpIesuZ4pPY3LlztWbNGvXr10+hoaFKSEhQYmKitm/frnXr1mnjxo167bXXnFsUwDpOnDih5557TitWrFBERIRuueUWxcfH67333lNaWpoSEhJUq1Yt7vRb0Llz5zRlyhT17NlTbdq00enTp7Vr1y7VqVNH+fn5WrNmjXr27MmNLos6cuSI/vWvf6lXr16KjY1Vfn6+Pv30U9WuXVvp6en6+uuvNW7cOFWrVk02m02xsbHO/blRdhmGoa+++kovv/yyPD09tXLlSiUnJ+v555/X4cOHlZiYqHfffVf33XefWrVqJYlydqso7sc9e/YoMTFR7u7u8vf3V0ZGhk6dOqWoqChlZ2dr+/btOnPmjAIDA1WnTh363iIMw9DGjRs1efJkVa9eXW+++aYiIiLUv39/TZkyRcnJyXr33Xc1evRonTt3Tnl5eWratKnZYZcad7MDwJ/v9OnT2r9/v95//31dvHhR69ev16lTpzRlyhQdOXJEly9fVnR0tMLDw80OFTfJLy9gcnNz1aVLF/n4+Gjy5MnKz89Xnz59NGrUKI0dO1a9evVSZGQkX3oW8cu+r1Klitzc3DRt2jS9/PLLuv3227VkyRINHDhQERERGjVqFKM8FnXy5ElNmDBBubm5KigokMPhkK+vrzp27Kj33pdutSUAACAASURBVHtPFy9e1COPPKKaNWtKIumxErvdrhUrVujJJ5/UbbfdJkm65557NGXKFD3zzDPKz8/X+fPnFR4e7ux3+t4aipOeKVOmqGvXrlq4cKEGDRqkuLg4JSUl6W9/+5vy8vI0Y8YMbd26VWlpaWaHjJsoNzdXy5cv19y5c7Vt2zb5+vqqUaNGCg0N1cqVK/XTTz/J09NTKSkpWr9+vd58802zQy5VJL3lzHfffaevvvpKe/fu1ahRo1RQUKCQkBBt2bJFly9f1tNPP212iCgFhmFo9+7dOnDggO6991599NFHioiI0FtvvaWhQ4eqoKBA/fr106JFi+Tn52d2uLgJCgoK5OHhIcMwlJaWpuzsbEVFRWnEiBF66623dOnSJTVt2lTu7u767LPPVFBQ4NyGiITHGor78eDBg/rkk0/UqlUr7dq1S7t27VLt2rVVuXJl3XPPPerSpYsMw1BgYCBJj0UU92NiYqIuXLig4ODgqxYmeuWVVzRv3jwVFhbK09PTeZObfreWo0ePauvWrXrvvfd06NAhffbZZ2rfvr38/PzUoUMHpaamKiAgQEeOHNHChQs1c+ZMs0PGDSo+9o8cOaKioiIFBgZqxYoV2rx5syZOnKjQ0FBt2LBBkZGRio2NVUpKilatWqXXX39dUVFRZodfqliZwuIcDoekn+/0StLx48fl6empLl26qGrVqho1apRGjx6tZ555Rjk5OSooKDAzXJSSgoICrVy5Uq+99prWrFmjZs2aadKkScrPz9ekSZP01ltvKS0tjQXLLKKwsNC5MN2BAwf06quvau7cuZo6daocDod+/PFHffHFF5Kkhg0bqmPHjsrPz9fbb7+twsJCLnwtoniUZ8KECdqxY4cOHTqkBg0aaPv27VqxYoVzVCcoKEiBgYHO16DsK+77iRMnKjw8XFFRURo7dqyzz9PS0pSamqorV66YHClutuLrvu+++07Dhg2Tw+HQ5MmTNXXqVL399tvy8/PT5s2blZaWppiYGNntdi1ZskQzZsxw7tSAsqv42B8+fLgCAgIUFhammTNn6u9//7tq1aqlnTt3aurUqc7nR0REaPTo0YqNjTUx6j8Hc3otrvgC5sSJE6pUqZLq1KmjtLQ0ZWVlqXLlymrVqpWWLVum2bNn65lnnlGVKlVMjhg325kzZ1RUVKT69esrMTFRly5dUt26dXXgwAElJSXp4YcfVr9+/RQcHMwFr0W4ubnJbrfr8ccf17p16/TCCy+oY8eOWrZsmS5duqS9e/dq//79atWqlQICAhQeHq5KlSrplltu4caHhZw/f14TJkzQ+PHj9eijj+qnn35Sbm6uoqKitHHjRmVnZ6tx48bORctgHdnZ2Zo2bZqefvppNWnSRA0bNlRmZqamTJmilJQULVy4UE8++aSlF60pr4oru6ZOnaohQ4YoNDRUa9eu1bPPPqt69eopOTlZL774otq1a6ewsDDnNIewsDCzQ8dNcODAAb388suaMmWKqlevrpCQEGVkZGjVqlW6ePGiZs2a5Vy80G63y2azlZttKEl6y4HTp0/rwQcfVEBAgOLj4xUdHa1z585p3bp1On78uBITEzV+/HjVrl3b7FBxk125ckXvvvuu1q9frxo1aqhbt25KTU1V27ZtZRiGNm3apC5durA9gQVVrFhRmzZtUn5+vnPvvW7duik8PFwBAQE6duyY6tevr4iICElSWFgYixZZTEFBgVavXq1mzZopPDxccXFxWrNmjVJTU9WuXTu1bNnS2f+wlsLCQn344Ydq0qSJqlevLofDoZYtW6pChQrq0KGDOnXqpISEBKYyWNSRI0c0a9YsNWrUSN26ddPRo0f13XffafPmzVq6dKmee+45tWrVSna7XYZhyMPDw+yQcZNkZGQoJSVFRUVF2rp1q5YsWaKKFSvKbrerU6dO6tq1q9q0aSOHw1HutqIj6S0H/Pz8VK1aNc2ZM0e+vr6KjY1VbGysVq9erYiICA0dOlSRkZFmh4lS4O7urvr16yswMFAvvPCCCgsLlZmZqcaNG6tLly66/fbbWbjIojw8PNSjRw81bNhQL7/8snx8fBQfH68LFy6oRYsW8vDw0MqVK9WlSxdG+izK29tbGRkZOn78uCpVqqQqVarI09NTSUlJKigo0F133UXfW5SHh4dyc3N1/PhxVa5cWUFBQUpOTtaSJUvUs2dP54JlJLzWVL16dcXGxurtt99W7dq19cADDyg8PFwhISG66667nDc8ylvSUx54eXnpwoULWr16tTp16qTevXvLbrerfv36zqmNUvk89kl6y4latWqpatWqmj59ujw9PZWamqq9e/dq6NChlDRbnJeXl6pVq6ZbbrlFu3fv1vr165WYmKi7775bPj4+fOlZmLu7u8LDw1W1alVNnjxZ58+f14IFC9SmTRtduXJF33zzjXr06CF3d9Y0tKqqVatqz549WrlypY4ePaoFCxboH//4hzZv3qy6deuqcuXKZoeIUhIWFqa9e/dq0aJFOn78uGbOnKknnnhC8fHxZoeGP0FUVJQiIyM1depUVaxYUe3bt1d0dLRCQkIklc+kpzzw9PRUw4YN1atXL9WpU0epqan65z//ySCHJMNRPOMd5cI333yj6dOny9vbW88++2y5mLiO/5Obm6vDhw8rLy9PLVq0MDsc/ImSk5O1bNkydevWTbfccos2b96siIgIxcTEmB0aSllWVpa+++47HTx4UB06dNCVK1c0ZswYvfPOOyS9FpeTk6O9e/cqPT1dERERatSokdkh4U+2YcMGTZkyRe+8845CQkK40V1OFBUV6cCBAxo3bpwee+wxderUyeyQTEfSWw7l5ubKMIyrti9A+cNcrvKnsLDQOaprt9u5+CmHduzYoSlTpuill17ipidQTly4cEFBQUFmh4E/WU5OjtLT01WtWjWu+UTSCwBAuXHu3DkVFBSwgBUAoFwh6QUAAAAAWBa1bQAAAAAAyyLpBQAAAABYFkkvAAAAAMCySHoBAAAAAJZF0gsAAAAAsCySXgAAAACAZZH0WlRGRoamT5+ujIwMs0OBCej/8ou+L9/o//KLvi/f6P/yi77/Y0h6LSojI0MzZszgACin6P/yi74v3+j/8ou+L9/o//KLvv9jSHoBAAAAAJZF0gsAAAAAsCySXgAAAACAZZH0WpTNZlNERIRsNpvZocAE9H/5Rd+Xb/R/+UXfl2/0f/lF3/8xhsPhcJgdBAAAAACg7LlwOVtBARXNDuM3uZsdgNWlZxXIbtJthRA/D/2UWWBO45I6v7jWtLZdwewhHUxtv1V0Je04esmUtgMqlO9Ty/bUi6a2/z8J1bTgm5OmtZ+eY955xxU0q+pnavu31g3Rxh9+MqXt59791pR2XcU/H2plavu3xARp65ELprW//ki6aW27gnY1Akxt/7a4KvrswDlT2k7LyTelXVfh42Fu8WzfhuFavue0KW0H+3ioY0yIOg2aotS0X193RoZW0hfvPGNCZFcr31emfwK7Q6YlvcXtm+Xk+WzzGncBeYV2s0MwLYaCovJdQJKZV2h2CKbGcCnX/M9vptwC8499s2I4mZ5jSruu4ooL9L2ZMVwo5ze8cgqKzA7BtBhc4XvPTA6H+aXF2fnm9L2Px8+fPTXtklLOmHfT7fcwpxcAAAAAYFmM9AIAAAAASs5w+/nnWo+7ANeIAgAAAACAUkDSCwAAAACwLMqbAQAAAAAlZxg//1zrcRfASC8AAAAAwLJIegEAAAAAlkV5MwAAAACg5AzjOqs3U94MAAAAAECpIukFAAAAAFgWSS8AAAAAwLKY0wsAAAAAKDm2LAIAAAAAwBwkvQAAAAAAy6K8GQAAAABQcobbdbYsco0xVteIAgAAAACAUkDSCwAAAACwLMqbAQAAAAAlx+rNAAAAAACYg6QXAAAAAGBZlDcDAAAAAEqO1ZsBAAAAADAHSS8AAAAAwLJIegEAAAAAlsWcXgAAAADADbjOlkViyyKXkJqaqh49ekiSEhMT1axZM/Xp00ddu3bVgAED9OWXX5ocIQAAAACgpMr1SG9hYeGvHmvevLlmz54tSTpw4ICGDBkib29vtW7d+s8ODwAAAABwg8pU0puamqrHHntMa9askSTNnz9fOTk5CggI0AcffCCbzaaYmBj985//VE5OjsaPH6/Dhw+rsLBQTzzxhDp37qwVK1bos88+U05Ojux2u1599dXrthcXF6fBgwdr8eLFJL0AAAAAcC2GcZ0ti1yjvLlMJb3XM2fOHG3cuFGenp7KyMiQJM2aNUutWrXSxIkTlZGRoX79+qlNmzaSpO+//14ff/yxKlWqpNTU1N9873r16mn+/Pml/hkAAAAAADefJZLeunXravjw4erUqZM6d+4sSdq6das2btyoBQsWSJLy8vJ05swZSVLbtm1VqVKlP/TeDofjhmIL8fO4odffqFB/89q/sPA+09rGzzrUDTI7hHKpYTU/s0PQ0Ha1zA4BJupeP9SUds/OucuUdvF/OsdVLpdt42d9GlY1OwSYZGDzamaH4NLKVNLr7u4uu93u/HteXp6kn0d6v/32W3355ZeaNWuWVq9eLUmaNm2aoqKirnqP3bt3q0KFCn+4ze+//17R0dEljvmnzALZbyxvLrFQfw+lZRSY07ikuCf+17S2XcHKv99uavsd6gZp8w8XTGk70Mfcmz1m+/L4eVPbH9qult7c8qNp7Z/LMu+84wraVAswtf3u9UP1yb40U9p+aNoWU9p1FYuf7mhq+53jKmvDAfPOPysPnDOtbVfQJSbQ1Pb7NKyqj/acMaXt01l5prTrKnw9baa2P7B5NS1MOmlK2yEVPdUtLvTf5c3XKGV2kfLmMrV6c3BwsNLT03Xx4kXl5+dr06ZNstvtOnPmjFq1aqXhw4crMzNTOTk5uuWWW7R48WLnSO3333//X7d38OBBzZw5UwMGDLjZHwUAAAAA8CcoUyO9Hh4eGjJkiPr166fQ0FBFRUXJbrdrxIgRysrKksPh0MCBA+Xv76/BgwfrlVdeUa9evWS32xUZGelclfm3JCUlqU+fPsrNzVVwcLDGjBnDIlYAAAAAUEaVqaRXkgYOHKiBAwf+7vO8vb310ksv/erxO++8U3feeafz75GRkc7VoFu2bKmdO3fevGABAAAAwOoMt+us3uwahcWuEQUAAAAAAKWApBcAAAAAYFllrrwZAAAAAOBCWL0ZAAAAAABzkPQCAAAAACyLpBcAAAAAYFnM6QUAAAAAlBxbFgEAAAAAYA6SXgAAAACAZVHeDAAAAAAoOcO4TnkzWxYBAAAAAFCqSHoBAAAAAJZFeTMAAAAAoOQMQ3K7Rikz5c0AAAAAAJQukl4AAAAAgGVR3gwAAAAAKDnD7TqrN7vGGKtrRAEAAAAAQCkg6QUAAAAAWBZJLwAAAADAspjTCwAAAAAoOcO49vZEbFkEAAAAAEDpIukFAAAAAFgW5c0AAAAAgJJjyyIAAAAAAMxB0gsAAAAAsCzKmwEAAAAAJWfoOqs3/+mRXBMjvQAAAAAAy2Kkt5Td8uAUpZy9ZErbudsmqubtL5jStiTt/ci8tl3Bpex8s0NQRU+bKe0W2R2mtOsqEqoGmh2CqTF42Fzktq5JHC7w61/Fx9uUdre93N2Udl1Fbn6R2SGoqr85fS9Jf42rYlrbrsDfy8PsEBTu62NKu2E+FUxp11UUucCJPzrA15R2/bzNudb8b5H0AgAAAABKrhRWbz5z5oxGjhyp9PR0GYahu+++Ww8++KCmT5+uf/3rXwoKCpIkPfPMM+rQocNvvhdJLwAAAADApdhsNo0aNUr16tVTVlaW+vbtq7Zt20qS/va3v+mhhx76w+9F0gsAAAAAKDVnzpxRUdHVU0D8/f3l7+9/3ddUqVJFVar8PG3C19dXUVFRSktLK1H7JL0AAAAAgFIzYMAAnTp16qrHnnjiCT355JN/6PWpqak6cOCAGjVqpO+++05LlizRRx99pPr162vUqFEKCAj4zdeT9AIAAAAASs4wrrNl0c+PLVmy5JojvX9Edna2nnrqKT3//PPy9fVV//79NXjwYBmGoTfffFOvvvqqJk6c+JvvQdILAAAAACg1VatWLdHrCgoK9NRTT6lnz5667bbbJEmVK1d2/nu/fv302GOP/e77sE8vAAAAAMClOBwO/f3vf1dUVJQGDRrkfPzcuXPOP2/YsEG1a9f+3fdipBcAAAAAUHKlsGXRzp07tWrVKtWpU0e9e/eW9PP2RGvWrNHBgwclSREREXrppZd+971IegEAAAAALqV58+b64YcffvX47+3Jey2UNwMAAAAALIuRXgAAAADADbjO6s261mN/PkZ6AQAAAACWRdILAAAAALAsypsBAAAAACVnGNdZvZnyZgAAAAAAShVJLwAAAADAskh6AQAAAACWxZxeAAAAAEDJGdfZsog5vQAAAAAAlC6SXgAAAACAZVHeDAAAAAAoOcPtOlsWucYYq2tEAQAAAABAKSDpBQAAAABYFuXNAAAAAICSo7wZAAAAAABzkPQCAAAAACyL8mYAAAAAQMkZxs8/13rcBTDSCwAAAACwLJJeAAAAAIBlkfQCAAAAACyLOb0AAAAAgJIzjOtsWcScXgAAAAAAShVJLwAAAADAsihvBgAAAACUHFsWAQAAAABgDpJeAAAAAIBlUd4MAAAAALgBbtdevdlFxlhdIwoAAAAAAEoBSS8AAAAAwLIobwYAAAAAlByrNwMAAAAAYA6SXgAAAACAZVHeDAAAAAAoMcMwZFyjlPlaj5mBkV4AAAAAgGWR9AIAAAAALIukFwAAAABgWczpBQAAAACUGHN6AQAAAAAwCUkvAAAAAMCyKG8GAAAAAJSc8e+faz3uAhjpBQAAAABYFkkvAAAAAMCyKG8GAAAAAJQYqzcDAAAAAGASkl4AAAAAgGVR3gwAAAAAKDHDuHYps4tUNzPSCwAAAACwLpJeAAAAAIBlkfQCAAAAACyLOb0AAAAAgBJjyyIAAAAAAExC0gsAAAAAsCzKm0vZ1nefVpHDvPZ/XDfOvMbLuYpeFcwOQRFB5sTgMPF33hU4XOA/oHqwib9/LlLKZBZX+PRmHfturvDhTRRY0dPsEBQeaN6xH+xr/uc3k938U78iTfved4EPbyJX6PvqwT6mtOv572zS0HXKm13iW5GRXgAAAACAhZH0AgAAAAAsi/JmAAAAAEDJGbr2/B7XqG5mpBcAAAAAYF0kvQAAAAAAy6K8GQAAAABQYoZxndWbXWRHB0Z6AQAAAACWRdILAAAAALAskl4AAAAAgGUxpxcAAAAAUHLXmdMr5vQCAAAAAFC6SHoBAAAAAJZFeTMAAAAAoMTYsggAAAAAAJOQ9AIAAAAALIvyZgAAAABAiVHeDAAAAACASUh6AQAAAACWRXkzAAAAAKDkjH//XOtxF8BILwAAAADAskh6AQAAAACWRdILAAAAALAs5vQCAAAAAEqMLYsAAAAAADAJSS8AAAAAwLIobwYAAAAAlJiha5cyu0ZxMyO9AAAAAAALI+kFAAAAAFgW5c0AAAAAgBJj9eZS8MgjjygjI+Omvd/777+vjz766FePp6amqkePHjetHQAAAADAn6tMjvTOnTv3pr5f//79b+r7AQAAAABcg0smvfPmzZOnp6cGDhyoV155RQcPHtTChQu1fft2LVu2TMnJyVq2bJlycnL0yCOPqFmzZkpOTlZoaKhmzpwpb29vpaSkaNy4cbp48aK8vb01fvx4RUdHX7O96dOny8fHRw899JD27dun559/XpLUtm3bP/NjAwAAAEDZY+jaSzW7RnWzaya9zZs314IFCzRw4EDt27dP+fn5Kigo0M6dO9WiRQslJyc7n3vixAlNmTJFEyZM0NChQ7V+/Xr17t1b//jHPzRu3DjVrFlTu3fv1rhx47Rw4cLfbXv06NF64YUX1KJFC02aNOmGP0uIv+cNv8eNCAswt32Yqyr9X25FBHqZHQJMFF6JY7+8CvSxmdi6mW1D4tgvz6oF8b3/W1wy6a1Xr57279+vrKwseXp6Kj4+Xvv27VNSUpLGjBmjOXPmOJ8bGRmpuLg45+tOnTql7OxsJScna+jQoc7n5efn/267GRkZyszMVIsWLSRJvXv31pYtW27os/yUka8ixw29RYmFBXjq7OXf/9woHSZ1u1PVAE+dMan/HWZ/eJM5TP4PiAj00qmLeeYF4CKLVpjF7E8fXslTpy+Zc+y7mf3hTeblYW7SF+hj08WcItPazyswr21XYDf5u8/MY9/s7z2zmd331YK8dPKCOd/7nu5SqL/rJ9wumfR6eHgoMjJSK1asUJMmTVS3bl0lJiYqJSXlVyXKnp7/d0fLZrMpLy9PDodD/v7+WrVq1Z8dOgAAAADAhbjs6s3FJc4tWrRQ8+bN9cEHHyguLu4PLXvt6+uryMhIrVu3TtLPd58OHjz4u6/z9/eXn5+fkpKSJEmrV6++sQ8BAAAAABZXvGXRtX5cgUsnvT/99JMaN26sypUry8vLS82bN//Dr3/99de1bNky9erVS927d9eGDRv+0OsmTpyol156Sb179y73pRoAAAAAUNYZDjK7UsWc3vLL7AOLOb3mMfu0ypxec5n96ZnTax7m9DKn10zM6TWP2X3vCnN6mz/3iU6m5/zq36sF+yhpUncTIruaS87pBQAAAACUDdcrZXaV8uZylfS+/fbb+vTTT6967Pbbb9fjjz9uUkQAAAAAgNJUrpLexx9/nAQXAAAAAMqRcpX0AgAAAABusuut1Owi5c0uu3ozAAAAAAA3iqQXAAAAAGBZlDcDAAAAAErM1VdvZqQXAAAAAGBZJL0AAAAAAMuivBkAAAAAUHLGv3+u9bgLYKQXAAAAAGBZJL0AAAAAAMsi6QUAAAAAWBZzegEAAAAAJWboOlsWucikXkZ6AQAAAACWRdILAAAAALAsypsBAAAAACVmGNcpb77GY2ZgpBcAAAAAYFkkvQAAAAAAy6K8GQAAAABQYoZx7VJmF6luZqQXAAAAAGBdJL0AAAAAAMuivBkAAAAAUHLGv3+u9bgLYKQXAAAAAGBZJL0AAAAAAMuivLmU+ft4ymFi+5UqeprWdmZugWltu4L8QrvZIchuN+e3z6RmXYabi5TymMVWzj9/fpH5B0ChSQehZznvfIfD/L53hRjKK1f4n3eFGMojV/h/NysGV/jsfwRJLwAAAACgxAzDuM6WRa5xM5TyZgAAAACAZZH0AgAAAAAsi/JmAAAAAECJUd4MAAAAAIBJSHoBAAAAAJZFeTMAAAAAoMQobwYAAAAAwCQkvQAAAAAAy6K8GQAAAABQctcpbxblzQAAAAAAlC6SXgAAAACAZZH0AgAAAAAsizm9AAAAAIAb4xrTd6+JkV4AAAAAgGWR9AIAAAAALIvyZgAAAABAiRnX2bLomtsYmYCRXgAAAACAZZH0AgAAAAAsi/JmAAAAAECJUd4MAAAAAIBJSHoBAAAAAJZFeTMAAAAAoMQM4+efaz3uChjpBQAAAABYFkkvAAAAAMCySHoBAAAAAJbFnF4AAAAAQImxZREAAAAAACYh6QUAAAAAWBblzQAAAACAEmPLIgAAAAAATELSCwAAAACwLMqbAQAAAAAl9nN587VWbzYhmGtgpBcAAAAAYFkkvQAAAAAAy6K8GQAAAABQYqzeDAAAAACASUh6AQAAAACWRXkzAAAAAKDEDMOQm9u1Vm92jfpmkl4AAAAAgEs5c+aMRo4cqfT0dBmGobvvvlsPPvigLl26pKefflqnTp1SRESEpk6dqoCAgN98L8qbAQAAAAAuxWazadSoUVq7dq0+/PBDLV26VEeOHNGcOXPUunVr/f/27j3IrqrMH/dndyfpXBvSkcRwU1AEjaKhQMQSlUQQI5KLolB4QxxKNAhfcRRBEBF/iIgyg0jJ4AzIIDUKmSSICILAWOh4QUZER0RGQTKQOLkI5Nrp7t8fgYwZTkw4uazN7uehdlVY3WevtXufs895z/uutW+++eYcdNBBueyyyza5L0EvAAAAtTJ+/PhMmjQpSTJ69OjsueeeWbhwYW699dbMmDEjSTJjxozccsstm9yX8mYAAADatqlbFj3yyCPp6+vb4Gfd3d3p7u7erP0//PDD+c///M+8/OUvz+LFizN+/PgkyU477ZTFixdv8vGCXgAAALaZY489NgsWLNigbfbs2TnppJM2+djly5fnwx/+cE4//fSMHj16g59VVbVZi2UJegEAANhmrr766paZ3k3p7e3Nhz/84bzlLW/JYYcdliQZN25cFi1alPHjx2fRokXp6enZ5H4EvQAAALRtYxnXp9omTpz4jPc5MDCQM844I3vuuWeOO+649e1TpkzJ3Llzc8IJJ2Tu3LmZOnXqJvcl6AUAAKBW7rrrrsybNy8vetGLMn369CTJRz7ykZxwwgk55ZRTcu2112bnnXfORRddtMl9CXoBAAColf333z/33Xdfy59deeWVz2hfgl4AAADatqnVm0tzn14AAAAaS9ALAABAYylvBgAAoG2bWr25NJleAAAAGkvQCwAAQGMJegEAAGgsc3oBAABomzm9AAAAUIigFwAAgMZS3gwAAEDbqmrd1qq9DmR6AQAAaCxBLwAAAI2lvBkAAIAt0Hr15qQe9c0yvQAAADSWTO829rtHH8+avoEifU9+Xnf+c8FjRfpOknGjhxXruw66hnaWHkKGdPpeq4S+/jKv+b9U8r545Y++rK4h5V93pcbQPzC4z35voff7uoyhBodfVB3yWaXGMFCX1YpKGeTXvmcDQS8AAABts3ozAAAAFCLoBQAAoLEEvQAAADSWOb0AAAC0rapa37Ko5MKaf0mmFwAAgMYS9AIAANBYypsBAABom1sWAQAAQCGCXgAAABpLeTMAAABts3ozAAAAFCLoBQAAoLGUNwMAANA2qzcDAABAIYJeAAAAUhIgUgAAIABJREFUGkvQCwAAQGOZ0wsAAEDb1s3pbXXLogKDaUGmFwAAgMYS9AIAANBYypsBAABom1sWAQAAQCGCXgAAABpLeTMAAABboGq5enNSj/pmmV4AAAAaS9ALAABAYylvBgAAoG1WbwYAAIBCahv0PvbYY7n66qu3S19/8zd/k8cee+xp7RdffHG+9rWvbZcxAAAAsPXVOui95pprtktf//AP/5Du7u7t0hcAAADbT23n9F544YV56KGHMn369Dzvec/LkUcemTe84Q1JklNPPTVvetOb8thjj+V73/tennjiiSxcuDBHHnlkZs+enSSZN29errrqqvT29ublL395PvWpT6Wzs7NlX1OmTMm1116bnp6eXHrppZk7d256enoyceLETJo0absdMwAAwLNNVbW+ZVHr2xhtf7UNek899dTcf//9mTdvXn7yk5/kiiuuyBve8IY8/vjjufvuu3P++edn/vz5+eUvf5nrr78+I0aMyNve9ra87nWvy8iRI3PjjTfmmmuuydChQ3P22Wfn+uuvz4wZM/5qn/fee2++853vZO7cuenr68vMmTO3OOidtOuYLXr8lpr8PBnswWxC99DSQ6CQnXccVnoIFOS1P3g594Oba//gtXtPV+kh1Fptg96/9MpXvjKf/vSns2TJktx000154xvfmCFD1g391a9+dcaOHZskOfTQQ3PXXXdlyJAhuffee/O2t70tSbJq1aqMGzduk/387Gc/yxve8IaMGDEiyboM8Jb61cOPZ03fwBbvpx2Tn9edux98+lzl7WXc6MF94e0a2rqyYHuZ0D00Cx/rLTqGwaqvv8xr/ik77zgs/71sTbH+a/KlbjEdhf8AJV/7/QNln/ulDeZznyRrC1/7Sit96St57R/cZ778+/7uPV15aMnqIn0PG5I8t7v+AfezIuhNkunTp2f+/Pm54YYbct55561v/78p86qqMjAwkJkzZ+bUU0/d3sMEAAAYVNyyqE2jRo3K8uXL1///rFmzcuWVVyZJXvjCF65vv/POO7Ns2bKsWrUqt9xyS/bbb78cdNBBuemmm7J48eIkybJly7JgwYJN9nnAAQfklltuyapVq/LEE0/ktttu28pHBQAAwPZU20zv2LFjs99+++WII47IwQcfnI9//OPZc8891y9m9ZR99903J5100vqFrF72spclSU455ZS8733vS39/f4YOHZqzzjoru+yyy1/tc9KkSZk2bVqmT5+enp6e9fsCAADg2am2QW+ybgXnp6xcuTIPPvhgjjjiiA1+57nPfW6+8pWvPO2x06ZNy7Rp0zarn+9///vr/33iiSfmxBNPbHPEAAAAg0vdV2+ubXnzX/rhD3+YadOm5Z3vfGfGjCm7GjIAAADPHrXO9D7l1a9+dcv5tbNmzcqsWbM2ez9HHXVU1qzZcFW7z3/+89l77723eIwAAADUz7Mi6N1avvWtb5UeAgAAQKMobwYAAIBCBL0AAAA01qAqbwYAAGDrqqp1W6v2OpDpBQAAoLEEvQAAADSWoBcAAIDGMqcXAACAtrllEQAAABQi6AUAAKCxlDcDAACwRWpSydySTC8AAACNJegFAACgsZQ3AwAA0DarNwMAAEAhgl4AAAAaS3kzAAAAbauq1qs316S6WaYXAACA5hL0AgAA0FiCXgAAABrLnF4AAADa1lFV6WgxgbdVWwkyvQAAADSWoBcAAIDGUt4MAABA2+p+yyJB7zb268WP5Yk1fUX6nvy87vzHomVF+k6SaWMnFuu7DlYUOu//a2ixMQwMDBTpl/+1qrfc82/YkMFdRPTEmrVF+5/QPTSPrewt0veOI4cW6bcu6nDlK/kBc8Xqss/90qoafLr3vl9GHQ5/VanPnQPPjvf8Z8coAQAAoA0yvQAAALRtXXnz06sdalAAkUSmFwAAgAYT9AIAANBYypsBAABoW1UlHTVevVmmFwAAgMYS9AIAANBYgl4AAAAay5xeAAAA2lZV1UZuWVSPSb0yvQAAADSWoBcAAIDGUt4MAABA26q0vj1RPYqbZXoBAABoMEEvAAAAjaW8GQAAgLZVT/7Xqr0OZHoBAABoLEEvAAAAjaW8GQAAgLZ1VOu2Vu11INMLAABAYwl6AQAAaCxBLwAAAI1lTi8AAABtq6oqVdXilkUt2kqQ6QUAAKCxBL0AAAA0lvJmAAAA2lZV67ZW7XUg0wsAAEBjCXoBAABoLOXNAAAAtK2qqnRYvRkAAAC2P0EvAAAAjaW8GQAAgLZZvRkAAAAKEfQCAADQWMqbAQAAaFtVVS1XarZ6MwAAAGxjgl4AAAAaS9ALAABAY5nTCwAAQNvcsggAAAAKEfQCAADQWMqbAQAAaFtHqnS0qGXuSD3qm2V6AQAAaCxBLwAAAI2lvBkAAIC2VU9urdrrQKYXAACAxhL0AgAA0FjKmwEAAGhfVaVqsXpzWrUVINMLAABAYwl6AQAAaCxBLwAAAI1lTi8AAABt66jWba3a60CmFwAAgMYS9AIAANBYypsBAABoW1Wl5S2LanLHIpleAAAAmkvQCwAAQGMpbwYAAKBt68qbW7fXgUwvAAAAjSXoBQAAoLGUNwMAANC2qqo2snpzPeqbZXoBAABoLEEvAAAAjaW8eRs7cNdxWds/UKz/1z1/p2J99/b1F+u7DrqGlP9OqdQYVq8d3Od+SEf5Up6hneWff4PV8KGdpYdQbAwF3+5qYWCg/B+gv+BJGNU1uD9Wlvy895RhNfjsMRjV4bXfNbTMuR86pPxnns0xuK9OAAAAbJGOat3Wqr0OfB0EAABAYwl6AQAAaCzlzQAAALRvI7csilsWAQAAwLYl6AUAAKCxlDcDAADQturJrVV7Hcj0AgAA0FiCXgAAABpLeTMAAABt60iVjhYrNXfUpMBZphcAAIDGEvQCAADQWIJeAAAAGsucXgAAANpWVeu2Vu11INMLAABAYwl6AQAAqJVPfOITOeigg3LEEUesb7v44otz8MEHZ/r06Zk+fXruuOOOzdqX8mYAAADaVlVVqha1zK3aNtesWbPyzne+Mx//+Mc3aH/ve9+b448//hntS6YXAACAWjnggAOyww47bJV9yfQCAACwzTzyyCPp6+vboK27uzvd3d3PeF9XX3115s6dm5e+9KU57bTTNiswlukFAACgbU+t3txqS5Jjjz02U6dO3WC78sorn3E/xxxzTL73ve9l3rx5GT9+fD73uc9t1uNkegEAANhmrr766paZ3mfqOc95zvp/H3XUUfnABz6wWY8T9AIAALDNTJw4cavsZ9GiRRk/fnyS5JZbbslee+21WY8T9AIAANC2qqrSsZVXb/7IRz6Sn/zkJ1m6dGle+9rX5qSTTspPfvKT/OY3v0mS7LLLLjnnnHM2a1+CXgAAAGrli1/84tPajjrqqLb2ZSErAAAAGkvQCwAAQGMpbwYAAKBtf3l7ov/bXgcyvQAAADSWoBcAAIDGEvQmOeOMM/K73/3uae1z5szZ7GWwAQAABqOqqja61UGt5vSuXbs2Q4Zs/yF99rOf3e59AgAAsO1t1wjzkksuyfz589PT05OJEydm0qRJuf3227PPPvvkrrvuyhFHHJHnP//5ufTSS9Pb25sdd9wxX/jCF/Kc5zwnF198cR566KE89NBDWbp0ad7//vfn7W9/e5Lk8ssvz4033pg1a9bk0EMPzYc//OGsWLEip5xySh599NH09/fngx/8YKZNm9ZyXO9617vysY99LC972cty3XXX5bLLLsuYMWOyzz77ZNiwYVt0zLuPG75Fj99Se+40omj/lLXzjlv2/OXZa7eertJDoCDnf/B67g6u+4PZ7l77g9bzCsccdbfdgt577rknN998c+bPn5/e3t7MmjUrkyZNSpL09vZmzpw5SZI///nP+eY3v5mqqvKtb30rl19+eU477bQkyX333ZdvfvObWbFiRWbOnJnXve51uf/++/Pggw/m2muvzcDAQE488cT89Kc/zZIlSzJ+/PhcdtllSZLHH398k2NctGhRLr744syZMyejR4/Ou9/97rzkJS/ZouN+aPGqrO0f2KJ9tGvPnUbkv/60skjfSTJsyOCunu8oXM6x847D8t/L1hTpe/Xa/iL91sWQjrLnfreervxxyepi/dekkqmYgTKX/PVKnv/Bft0fKHzyn7vDsDz65zLX/SQp9HGnNkp93nvK7j1deajgtX8wK/3af9644Xlw8aoifQ8bUmXiDl3pSOt5s3V5V9huQe/Pf/7zTJ06NV1dXenq6sohhxyy/md/mYF99NFH8//+3//Ln/70p6xZsya77rrr+p9NnTo1w4cPz/Dhw3PggQfml7/8Ze66667ceeedmTFjRpJkxYoV+cMf/pD9998/559/fi644IIccsgh2X///Tc5xnvuuSevfOUr09PTs35cf/jDH7bSXwAAAIDtrRZzekeM+N8S3HPPPTfvfe97M3Xq1Pz4xz/Ol7/85fU/azURemBgICeccEKOPvrop/1szpw5ueOOO3LRRRflVa96VWbPnr1tDgAAAIBa2m4Z5/322y+33XZbVq9eneXLl+f2229v+XuPP/54JkyYkCSZO3fuBj+79dZbs3r16ixdujQ/+clP8rKXvSyvec1rct1112X58uVJkoULF2bx4sVZuHBhRowYkenTp+f444/Pr3/9602Ocd99981Pf/rTLF26NL29vfnud7+7ZQcNAADQcFZvftK+++6bKVOm5Mgjj8y4cePyohe9KGPGjHna782ePTsnn3xydthhhxx44IF5+OGH1/9s7733zrvf/e4sXbo0H/zgBzNhwoRMmDAhDzzwwPpM78iRI3PBBRfkwQcfzOc///l0dHRkyJAhOfvsszc5xvHjx2f27Nk5+uijM2bMmLz4xS/eascPAADA9lcNbMeZ18uXL8+oUaOycuXKHHvssfnMZz6zfjGrTbn44oszcuTIHH/88dt4lFuXhawGLwtZDV4WsirWdS1YyGrwKr2YjYWsyrKQ1eBV+rVfh4Wszr75gSxZ0fu0n/eMHJqzD3tBgZFtaLvO6T3rrLPyu9/9LqtXr87MmTM3O+AFAACgnjqStPrOvy5fhW7XoPfCCy9s+7EnnXTSFvf/oQ99aINy6ST56Ec/moMPPniL9w0AAED91GL15u3lkksuKT0EAAAAtqO6ZJwBAABgqxtUmV4AAAC2rqpqPae3LotbyvQCAADQWIJeAAAAGkt5MwAAAG2rqqRqUcusvBkAAAC2MUEvAAAAjaW8GQAAgLZ1bGT15lZtJcj0AgAA0FiCXgAAABpLeTMAAABtW7d6c+v2OpDpBQAAoLEEvQAAADSWoBcAAIDGMqcXAACAtnVUVTpaTOBt1VaCTC8AAACNJegFAACgsZQ3AwAA0LYqrbOp9ShulukFAACgwQS9AAAANJbyZgAAANpWVeu2Vu11INMLAABAY8n0bmOHvuv/y0OPLCnS98q7v5xJh/1tkb6T5A93fKlY33WwbEVv4REMy+Or1hbpubOjJl/rFbJyTV/hEXQVO/dJMshPfw10ZfnqMud/+NBhRfqti+Vr+ksPIat6y42h5HWnDspf+7ry+Moynz36+geK9FsXA4UP/3njhmfZ8jLnfuSwjmSHriJ9PxOCXgAAANrWUVXpaFHL3KqtBOXNAAAANJagFwAAgMYS9AIAANBY5vQCAADQtiobuWXRdh9JazK9AAAANJagFwAAgMZS3gwAAEDbOqrW96ouf//qdWR6AQAAaCxBLwAAAI2lvBkAAIC2VVWVjhbLN1etlnQuQKYXAACAxhL0AgAA0FjKmwEAAGhbVa3bWrXXgUwvAAAAjSXoBQAAoLEEvQAAADSWOb0AAAC0raNat7VqrwOZXgAAABpL0AsAAEBjKW8GAACgbdWT/7VqrwOZXgAAABpL0AsAAEBjKW8GAACgbVZvBgAAgEIEvQAAADSW8mYAAADaVm2kvLlS3gwAAADblqAXAACAxlLeDAAAQNuqqkrVopa5VVsJMr0AAAA0lqAXAACAxhL0AgAA0Fjm9AIAANC2jrS+ZVFdMqx1GQcAAABsdYJeAAAAGkt5MwAAAG2rqnVbq/Y6kOkFAACgsQS9AAAANJbyZgAAANrWUVXpaFHL3KqtBJleAAAAGkvQCwAAQGMpbwYAAKBtVZV0WL0ZAAAAtj9BLwAAAI0l6AUAAKCxzOkFAACgbVXVev6uOb0AAACwjQl6AQAAaCzlzQAAALStI1U68vRa5lZtJcj0AgAA0FiCXgAAABpLeTMAAABts3ozAAAAFCLoBQAAoLGUNwMAANC2jmrd1qq9DmR6AQAAaCxBLwAAAI0l6AUAAKCxzOkFAACgbVWVdLS4P5FbFgEAAMA2JugFAACgsZQ3AwAA0LYqrUuZa1LdLOjd1uZe/rH09g0U6//H888r1vfy1WuL9V0Ho7s6Sw+h2BiGdA7uIpLevv7SQ0j3iHKX96ouE3gK6e8vd81/yqiuMuf/8VWD+7pf6u/+l0YMK/feM6TTa7+0McMLPQcH+XU/A+XP/dhRQ4v0O2zIs+PcD+5PpgAAADRa+a8kAQAAeNbqqKqWqze3aitBphcAAIDGEvQCAADQWMqbAQAAaFtVbWT15npUN8v0AgAA0FyCXgAAABpL0AsAAEBjmdMLAABA2zrSOptalwxrXcYBAAAAW52gFwAAgMZS3gwAAED7qipVje9ZJNMLAABAYwl6AQAAaCzlzQAAALStenJr1V4HMr0AAAA0lqAXAACAxlLeDAAAQNs6qiodLVZqbtVWgkwvAAAAjSXoBQAAoLEEvQAAADSWOb0AAAC0zS2LAAAAoBBBLwAAAI2lvBkAAIC2VdW6rVV7Hcj0AgAA0FiCXgAAABpLeTMAAABtq6oqVYta5lZtJRTP9F5xxRVZuXJl6WFkypQpWbJkSelhAAAAsBUVD3q//vWvbzTo7evr286jAQAAoEk2q7x57ty5+drXvpaqqrL33nvn5JNPzumnn56lS5emp6cn5513Xnbeeeecdtppef3rX5/DDz88STJ58uTcfffd+fGPf5wvf/nLGTt2bH77299m0qRJ+cIXvpCrrroqixYtynve857suOOOueqqqzJ58uS84x3vyA9/+MMcdthh+fWvf52vfOUrSZI777wz3/jGN3LJJZe0HOe//du/5Utf+lL6+voyduzYXHnllVm2bFlOP/30/PGPf8yIESNyzjnnZJ999snSpUtz6qmnZuHChXnFK16RgYGB9fuZN29errrqqvT29ublL395PvWpT6Wzs3NL/9YAAACNU6V1NrUexc2bEfTef//9ufTSS3PNNdekp6cny5Yty2mnnZaZM2dm5syZufbaa3PuueeuD0w35te//nVuuOGGjB8/Psccc0zuuuuuvPvd784VV1yRK6+8Mj09PUmSFStWZN99981pp52WgYGBvOlNb8qSJUvS09OTOXPm5K1vfWvL/S9ZsiRnnnlm/vmf/zm77bZbli1bliS5+OKL85KXvCRf+cpX8qMf/Sgf//jHM2/evFxyySXZb7/9Mnv27Nx+++259tprkyQPPPBAbrzxxlxzzTUZOnRozj777Fx//fWZMWPGM/rDPuXFO49u63Fby767jSnaP2XtMrar9BAoZFfnflDbrcf5H6wmdA8tPQQK2n3c8NJDoBDn/q/bZND77//+7zn88MPXB6U77rhj7r777lx88cVJkunTp+eCCy7YZEf77rtvnvvc5yZJ9tlnnyxYsCD777//036vs7Mzb3zjG5Osm/g8ffr0zJ8/P7Nmzcrdd9+d888/v+X+/+M//iP7779/dtttt/XjTJK77rpr/VgPOuigLFu2LE888UR++tOf5stf/nKS5PWvf3122GGHJMmPfvSj3HvvvXnb296WJFm1alXGjRu3yePbmP/87yfS2zew6V/cBvbdbUzu+ePjRfpOktHDB/c6aV1Dys4e2GVsVxYsXV2k7yGdxWdOFNXb11+0/13HduXhQuc+qc+iFaX095e55j9lt56u/HFJmfNf+rlf2qiusu97E7qHZuFjvcX6H+znv/Rrf/dxw/PQ4lVlOh/k1/0MDN5zP2xIlefuUP8vWrfq1bmzszP9/esueP39/ent/d8L77Bhwzb4vY3N1+3q6tqglHjWrFk58cQTM2zYsBx++OEZMmTbvqEMDAxk5syZOfXUU7dpPwAAAE3wrF+9+VWvelW++93vZunSpUmSZcuWZfLkybnhhhuSJNdff/36jO0uu+ySX/3qV0mS73//+xsEvRszatSoLF++fKM/nzBhQsaPH59LL710o6XNSfKKV7wiP/vZz/LHP/5x/TiTZP/998/8+fOTJD/+8Y8zduzYjB49OgcccECuv/76JMkdd9yRP//5z0nWZYNvuummLF68eP1+FixYsMnjAAAAoH42mTbda6+98oEPfCDvete70tHRkZe85CU588wz84lPfCJf+9rX1i9klSRvf/vb88EPfjBHHnlkDj744IwcOXKTA3j729+e97///Rk/fnyuuuqqlr/zlre8JUuWLMkLXvCCje6np6cn55xzTk466aT09/dn3Lhx+ad/+qfMnj07p59+et7ylrdkxIgR+dznPpck+dCHPpRTTz01b37zmzN58uTsvPPOSZIXvvCFOeWUU/K+970v/f39GTp0aM4666zssssumzwWAAAA6qUaGChchL4ZzjnnnLz4xS/OUUcdVXooz5g5vYOXOb2DV+l5beb0llV6Xp85veWY0zu4z3/p1745vQWZ05tv/3phVqx5+vTVkcM6c8RLJhQY2YZq/8l01qxZue+++zJ9+vTSQwEAAOD/qP7KVge1T8XNmTPnaW1HHXVU1qxZs0Hb5z//+ey9997ba1gAAAA8C9Q+6G3lW9/6VukhAAAA8CzwrAx6AQAAqIcqG7llUU0KnGs/pxcAAADaJegFAACgsZQ3AwAA0LaOtM6m1iXDWpdxAAAAwFYn6AUAAKCxlDcDAADQtqrayOrNLdpKkOkFAACgsQS9AAAANJagFwAAgMYypxcAAIC2VU9urdrrQKYXAACAxhL0AgAA0FjKmwEAAGhflbS8O1FN6ptlegEAAKiVT3ziEznooINyxBFHrG9btmxZjjvuuBx22GE57rjj8uc//3mz9iXoBQAAoFZmzZqVyy+/fIO2yy67LAcddFBuvvnmHHTQQbnssss2a1+CXgAAANrWkaQjVYutfQcccEB22GGHDdpuvfXWzJgxI0kyY8aM3HLLLZu1L3N6AQAA2GYeeeSR9PX1bdDW3d2d7u7uZ7SfxYsXZ/z48UmSnXbaKYsXL96sxwl6AQAA2GaOPfbYLFiwYIO22bNn56STTmp7n1VVpWq5etbTCXoBAABoW7WR1Zufarv66qtbZnqfqXHjxmXRokUZP358Fi1alJ6ens16nKAXAACAbWbixIlbZT9TpkzJ3Llzc8IJJ2Tu3LmZOnXqZj3OQlYAAADUykc+8pEcffTR+f3vf5/Xvva1+da3vpUTTjghd955Zw477LD88Ic/zAknnLBZ+5LpBQAAoFa++MUvtmy/8sorn/G+BL3b2K/+9OcsX9O36V/cBvbdbUzufnRpkb6T5ODn71Ss7zpYUei812MM5Y+9pL7+gcIj6MoTq9YW631I5+AuIlrdW/r535XHVvYW6Xnc6GFF+q2L3r7+0kMoOoa1faWvfWUtX13uuvuUxwtd+zs7Nm8xoaaqw3P/sZVlzv2IYeve86sn//u/WrWVMLg/mQAAANBogl4AAAAaS3kzAAAAbdvULYtKk+kFAACgsQS9AAAANJbyZgAAANrWkSodLVZqbtVWgkwvAAAAjSXoBQAAoLGUNwMAANC+jazeXJPqZpleAAAAmkvQCwAAQGMJegEAAGgsc3oBAABoW7WROb0t5/kWINMLAABAYwl6AQAAaCzlzQAAALStevK/Vu11INMLAABAYwl6AQAAaCzlzQAAALSto1q3tWqvA5leAAAAGkvQCwAAQGMpbwYAAKBtVm8GAACAQgS9AAAANJbyZgAAANpWJalaVDLXo7hZphcAAIAGE/QCAADQWIJeAAAAGsucXgAAANrmlkUAAABQiKAXAACAxlLeDAAAQNuqKulodcuielQ3y/QCAADQXIJeAAAAGkt5MwAAAG2zejMAAAAUIugFAACgsZQ3AwAA0Laqar1Ss9WbAQAAYBsT9AIAANBYgl4AAAAay5xeAAAA2lY9ubVqrwOZXgAAABpL0AsAAEBjKW8GAACgbR1VlY4W9ydq1VaCTC8AAACNJegFAACgsZQ3AwAA0DarNwMAAEAhgl4AAAAaS3kzAAAA7at5fbNMLwAAAI0l6AUAAKCxBL0AAAA0ljm9AAAAbJGqLhN4W5DpBQAAoLEEvQAAADSW8mYAAADaVlXrtlbtdSDTCwAAQGMJegEAAGgs5c0AAAC0rXpya9VeBzK9AAAANJagFwAAgMZS3ryNvXLXcVnbP1Cs/4Ofv1OxvkcPH9xPr4Fyp3297hFDi/Q7UIeDL6iv4Gv+KWMKvv46OupSzFTG6K7O0kPIuNHDivQ7tHNwf5c+fGj55/7ornKv/VW9fcX6roMRw7pKDyHPGVNmDGv7+ov0Wxs1WKJ4bKHr/rCn3vJqXt88uN+dAAAAaDRBLwAAAI0l6AUAAKCxBvekSwAAALZIlWojU3rrMalXphcAAIDGEvQCAADQWMqbAQAAaFtVtb5zUw3u5pREphcAAIAGE/QCAADQWMqbAQAAaFv15NaqvQ5kegEAAGgsQS8AAACNpbwZAACALVOXWuYWZHoBAABoLEEvAAAAjSXoBQAAoLHM6QUAAKBtVaqN3LKoHhN9ZXoBAABoLEEvAAAAjaW8GQAAgLZV1bqtVXsdyPQCAADQWIJeAAAAGkt5MwAAAFukJpXMLcn0AgAA0FiCXgAAABpLeTMAAADtq9K6vrkmNc8yvQAAADTQaqytAAAQJElEQVSWoBcAAIDGelYGvX/3d3+XH/7wh1ttf7feemsuu+yylj+bPHnyVusHAACgaaq/8l8dFJ/TOzAwkIGBgXR0bH78ffLJJ2/VMUydOjVTp07dqvsEAACgvCJB78MPP5zjjz8+L3/5y/OrX/0qb3rTm3LbbbdlzZo1OfTQQ/PhD384SXLJJZdk/vz56enpycSJEzNp0qQcf/zxOe200/L6178+hx9+eH70ox/l/PPPT19fX1760pfm05/+dIYNG5YpU6ZkxowZue2227J27dpcdNFFecELXtByPHPmzMm9996bs846K3/84x/z0Y9+NCtWrMiUKVO2+Fh3Hzd8i/exJfbcaUTR/ilrQvfQ0kOgkF3GdpUeAgU9d4dhpYdAITuO7CzYe8m+SbzvD2a77Oi6/9cUy/Q++OCDOf/88/PEE0/kpptuyrXXXpuBgYGceOKJ+elPf5qurq7cfPPNmT9/fnp7ezNr1qxMmjRpg32sXr06p512Wq644orsscce+djHPpZvfOMbee9735skGTt2bP71X/81V199df7xH/8xn/3sZzc5rs9+9rM55phjMmPGjFx99dVbfJwPLV6Vtf0DW7yfduy504j8159WFuk7SUYPL15IUNRAmdO+3oTuoVn4WG+RvgdKH3xhfYVe80/ZZWxXFixdXaz/jo56lDKVUvron7vDsDz65zVF+h7a+aycNbXVdBZ+7u84sjPLVvQV639Vb7m+66Cqyp7/ku/7a/v6i/RbG4XP/S47DsuCZWWu+8M6k53G1D/gLvbutPPOO+cVr3hF7rzzztx5552ZMWNGZs6cmf/6r//KH/7wh/z85z/P1KlT09XVldGjR+eQQw552j5+//vfZ9ddd80ee+yRJJk5c2Z+9rOfrf/5YYcdliR56UtfmgULFmzWuO6+++68+c1vTpJMnz59Sw8TAACg0apq41sdFEvFjRw5Msm6jNAJJ5yQo48+eoOfX3HFFVvcx9Ch60o8Ojo60te3+d8+lv6mDgAAgK2jeB3Sa17zmlx33XVZvnx5kmThwoVZvHhx9ttvv9x2221ZvXp1li9fnttvv/1pj91jjz2yYMGCPPjgg0mSefPm5YADDtii8UyePDk33HBDkmT+/PlbtC8AAADKKj7p8jWveU0eeOCB9ZnekSNH5oILLsi+++6bKVOm5Mgjj8y4cePyohe9KGPGjNngsV1dXTnvvPNy8sknr1/I6phjjtmi8Zxxxhn56Ec/mssvv3yrLGQFAADQZFVar2lRl/rZaqDGK84sX748o0aNysqVK3PsscfmM5/5zNMWs6o7C1kNXqVfWRayKsdCVnV5iyuj9NFbyKocC1lZyKokC1kVZCGr3PfI8vT2Pf3zz9DOKntPHFVgZBuqdVRy1lln5Xe/+11Wr16dmTNnPusCXgAAAMqqddB74YUXbtX9XXfddfn617++Qdt+++2XT33qU1u1HwAAgEGj5vXNtQ56t7a3vvWteetb31p6GAAAAGwng3vyDQAAAI02qDK9AAAAbF1Vqo1UN9ejvlmmFwAAgMYS9AIAANBYgl4AAAAay5xeAAAA2lZV67ZW7XUg0wsAAEBjCXoBAABoLOXNAAAAtK16cmvVXgcyvQAAADSWoBcAAIDGUt4MAABA+2pe3yzTCwAAQGMJegEAAGgs5c0AAAC0rUq1kermetQ3y/QCAADQWIJeAAAAGkvQCwAAQGOZ0wsAAED7qqRyyyIAAADY/gS9AAAANJbyZgAAANpWpXUlc02qmwW929ry1WvT2zdQrP8nVq0t1nfXkMFdSNDXX+68rzM0q3v7ivTc2encl1ZyDAUvefUwUP4PsGZtf5F+q5YTugaPtcVf+51ZXejcJyn6eacO+vrL/e3XGZqVa8q87w8b5J/5Sr7unlLsul+bsPavG9zPUAAAABpNphcAAIAtU+Okr0wvAAAAjSXoBQAAoLGUNwMAANC2aiNLWtVloSuZXgAAABpL0AsAAEBjCXoBAABoLHN6AQAAaFtVrdtatdeBTC8AAACNJegFAACgsZQ3AwAA0Lbqya1Vex3I9AIAANBYgl4AAAAaS3kzAAAA7at5fbNMLwAAAI0l6AUAAKCxlDcDAADQtirVRqqb61HfLNMLAABAYwl6AQAAaCzlzQAAALStqtZtrdrrQKYXAACAxhL0AgAA0FiCXgAAABrLnF4AAADaVj25tWqvA5leAAAAGkvQCwAAQGMpbwYAAKB9Na9vlukFAACgsQS9AAAANJbyZgAAALZItQ1qmadMmZJRo0alo6MjnZ2dmTNnTlv7EfQCAABQS1deeWV6enq2aB+CXgAAALaZRx55JH19fRu0dXd3p7u7e7v0L+gFAACgbVW1bmvVniTHHntsFixYsMHPZs+enZNOOmmT+z7++ONTVVXe8Y535B3veEdb4xP0AgAAsM1cffXVLTO9m3LNNddkwoQJWbx4cY477rjsueeeOeCAA55x/4JeAAAAtpmJEye29bgJEyYkScaNG5dDDz0099xzT1tBr1sWAQAAUCsrVqzIE088sf7fd955Z/baa6+29iXTCwAAQNuqJ7dW7e1avHhxPvShDyVJ+vr6csQRR+S1r31tW/sS9AIAAFAru+22W+bPn79V9qW8GQAAgMaS6QUAAKBtm7plUWkyvQAAADSWoBcAAIDGUt4MAADAFqhJHfNGyPQCAADQWIJeAAAAGkt5MwAAAG2zejMAAAAUIugFAACgsQS9AAAANJY5vQAAALStSuubFtVkSq9MLwAAAM0l6AUAAKCxlDcDAADQtiobuWXRdh9JazK9AAAANJagFwAAgMZS3gwAAEDbqlRWbwYAAIASBL0AAAA0lvJmAAAA2rexOuaa1DfL9AIAANBYgl4AAAAaS9ALAABAY5nTu42NHDYka/sHivU/qqvcKS531PXQ2Vn+O6VSY+ioyfyNUvqqGvwB6jCGQaqjBi+AOoxhMKrDy67kGAb7866v4Oe90gbzsSdJ15Dyn/lKjWFo5//+u85XgPJnCAAAALYRQS8AAACNpbwZAACAtlVV6/LmOkz7SGR6AQAAaDBBLwAAAI2lvBkAAIC2Valalzdv95G0JtMLAABAYwl6AQAAaCzlzQAAALRvY3XMNalvlukFAACgsQS9AAAANJagFwAAgMYypxcAAIC2VWk9fbcmU3plegEAAGguQS8AAACNpbwZAACAtlXVRsqba1LfLNMLAABAYwl6AQAAaCzlzQAAALStSmX1ZgAAAChB0AsAAEBjKW8GAACgbVZvBgAAgEIEvQAAADSWoBcAAIDGEvQCAADQWIJeAAAAGkvQuxEPP/xwrr/++tLDAAAAYAsIejdiwYIF+fa3v116GAAAALVWVRvf6qDofXpXrFiRU045JY8++mj6+/vzwQ9+MLvvvns+97nPZcWKFRk7dmzOO++8jB8/Pvfcc0/OOOOMdHR05NWvfnV+8IMf5Nvf/nbmzJmTW265JStXrsyDDz6Y973vfent7c28efMybNiwXHbZZdlxxx3z0EMP5dOf/nSWLl2a4cOH5zOf+Uxe8IIX5LTTTsvo0aNz77335k9/+lP+9m//NocffnguvPDCPPDAA5k+fXpmzpyZ9773vSX/VAAAALShaKb3Bz/4QcaPH5/58+fn29/+dg4++OCce+65+fu///vMmTMnb33rW/OlL30pSXL66afnnHPOybx589LZ2bnBfu6///5cfPHFufbaa/OlL30pw4cPz9y5c/OKV7wic+fOTZKceeaZOfPMMzNnzpx8/OMfz6c//en1j1+0aFG+8Y1v5Ktf/WouvPDCJMmpp56a/fffP/PmzRPwAgAAPEsVzfS+6EUvyvnnn58LLrgghxxySLq7u/Pb3/42xx13XJKkv78/O+20Ux577LEsX748kydPTpIcccQRuf3229fv58ADD8zo0aOTJGPGjMmUKVPW7/++++7L8uXLc/fdd+fkk09e/5g1a9as//cb3vCGdHR05IUvfGH+53/+Z6se4/OeM3yr7u+ZesH4EUX7p6xddhxWeggUsntPV+khUNCuY53/wWr8mKGlh0BBzy/8uZNydi7+ma9KTSqZWyoa9O6xxx6ZM2dO7rjjjlx00UV51atelb322iv/8i//ssHvPfbYY391P8OG/e9J7ujoyNChQ9f/u6+vLwMDA+nu7s68efM2+fit7cH/WZW1/QPbbP9/zQvGj8gDi1YW6TtJuoYO7injVeFJDLvsOCwLlq3Z9C9uAx11vuptB719ZV7zT9m9pysPLVlddAyDWenn/65ju/Lw0jLnf2jnYL/ul+1//JihWfR4b7H+S1/7Sutd21+0/+c/Z3j+8D+rivTdWfrCV1jp4995x2H570Kf+YZ2JjuNKR1wb1rRd6eFCxdmxIgRmT59eo4//vj84he/yJIlS3L33XcnSXp7e3P//fenu7s7o0aNyi9+8YskyXe+851n1M/o0aOz66675sYbb0ySDAwM5De/+c1ffcyoUaOyfPnyNo4KAACAuiia6f3tb3+bz3/+8+no6MiQIUNy9tlnZ8iQITn33HPz+OOPp6+vL+95z3uy11575bOf/Ww++clPpqOjIwcccMD6cubNdcEFF+Tss8/OpZdemrVr12batGnZZ599Nvr7e++9dzo6OnLkkUdm1qxZ5vUCAAC0sLFKl9IVME+pBgYGnhW1KMuXL8+oUaOSJJdddlkWLVqUT37yk4VHtWnKmwcv5c2DV+kSP+XNZZV+/itvLqf0hzvlzWUpbx68Sh9/HcqbH1/dn1ZRZVUlY7rKvzcUzfQ+E3fccUe++tWvpq+vLzvvvHM+97nPlR4SAAAANfesCXqnTZuWadOmlR4GAAAAf2Fjue661ACUzzUDAADANiLoBQAAoLEEvQAAADTWs2ZOLwAAADVVlwm8Lcj0AgAA0FiCXgAAABpLeTMAAABtqzZS21yXimeZXgAAABpL0AsAAEBjKW8GAACgbdVG6piVNwMAAMA2JugFAACgsZQ3AwAA0LaNlTErbwYAAIBtTNALAABAYwl6AQAAaCxzegEAAGhfXSbvboRMLwAAAI0l6AUAAKCxlDcDAADQtmoj9c11qXqW6QUAAKCxBL0AAAA0lvJmAAAA2lZtpI5ZeTMAAABsYzK921hnR9nvN4YU7L9zkH+lsrFvvLanUudgkJ/69NfgDzDYX38lFb7sJyn42q/BsZdUh+t+yXMw2K87AzV4AZT63NcxyM99HZ77dbjul38FbFw1MDAwUHoQAAAAsC3U4HsJtoVHHnkkU6ZMySOPPFJ6KBTg/A9ezv3g5vwPXs794Ob8D17O/eYR9DZUX19fFixYkL6+vtJDoQDnf/By7gc353/wcu4HN+d/8HLuN4+gFwAAgMYS9AIAANBYgl4AAAAaq/Pss88+u/Qg2Da6urpy4IEHpqurq/RQKMD5H7yc+8HN+R+8nPvBzfkfvJz7TXPLIgAAABpLeTMAAACNJegFAACgsQS9AAAANJagFwAAgMYS9AIAANBY/z+sxI83ser6VgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyJSjMWmnc6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}